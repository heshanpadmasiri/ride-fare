{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,f1_score,confusion_matrix,log_loss\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate,Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor,DMatrix,plot_tree\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "train_df_org = pd.read_csv('train_df_final_blanced.csv')\n",
    "train_df_org = train_df_org.fillna(0)\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "test_df = test_df.fillna(0)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = train_df['label'].values\n",
    "y_org = train_df_org['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    'fare_per_distance',\n",
    "    'fare_per_duration',\n",
    "    'avg_speed',\n",
    "    'meter_waiting_per_duration',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration',\n",
    "    'fare-additional_fare_per_distance',\n",
    "    'fare-additional_fare_per_duration',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_distance',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_duration',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting',\n",
    "    'meter_waiting_after_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_distance',\n",
    "    'meter_waiting_after_pickup_per_distance',\n",
    "    'meter_waiting_till_pickup_per_fare',\n",
    "    'meter_waiting_after_pickup_per_fare',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting_fare',\n",
    "    'meter_waiting_after_pickup_per_meter_waiting_fare',    \n",
    "]\n",
    "\n",
    "base_cat_features = []\n",
    "\n",
    "cat_cols = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'pickup_date',\n",
    "    'pickup_hour',\n",
    "    'pickup_minute',\n",
    "    'drop_date',\n",
    "    'drop_hour',\n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_accuracy(features, cat_features,y):\n",
    "    train = train_df[features]\n",
    "    test = test_df[features]\n",
    "    for each in cat_features:\n",
    "        train[each] = train[each].values.astype(int)\n",
    "        test[each] = test[each].values.astype(int)\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    validation_scores = []\n",
    "    for train_index, test_index in skf.split(train, y):\n",
    "        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "        test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "        model = CatBoostClassifier(**catboost_params)\n",
    "        model.fit(X=train_pool, eval_set=test_pool,verbose=0)\n",
    "        \n",
    "        validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    return np.mean(validation_scores), np.min(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = base_features[:]\n",
    "other_features = [each for each in test_df.columns if each not in selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy, _ = get_mean_accuracy(base_features,base_cat_features,y)\n",
    "feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_features = other_features[:]\n",
    "# remaining_features.remove('predicted_duration_diff_bucket@predicted_avg_speed')\n",
    "# selected_features.append('predicted_duration_diff_bucket@predicted_avg_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "while len(remaining_features)>0:\n",
    "    for new_feature in remaining_features:\n",
    "        features = selected_features + [new_feature]\n",
    "        cat_features = [feature for feature in features if feature in cat_cols]\n",
    "        mean,_ = get_mean_accuracy(features,cat_features,y)\n",
    "        if mean > mean_accuracy:\n",
    "            mean_accuracy = mean\n",
    "            feature = new_feature\n",
    "            print(new_feature, mean)\n",
    "    if feature != None:\n",
    "        selected_features.append(feature)\n",
    "        remaining_features.remove(feature)\n",
    "        feature = None\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = selected_features[:]\n",
    "cat_features = [feature for feature in features if feature in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "train_org = train_df_org[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)\n",
    "    train_org[each] = train_org[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "org_pool = Pool(data=train_org[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    org_scores.append(f1_score(y_org,model.predict(org_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores), min(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(org_scores), np.std(org_scores), min(org_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = test_class\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = test_df.columns\n",
    "X_train = train_df[features].values\n",
    "X_train_org = train_df_org[features].values\n",
    "X_test = test_df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "X_train_transformed = pca.fit_transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)\n",
    "X_train_org_transformed = pca.transform(X_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pd.DataFrame()\n",
    "pca_train['label'] = train_df['label']\n",
    "\n",
    "pca_train_org = pd.DataFrame()\n",
    "pca_train_org['label'] = y_org\n",
    "\n",
    "pca_test = pd.DataFrame()\n",
    "for i in range(40):\n",
    "    name = f'col_{i}'\n",
    "    pca_train[name] = X_train_transformed[:,i]\n",
    "    pca_test[name] = X_test_transformed[:,i]\n",
    "    pca_train_org[name] = X_train_org_transformed[:,i]\n",
    "    \n",
    "pca_train.to_csv('pca_train.csv',index=False)\n",
    "pca_test.to_csv('pca_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='col_0',y='col_1',data=pca_train,hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='col_0',y='col_3',data=pca_train,hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pca_test.columns\n",
    "cat_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pca_train[features]\n",
    "test = pca_test[features]\n",
    "train_org = pca_train_org[features]\n",
    "y = pca_train['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)\n",
    "    train_org[each] = train_org[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=pca_test[features], cat_features=cat_features)\n",
    "org_pool = Pool(data=pca_train_org[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    org_scores.append(f1_score(y_org,model.predict(org_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores), min(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(org_scores), np.std(org_scores), min(org_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
