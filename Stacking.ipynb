{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate,Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.DataFrame()\n",
    "model_predictions_train['label'] = train_df['label']\n",
    "model_predictions_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "}\n",
    "depths = [3,6,8]\n",
    "l2_leaf_regs = [1.0,3.0,6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params():\n",
    "    params = []\n",
    "    for depth in depths:\n",
    "        for l2_leaf_reg in l2_leaf_regs:\n",
    "            param = fixed_params.copy()\n",
    "            param['depth'] = depth\n",
    "            param['l2_leaf_reg'] = l2_leaf_reg\n",
    "            params.append(param)\n",
    "    return params\n",
    "\n",
    "def generate_model_name(params,base_name='catboost_base'):\n",
    "    return f'{base_name}_{params[\"depth\"]}_{params[\"l2_leaf_reg\"]}'\n",
    "\n",
    "def get_model_predictions(params=fixed_params):\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "    train_class = np.zeros(train_df.shape[0])\n",
    "    test_class = np.zeros(test_df.shape[0])\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    for train_index, test_index in skf.split(train, y):\n",
    "        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "        test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X=train_pool, eval_set=test_pool,verbose=0)\n",
    "        train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "        train_class[test_index] = model.predict(test_pool)\n",
    "        test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "        test_class = model.predict(submission_pool)\n",
    "    test_class = np.where(test_class > 2, 1, 0)\n",
    "    return train_preds,test_preds, train_class, test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # noise columns    \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'fare',\n",
    "    'predicted_fare',\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'fare_per_distance',\n",
    "    'predicted_fare_per_distance', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duration',\n",
    "    'predicted_duration_diff', \n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'fare_per_duration',\n",
    "    'predicted_fare_per_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'avg_speed', \n",
    "    'predicted_avg_speed', \n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting', \n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'meter_waiting_per_duration', \n",
    "    'predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare', \n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare', \n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_per_fare', \n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'predicted_addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration', \n",
    "    'predicted_addtional_fare_per_duration',\n",
    "]\n",
    "cat_features = []\n",
    "y = train_df['label'].values\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in tqdm(generate_params()):\n",
    "    train_preds, test_preds, train_class, test_class = get_model_predictions(params)\n",
    "    name = generate_model_name(params)\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds\n",
    "    model_predictions_train[f'{name}_class'] = train_class\n",
    "    model_predictions_test[f'{name}_class'] = test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [each for each in train_df.columns if 'anomaly' in each]\n",
    "cat_features = features[:]\n",
    "y = train_df['label'].values\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "scale_pos_weight = (y.shape[0]-y.sum())/y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in tqdm(generate_params()):    \n",
    "    train_preds, test_preds, train_class, test_class = get_model_predictions(params)\n",
    "    name = generate_model_name(params,'catboost_anomaly')\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds\n",
    "    model_predictions_train[f'{name}_class'] = train_class\n",
    "    model_predictions_test[f'{name}_class'] = test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(value=0)\n",
    "test_df = test_df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "\n",
    "X = train_df[features]\n",
    "Y = train_df['label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_scale = scaler.fit_transform(X)\n",
    "x_correct, x_incorrect = x_scale[Y == 1], x_scale[Y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    ## input layer \n",
    "    input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "    ## encoding part\n",
    "    encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "    ## decoding part\n",
    "    decoded = Dense(50, activation='tanh')(encoded)\n",
    "    decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "    ## output layer\n",
    "    output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = get_model()\n",
    "autoencoder.fit(x_correct, x_correct, \n",
    "                batch_size = 256, epochs = 50, \n",
    "                shuffle = True, validation_split = 0.20,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])\n",
    "\n",
    "\n",
    "train = hidden_representation.predict(scaler.transform(train_df[features]))\n",
    "test = hidden_representation.predict(scaler.transform(test_df[features]))\n",
    "sub_pool = Pool(data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_predictions(params):\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "    train_class = np.zeros(train_df.shape[0])\n",
    "    test_class = np.zeros(test_df.shape[0])\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    for train_index, test_index in skf.split(train, Y):\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        train_pool = Pool(data=X_train, label=y_train)\n",
    "        test_pool = Pool(data=X_test, label=y_test)    \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X=train_pool, eval_set=test_pool,verbose=0)\n",
    "        train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "        test_preds += model.predict_proba(sub_pool)[:,1]/3\n",
    "        train_class[test_index] = model.predict(test_pool)\n",
    "        test_class = model.predict(sub_pool)\n",
    "    test_class = np.where(test_class > 2, 1, 0)\n",
    "    return train_preds,test_preds, train_class, test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in tqdm(generate_params()):\n",
    "    train_preds, test_preds, train_class, test_class = get_catboost_predictions(params)\n",
    "    name = generate_model_name(params,'autoencoder_catboost')\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds\n",
    "    model_predictions_train[f'{name}_class'] = train_class\n",
    "    model_predictions_test[f'{name}_class'] = test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_model(input_size,layers=[40,20,10]):\n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    \n",
    "    X = Dense(layers[0],activation='relu')(input_layer)\n",
    "    for nodes in layers[1:]:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X_train.shape[1],[100,50,50])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds / 3\n",
    "    train_preds[test_index] += model.predict(X_valid).reshape(X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'simple_nn'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X_train.shape[1],[100,50,50])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds / 3\n",
    "    train_preds[test_index] += model.predict(X_valid).reshape(X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'simple_nn_with_linear_predictions'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "STEPS_PER_EPOCH = 3400//BATCH_SIZE\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "      0.001,\n",
    "      decay_steps=STEPS_PER_EPOCH*1000,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "\n",
    "def get_log_dir(model):\n",
    "    model_name = '-'.join(map(lambda x: str(x),model))\n",
    "    return f'./logs/{model_name}'\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_combined_model(fare_model, duration_model, meter_waiting_model, meter_waiting_fare_model, model_def=[100,50], freeze_input=True):\n",
    "    if freeze_input:\n",
    "        fare_model.trainable = False\n",
    "        duration_model.trainable = False\n",
    "        meter_waiting_model.trainable = False\n",
    "        meter_waiting_fare_model.trainable = False\n",
    "    \n",
    "    fare_input = Input(shape=(fare_model.input.shape[1],), name='fare_input')\n",
    "    fare = fare_model(fare_input)\n",
    "    \n",
    "    duration_input = Input(shape=(duration_model.input.shape[1],), name='duration_input')\n",
    "    duration = fare_model(duration_input)\n",
    "    \n",
    "    meter_waiting_input = Input(shape=(meter_waiting_model.input.shape[1],), name='meter_waiting_input')\n",
    "    meter_waiting = fare_model(meter_waiting_input)\n",
    "    \n",
    "    meter_waiting_fare_input = Input(shape=(meter_waiting_fare_model.input.shape[1],), name='meter_waiting_fare_input')\n",
    "    meter_waiting_fare = fare_model(meter_waiting_fare_input)\n",
    "    \n",
    "    X = concatenate([fare,duration,meter_waiting,meter_waiting_fare])\n",
    "    \n",
    "    for nodes in model_def:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model([fare_input,duration_input,meter_waiting_input,meter_waiting_fare_input],output_layer)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule), \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_representation = tf.keras.models.load_model('models/fare_representation')\n",
    "duration_representation = tf.keras.models.load_model('models/duration_representation')\n",
    "meter_waiting_representation = tf.keras.models.load_model('models/meter_waiting_representation')\n",
    "meter_waiting_fare_representation = tf.keras.models.load_model('models/meter_waiting_fare_representation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference'\n",
    "]\n",
    "\n",
    "fare_features = ['additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "duration_features = ['additional_fare', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_features = ['additional_fare', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_fare_features = ['additional_fare', \n",
    "    'meter_waiting',    \n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])\n",
    "\n",
    "train = train_df.copy()\n",
    "train[features] = X_scale\n",
    "\n",
    "test = test_df.copy()\n",
    "test[features] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "model_def=(400, 800, 400, 100, 50, 20, 10)\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_fare_train, X_fare_test = train[fare_features].iloc[train_index,:],train[fare_features].iloc[test_index,:]\n",
    "    X_duration_train, X_duration_test = train[duration_features].iloc[train_index,:],train[duration_features].iloc[test_index,:]\n",
    "    X_meter_waiting_train, X_meter_waiting_test = train[meter_waiting_features].iloc[train_index,:],train[meter_waiting_features].iloc[test_index,:]\n",
    "    X_meter_waiting_fare_train, X_meter_waiting_fare_test = train[meter_waiting_fare_features].iloc[train_index,:],train[meter_waiting_fare_features].iloc[test_index,:]\n",
    "    \n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_combined_model(fare_representation,\n",
    "                           duration_representation,\n",
    "                           meter_waiting_representation,\n",
    "                           meter_waiting_fare_representation,\n",
    "                           model_def=model_def)\n",
    "    model.fit({'fare_input':X_fare_train,\n",
    "              'duration_input':X_duration_train,\n",
    "              'meter_waiting_input':X_meter_waiting_train,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_train},\n",
    "              y_train,\n",
    "              batch_size=512,\n",
    "              epochs=500,\n",
    "              validation_data=({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test},y_valid),callbacks=callbacks)\n",
    "    y_hat = model.predict({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test}).reshape(y_valid.shape)\n",
    "    train_preds[test_index] = y_hat\n",
    " \n",
    "    X_fare, X_duration, X_meter_waiting,X_X_meter_waiting_fare = test[fare_features],test[duration_features],test[meter_waiting_features],test[meter_waiting_fare_features]\n",
    "    \n",
    "    preds = model.predict({'fare_input':X_fare,\n",
    "              'duration_input':X_duration,\n",
    "              'meter_waiting_input':X_meter_waiting,\n",
    "              'meter_waiting_fare_input':X_X_meter_waiting_fare}).reshape(test_preds.shape)\n",
    "    test_preds += preds/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'multihead_nn'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat,average='micro'), True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "train_X = train_df[features]\n",
    "test_X = test_df[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bagging_fraction': 0.7528277381788788,\n",
    "    'class_weight': None,\n",
    "    'feature_fraction': 0.5625261317624038,\n",
    "    'lambda_l2_positive': 0.01363014388342585,\n",
    "    'learning_rate': 0.11231814419878085,\n",
    "    'min_child_weight': 20.69211631593017,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'num_leaves': 86,\n",
    "    'subsample_for_bin': 60000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "test_preds = np.zeros(test_X.shape[0])\n",
    "train_preds = np.zeros(train_X.shape[0])\n",
    "for train_index, test_index in skf.split(train_df, y):\n",
    "    X_train, X_test = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train = lgb.Dataset(X_train,y_train)\n",
    "    valid = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test_X) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_all'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'fare',\n",
    "    'predicted_fare',\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'fare_per_distance',\n",
    "    'predicted_fare_per_distance', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duration',\n",
    "    'predicted_duration_diff', \n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'fare_per_duration',\n",
    "    'predicted_fare_per_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'avg_speed', \n",
    "    'predicted_avg_speed', \n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting', \n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'meter_waiting_per_duration', \n",
    "    'predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare', \n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare', \n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_per_fare', \n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'predicted_addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration', \n",
    "    'predicted_addtional_fare_per_duration',\n",
    "]\n",
    "train_X = train_df[features]\n",
    "test_X = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bagging_fraction': 0.9582184397618998,\n",
    "    'class_weight': 'balanced',\n",
    "    'feature_fraction': 0.6584730253641345,\n",
    "    'lambda_l1_positive': 0.004131014051823846,\n",
    "    'lambda_l2_positive': 2.021463074958273,\n",
    "    'learning_rate': 0.1292032123987036,\n",
    "    'min_child_weight': 27.329223863721854,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_leaves': 120,\n",
    "    'subsample_for_bin': 20000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "test_preds = np.zeros(test_X.shape[0])\n",
    "train_preds = np.zeros(train_X.shape[0])\n",
    "for train_index, test_index in skf.split(train_df, y):\n",
    "    X_train, X_test = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train = lgb.Dataset(X_train,y_train)\n",
    "    valid = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test_X) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_catfeatures'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_predictions_test.columns\n",
    "cat_features = [each for each in features if 'class' in each]\n",
    "\n",
    "for each in cat_features:\n",
    "    model_predictions_train[each] = model_predictions_train[each].values.astype(int)\n",
    "    model_predictions_test[each] = model_predictions_test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(model_predictions_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train.to_csv('stack_train.csv',index=False)\n",
    "model_predictions_test.to_csv('stack_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "ignore = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_6_3.0_class',\n",
    "    'catboost_base_3_6.0',\n",
    "    'catboost_base_3_6.0_class',\n",
    "    'catboost_base_3_1.0',\n",
    "    'catboost_base_3_1.0_class',\n",
    "    'catboost_base_8_3.0',\n",
    "    'catboost_base_8_3.0_class',\n",
    "    'autoencoder_catboost_8_3.0',\n",
    "    'catboost_anomaly_8_1.0',\n",
    "    'catboost_anomaly_8_1.0_class',\n",
    "    \n",
    "    'catboost_anomaly_3_1.0_class',\n",
    "    'catboost_anomaly_3_1.0_class',\n",
    "    'catboost_anomaly_3_3.0_class',\n",
    "    'catboost_anomaly_3_6.0_class',\n",
    "    'catboost_anomaly_6_3.0_class',\n",
    "    'catboost_anomaly_8_3.0_class',\n",
    "    'catboost_anomaly_8_6.0_class',\n",
    "    'autoencoder_catboost_3_1.0_class',\n",
    "    'autoencoder_catboost_3_3.0_class',\n",
    "    'autoencoder_catboost_3_6.0_class',\n",
    "    'autoencoder_catboost_6_1.0_class',\n",
    "#     'autoencoder_catboost_6_3.0_class',\n",
    "#     'autoencoder_catboost_6_6.0_class',\n",
    "#     'autoencoder_catboost_8_1.0_class',\n",
    "#     'autoencoder_catboost_8_6.0_class'\n",
    "]\n",
    "\n",
    "features = [each for each in model_predictions_test.columns if each not in ignore]\n",
    "cat_features = [each for each in features if 'class' in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 0.5, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'catboost_anomaly_3_6.0',\n",
    "    'catboost_base_6_3.0_class',\n",
    "    'catboost_base_3_1.0_class',\n",
    "    'autoencoder_catboost_8_1.0_class',\n",
    "    'catboost_anomaly_3_6.0_class',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'catboost_base_6_3.0_class',\n",
    "    'catboost_base_3_1.0_class',\n",
    "    'autoencoder_catboost_8_1.0_class',\n",
    "    'catboost_anomaly_3_6.0_class'\n",
    "]\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model = models[np.argmin(validation_scores)]\n",
    "worst_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model.plot_tree(0,train_pools[np.argmin(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "predictions_df['target'] = labels\n",
    "predictions_df['worst_model'] = worst_model.predict(train)\n",
    "predictions_df['best_model'] = best_model.predict(train)\n",
    "\n",
    "predictions_df['worst_incorrect'] = np.abs(predictions_df['target']-predictions_df['worst_model'])\n",
    "predictions_df['best_incorrect'] = np.abs(predictions_df['target']-predictions_df['best_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['worst_incorrect'][:1_000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['best_incorrect'][:1_000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 0.5, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta predictions feature engineerings\n",
    "\n",
    "All the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = list(model_predictions_test.columns)\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "labels = model_predictions_train['label']\n",
    "model_predictions_train = model_predictions_train[features]\n",
    "model_predictions_test = model_predictions_test[features]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model = models[np.argmin(validation_scores)]\n",
    "worst_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = best_model.get_feature_importance(prettified=True)\n",
    "important_features = f_i[f_i['Importances'] > 0]['Feature Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = model_predictions_train[important_features]\n",
    "model_predictions_test = model_predictions_test[important_features]\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[important_features], cat_features=cat_features)\n",
    "train = model_predictions_train[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra trees stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_predictions_test.columns\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':10,\n",
    "    'random_state':0,\n",
    "    'max_depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':10,\n",
    "    'random_state':0,\n",
    "    'max_depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = model_predictions_test.columns\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {    \n",
    "    'random_state':0,\n",
    "    'penalty':'l2',\n",
    "    'solver':'lbfgs',\n",
    "    'max_iter':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {    \n",
    "    'random_state':0,\n",
    "    'penalty':'l2',\n",
    "    'solver':'lbfgs',\n",
    "    'max_iter':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "y = model_predictions_train['label'].values\n",
    "model_predictions_train = model_predictions_train[features]\n",
    "model_predictions_test = model_predictions_test[features]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
