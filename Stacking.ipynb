{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate,Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.DataFrame()\n",
    "model_predictions_train['label'] = train_df['label']\n",
    "model_predictions_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "}\n",
    "depths = [3,6,8]\n",
    "l2_leaf_regs = [1.0,3.0,6.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params():\n",
    "    params = []\n",
    "    for depth in depths:\n",
    "        for l2_leaf_reg in l2_leaf_regs:\n",
    "            param = fixed_params.copy()\n",
    "            param['depth'] = depth\n",
    "            param['l2_leaf_reg'] = l2_leaf_reg\n",
    "            params.append(param)\n",
    "    return params\n",
    "\n",
    "def generate_model_name(params,base_name='catboost_base'):\n",
    "    return f'{base_name}_{params[\"depth\"]}_{params[\"l2_leaf_reg\"]}'\n",
    "\n",
    "def get_model_predictions(params=fixed_params):\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    for train_index, test_index in skf.split(train, y):\n",
    "        X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "        test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X=train_pool, eval_set=test_pool,verbose=0)\n",
    "        train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "        test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    return train_preds,test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # noise columns    \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'fare',\n",
    "    'predicted_fare',\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'fare_per_distance',\n",
    "    'predicted_fare_per_distance', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duration',\n",
    "    'predicted_duration_diff', \n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'fare_per_duration',\n",
    "    'predicted_fare_per_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'avg_speed', \n",
    "    'predicted_avg_speed', \n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting', \n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'meter_waiting_per_duration', \n",
    "    'predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare', \n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare', \n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_per_fare', \n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'predicted_addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration', \n",
    "    'predicted_addtional_fare_per_duration',\n",
    "]\n",
    "cat_features = []\n",
    "y = train_df['label'].values\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:11<00:00,  7.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for params in tqdm(generate_params()):\n",
    "    train_preds, test_preds = get_model_predictions(params)\n",
    "    name = generate_model_name(params)\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [each for each in train_df.columns if 'anomaly' in each]\n",
    "cat_features = features[:]\n",
    "y = train_df['label'].values\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "scale_pos_weight = (y.shape[0]-y.sum())/y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:26<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "for params in tqdm(generate_params()):\n",
    "    train_preds, test_preds = get_model_predictions(params)\n",
    "    name = generate_model_name(params,'catboost_anomaly')\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(value=0)\n",
    "test_df = test_df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "\n",
    "X = train_df[features]\n",
    "Y = train_df['label']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_scale = scaler.fit_transform(X)\n",
    "x_correct, x_incorrect = x_scale[Y == 1], x_scale[Y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    ## input layer \n",
    "    input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "    ## encoding part\n",
    "    encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "    ## decoding part\n",
    "    decoded = Dense(50, activation='tanh')(encoded)\n",
    "    decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "    ## output layer\n",
    "    output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f55eb725150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = get_model()\n",
    "autoencoder.fit(x_correct, x_correct, \n",
    "                batch_size = 256, epochs = 50, \n",
    "                shuffle = True, validation_split = 0.20,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])\n",
    "\n",
    "\n",
    "train = hidden_representation.predict(scaler.transform(train_df[features]))\n",
    "test = hidden_representation.predict(scaler.transform(test_df[features]))\n",
    "sub_pool = Pool(data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_predictions(params):\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    for train_index, test_index in skf.split(train, Y):\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        train_pool = Pool(data=X_train, label=y_train)\n",
    "        test_pool = Pool(data=X_test, label=y_test)    \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X=train_pool, eval_set=test_pool,verbose=0)\n",
    "        train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "        test_preds += model.predict_proba(sub_pool)[:,1]/3\n",
    "    return train_preds,test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:34<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for params in tqdm(generate_params()):\n",
    "    train_preds, test_preds = get_catboost_predictions(params)\n",
    "    name = generate_model_name(params,'autoencoder_catboost')\n",
    "    model_predictions_train[name] = train_preds\n",
    "    model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_model(input_size,layers=[40,20,10]):\n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    \n",
    "    X = Dense(layers[0],activation='relu')(input_layer)\n",
    "    for nodes in layers[1:]:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0415 - f1_score: 0.9529 - val_loss: 0.0409 - val_f1_score: 0.9529\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0402 - f1_score: 0.9529 - val_loss: 0.0397 - val_f1_score: 0.9529\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0394 - f1_score: 0.9529 - val_loss: 0.0389 - val_f1_score: 0.9529\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0381 - f1_score: 0.9529 - val_loss: 0.0376 - val_f1_score: 0.9529\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0367 - f1_score: 0.9529 - val_loss: 0.0366 - val_f1_score: 0.9529\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0355 - f1_score: 0.9529 - val_loss: 0.0378 - val_f1_score: 0.9529\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0351 - f1_score: 0.9529 - val_loss: 0.0370 - val_f1_score: 0.9529\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0331 - f1_score: 0.9529 - val_loss: 0.0356 - val_f1_score: 0.9529\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0323 - f1_score: 0.9529 - val_loss: 0.0346 - val_f1_score: 0.9529\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0312 - f1_score: 0.9529 - val_loss: 0.0343 - val_f1_score: 0.9529\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0303 - f1_score: 0.9529 - val_loss: 0.0342 - val_f1_score: 0.9529\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0298 - f1_score: 0.9529 - val_loss: 0.0341 - val_f1_score: 0.9529\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0291 - f1_score: 0.9529 - val_loss: 0.0385 - val_f1_score: 0.9529\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0292 - f1_score: 0.9529 - val_loss: 0.0343 - val_f1_score: 0.9529\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0340 - val_f1_score: 0.9529\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0280 - f1_score: 0.9529 - val_loss: 0.0344 - val_f1_score: 0.9529\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0272 - f1_score: 0.9529 - val_loss: 0.0334 - val_f1_score: 0.9529\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0278 - f1_score: 0.9529 - val_loss: 0.0353 - val_f1_score: 0.9529\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0277 - f1_score: 0.9529 - val_loss: 0.0356 - val_f1_score: 0.9529\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0274 - f1_score: 0.9529 - val_loss: 0.0333 - val_f1_score: 0.9529\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0266 - f1_score: 0.9529 - val_loss: 0.0339 - val_f1_score: 0.9529\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0266 - f1_score: 0.9529 - val_loss: 0.0343 - val_f1_score: 0.9529\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0339 - val_f1_score: 0.9529\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0260 - f1_score: 0.9529 - val_loss: 0.0346 - val_f1_score: 0.9529\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0337 - val_f1_score: 0.9529\n",
      "fold: 2\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0420 - f1_score: 0.9529 - val_loss: 0.0411 - val_f1_score: 0.9529\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0400 - f1_score: 0.9529 - val_loss: 0.0405 - val_f1_score: 0.9529\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0394 - f1_score: 0.9529 - val_loss: 0.0400 - val_f1_score: 0.9529\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0384 - f1_score: 0.9529 - val_loss: 0.0400 - val_f1_score: 0.9529\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0374 - f1_score: 0.9529 - val_loss: 0.0380 - val_f1_score: 0.9529\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0359 - f1_score: 0.9529 - val_loss: 0.0373 - val_f1_score: 0.9529\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0348 - f1_score: 0.9529 - val_loss: 0.0363 - val_f1_score: 0.9529\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0340 - f1_score: 0.9529 - val_loss: 0.0355 - val_f1_score: 0.9529\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0329 - f1_score: 0.9529 - val_loss: 0.0340 - val_f1_score: 0.9529\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0321 - f1_score: 0.9529 - val_loss: 0.0341 - val_f1_score: 0.9529\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0315 - f1_score: 0.9529 - val_loss: 0.0338 - val_f1_score: 0.9529\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0314 - f1_score: 0.9529 - val_loss: 0.0336 - val_f1_score: 0.9529\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0309 - f1_score: 0.9529 - val_loss: 0.0319 - val_f1_score: 0.9529\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0302 - f1_score: 0.9529 - val_loss: 0.0316 - val_f1_score: 0.9529\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0299 - f1_score: 0.9529 - val_loss: 0.0374 - val_f1_score: 0.9529\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0308 - f1_score: 0.9529 - val_loss: 0.0313 - val_f1_score: 0.9529\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0294 - f1_score: 0.9529 - val_loss: 0.0319 - val_f1_score: 0.9529\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0288 - f1_score: 0.9529 - val_loss: 0.0306 - val_f1_score: 0.9529\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0288 - f1_score: 0.9529 - val_loss: 0.0313 - val_f1_score: 0.9529\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0286 - f1_score: 0.9529 - val_loss: 0.0301 - val_f1_score: 0.9529\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0279 - f1_score: 0.9529 - val_loss: 0.0301 - val_f1_score: 0.9529\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0282 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9529\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0275 - f1_score: 0.9529 - val_loss: 0.0302 - val_f1_score: 0.9529\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0276 - f1_score: 0.9529 - val_loss: 0.0296 - val_f1_score: 0.9529\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0269 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9529\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0272 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9529\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0271 - f1_score: 0.9529 - val_loss: 0.0297 - val_f1_score: 0.9529\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0297 - val_f1_score: 0.9529\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0269 - f1_score: 0.9529 - val_loss: 0.0381 - val_f1_score: 0.9529\n",
      "fold: 3\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0412 - f1_score: 0.9529 - val_loss: 0.0409 - val_f1_score: 0.9530\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0397 - f1_score: 0.9529 - val_loss: 0.0406 - val_f1_score: 0.9530\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0389 - f1_score: 0.9529 - val_loss: 0.0394 - val_f1_score: 0.9530\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0377 - f1_score: 0.9529 - val_loss: 0.0386 - val_f1_score: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0362 - f1_score: 0.9529 - val_loss: 0.0374 - val_f1_score: 0.9530\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0351 - f1_score: 0.9529 - val_loss: 0.0383 - val_f1_score: 0.9530\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0345 - f1_score: 0.9529 - val_loss: 0.0351 - val_f1_score: 0.9530\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0329 - f1_score: 0.9529 - val_loss: 0.0351 - val_f1_score: 0.9530\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0325 - f1_score: 0.9529 - val_loss: 0.0344 - val_f1_score: 0.9530\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0321 - f1_score: 0.9529 - val_loss: 0.0341 - val_f1_score: 0.9530\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0310 - f1_score: 0.9529 - val_loss: 0.0333 - val_f1_score: 0.9530\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0306 - f1_score: 0.9529 - val_loss: 0.0328 - val_f1_score: 0.9530\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0298 - f1_score: 0.9529 - val_loss: 0.0352 - val_f1_score: 0.9530\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0300 - f1_score: 0.9529 - val_loss: 0.0335 - val_f1_score: 0.9530\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0292 - f1_score: 0.9529 - val_loss: 0.0324 - val_f1_score: 0.9530\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0287 - f1_score: 0.9529 - val_loss: 0.0315 - val_f1_score: 0.9530\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0284 - f1_score: 0.9529 - val_loss: 0.0312 - val_f1_score: 0.9530\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0285 - f1_score: 0.9529 - val_loss: 0.0325 - val_f1_score: 0.9530\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0285 - f1_score: 0.9529 - val_loss: 0.0308 - val_f1_score: 0.9530\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0275 - f1_score: 0.9529 - val_loss: 0.0308 - val_f1_score: 0.9530\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0279 - f1_score: 0.9529 - val_loss: 0.0318 - val_f1_score: 0.9530\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0284 - f1_score: 0.9529 - val_loss: 0.0330 - val_f1_score: 0.9530\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0274 - f1_score: 0.9529 - val_loss: 0.0303 - val_f1_score: 0.9530\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9530\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0271 - f1_score: 0.9529 - val_loss: 0.0307 - val_f1_score: 0.9530\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0264 - f1_score: 0.9529 - val_loss: 0.0314 - val_f1_score: 0.9530\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0265 - f1_score: 0.9529 - val_loss: 0.0306 - val_f1_score: 0.9530\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0260 - f1_score: 0.9529 - val_loss: 0.0305 - val_f1_score: 0.9530\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X_train.shape[1],[100,50,50])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds / 3\n",
    "    train_preds[test_index] += model.predict(X_valid).reshape(X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'simple_nn'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0406 - f1_score: 0.9529 - val_loss: 0.0410 - val_f1_score: 0.9529\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0397 - f1_score: 0.9529 - val_loss: 0.0396 - val_f1_score: 0.9529\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0397 - f1_score: 0.9529 - val_loss: 0.0390 - val_f1_score: 0.9529\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0384 - f1_score: 0.9529 - val_loss: 0.0378 - val_f1_score: 0.9529\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0371 - f1_score: 0.9529 - val_loss: 0.0369 - val_f1_score: 0.9529\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0362 - f1_score: 0.9529 - val_loss: 0.0372 - val_f1_score: 0.9529\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0348 - f1_score: 0.9529 - val_loss: 0.0351 - val_f1_score: 0.9529\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0338 - f1_score: 0.9529 - val_loss: 0.0344 - val_f1_score: 0.9529\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0330 - f1_score: 0.9529 - val_loss: 0.0375 - val_f1_score: 0.9529\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0319 - f1_score: 0.9529 - val_loss: 0.0359 - val_f1_score: 0.9529\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0321 - f1_score: 0.9529 - val_loss: 0.0377 - val_f1_score: 0.9529\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0313 - f1_score: 0.9529 - val_loss: 0.0336 - val_f1_score: 0.9529\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0312 - f1_score: 0.9529 - val_loss: 0.0353 - val_f1_score: 0.9529\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0310 - f1_score: 0.9529 - val_loss: 0.0361 - val_f1_score: 0.9529\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0299 - f1_score: 0.9529 - val_loss: 0.0333 - val_f1_score: 0.9529\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0293 - f1_score: 0.9529 - val_loss: 0.0352 - val_f1_score: 0.9529\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0286 - f1_score: 0.9529 - val_loss: 0.0377 - val_f1_score: 0.9529\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0299 - f1_score: 0.9529 - val_loss: 0.0331 - val_f1_score: 0.9529\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0324 - val_f1_score: 0.9529\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0299 - f1_score: 0.9529 - val_loss: 0.0322 - val_f1_score: 0.9529\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0275 - f1_score: 0.9529 - val_loss: 0.0346 - val_f1_score: 0.9529\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0273 - f1_score: 0.9529 - val_loss: 0.0326 - val_f1_score: 0.9529\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0285 - f1_score: 0.9529 - val_loss: 0.0387 - val_f1_score: 0.9529\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0323 - val_f1_score: 0.9529\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0344 - val_f1_score: 0.9529\n",
      "fold: 2\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0404 - f1_score: 0.9529 - val_loss: 0.0421 - val_f1_score: 0.9529\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0397 - f1_score: 0.9529 - val_loss: 0.0405 - val_f1_score: 0.9529\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0386 - f1_score: 0.9529 - val_loss: 0.0388 - val_f1_score: 0.9529\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0376 - f1_score: 0.9529 - val_loss: 0.0376 - val_f1_score: 0.9529\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0367 - f1_score: 0.9529 - val_loss: 0.0404 - val_f1_score: 0.9529\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0367 - f1_score: 0.9529 - val_loss: 0.0401 - val_f1_score: 0.9529\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0365 - f1_score: 0.9529 - val_loss: 0.0379 - val_f1_score: 0.9529\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0357 - f1_score: 0.9529 - val_loss: 0.0384 - val_f1_score: 0.9529\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0350 - f1_score: 0.9529 - val_loss: 0.0353 - val_f1_score: 0.9529\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0333 - f1_score: 0.9529 - val_loss: 0.0339 - val_f1_score: 0.9529\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0329 - f1_score: 0.9529 - val_loss: 0.0330 - val_f1_score: 0.9529\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0319 - f1_score: 0.9529 - val_loss: 0.0349 - val_f1_score: 0.9529\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0320 - f1_score: 0.9529 - val_loss: 0.0319 - val_f1_score: 0.9529\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0308 - f1_score: 0.9529 - val_loss: 0.0329 - val_f1_score: 0.9529\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0332 - f1_score: 0.9529 - val_loss: 0.0320 - val_f1_score: 0.9529\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0307 - f1_score: 0.9529 - val_loss: 0.0315 - val_f1_score: 0.9529\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0303 - f1_score: 0.9529 - val_loss: 0.0330 - val_f1_score: 0.9529\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0307 - f1_score: 0.9529 - val_loss: 0.0371 - val_f1_score: 0.9529\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0314 - f1_score: 0.9529 - val_loss: 0.0339 - val_f1_score: 0.9529\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0297 - f1_score: 0.9529 - val_loss: 0.0333 - val_f1_score: 0.9529\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0297 - f1_score: 0.9529 - val_loss: 0.0308 - val_f1_score: 0.9529\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0287 - f1_score: 0.9529 - val_loss: 0.0300 - val_f1_score: 0.9529\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0290 - f1_score: 0.9529 - val_loss: 0.0317 - val_f1_score: 0.9529\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0303 - f1_score: 0.9529 - val_loss: 0.0335 - val_f1_score: 0.9529\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0284 - f1_score: 0.9529 - val_loss: 0.0294 - val_f1_score: 0.9529\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0282 - f1_score: 0.9529 - val_loss: 0.0305 - val_f1_score: 0.9529\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0280 - f1_score: 0.9529 - val_loss: 0.0315 - val_f1_score: 0.9529\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0278 - f1_score: 0.9529 - val_loss: 0.0287 - val_f1_score: 0.9529\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - f1_score: 0.9529 - val_loss: 0.0290 - val_f1_score: 0.9529\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0272 - f1_score: 0.9529 - val_loss: 0.0286 - val_f1_score: 0.9529\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0270 - f1_score: 0.9529 - val_loss: 0.0291 - val_f1_score: 0.9529\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9529\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0275 - f1_score: 0.9529 - val_loss: 0.0286 - val_f1_score: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - f1_score: 0.9529 - val_loss: 0.0286 - val_f1_score: 0.9529\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0271 - f1_score: 0.9529 - val_loss: 0.0383 - val_f1_score: 0.9529\n",
      "fold: 3\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0444 - f1_score: 0.9529 - val_loss: 0.0410 - val_f1_score: 0.9530\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0402 - f1_score: 0.9529 - val_loss: 0.0408 - val_f1_score: 0.9530\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0396 - f1_score: 0.9529 - val_loss: 0.0403 - val_f1_score: 0.9530\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0385 - f1_score: 0.9529 - val_loss: 0.0392 - val_f1_score: 0.9530\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0377 - f1_score: 0.9529 - val_loss: 0.0377 - val_f1_score: 0.9530\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0361 - f1_score: 0.9529 - val_loss: 0.0385 - val_f1_score: 0.9530\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0356 - f1_score: 0.9529 - val_loss: 0.0364 - val_f1_score: 0.9530\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0343 - f1_score: 0.9529 - val_loss: 0.0350 - val_f1_score: 0.9530\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0331 - f1_score: 0.9529 - val_loss: 0.0347 - val_f1_score: 0.9530\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0327 - f1_score: 0.9529 - val_loss: 0.0346 - val_f1_score: 0.9530\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0326 - f1_score: 0.9529 - val_loss: 0.0336 - val_f1_score: 0.9530\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0320 - f1_score: 0.9529 - val_loss: 0.0338 - val_f1_score: 0.9530\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0317 - f1_score: 0.9529 - val_loss: 0.0327 - val_f1_score: 0.9530\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0307 - f1_score: 0.9529 - val_loss: 0.0345 - val_f1_score: 0.9530\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0314 - f1_score: 0.9529 - val_loss: 0.0333 - val_f1_score: 0.9530\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0301 - f1_score: 0.9529 - val_loss: 0.0322 - val_f1_score: 0.9530\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0295 - f1_score: 0.9529 - val_loss: 0.0307 - val_f1_score: 0.9530\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0294 - f1_score: 0.9529 - val_loss: 0.0304 - val_f1_score: 0.9530\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0297 - f1_score: 0.9529 - val_loss: 0.0331 - val_f1_score: 0.9530\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0292 - f1_score: 0.9529 - val_loss: 0.0323 - val_f1_score: 0.9530\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0295 - f1_score: 0.9529 - val_loss: 0.0306 - val_f1_score: 0.9530\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0281 - f1_score: 0.9529 - val_loss: 0.0300 - val_f1_score: 0.9530\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0276 - f1_score: 0.9529 - val_loss: 0.0298 - val_f1_score: 0.9530\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0282 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9530\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0286 - f1_score: 0.9529 - val_loss: 0.0302 - val_f1_score: 0.9530\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0274 - f1_score: 0.9529 - val_loss: 0.0319 - val_f1_score: 0.9530\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0272 - f1_score: 0.9529 - val_loss: 0.0299 - val_f1_score: 0.9530\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.0266 - f1_score: 0.9529 - val_loss: 0.0313 - val_f1_score: 0.9530\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X_train.shape[1],[100,50,50])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds / 3\n",
    "    train_preds[test_index] += model.predict(X_valid).reshape(X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'simple_nn_with_linear_predictions'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "STEPS_PER_EPOCH = 3400//BATCH_SIZE\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "      0.001,\n",
    "      decay_steps=STEPS_PER_EPOCH*1000,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "\n",
    "def get_log_dir(model):\n",
    "    model_name = '-'.join(map(lambda x: str(x),model))\n",
    "    return f'./logs/{model_name}'\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_combined_model(fare_model, duration_model, meter_waiting_model, meter_waiting_fare_model, model_def=[100,50], freeze_input=True):\n",
    "    if freeze_input:\n",
    "        fare_model.trainable = False\n",
    "        duration_model.trainable = False\n",
    "        meter_waiting_model.trainable = False\n",
    "        meter_waiting_fare_model.trainable = False\n",
    "    \n",
    "    fare_input = Input(shape=(fare_model.input.shape[1],), name='fare_input')\n",
    "    fare = fare_model(fare_input)\n",
    "    \n",
    "    duration_input = Input(shape=(duration_model.input.shape[1],), name='duration_input')\n",
    "    duration = fare_model(duration_input)\n",
    "    \n",
    "    meter_waiting_input = Input(shape=(meter_waiting_model.input.shape[1],), name='meter_waiting_input')\n",
    "    meter_waiting = fare_model(meter_waiting_input)\n",
    "    \n",
    "    meter_waiting_fare_input = Input(shape=(meter_waiting_fare_model.input.shape[1],), name='meter_waiting_fare_input')\n",
    "    meter_waiting_fare = fare_model(meter_waiting_fare_input)\n",
    "    \n",
    "    X = concatenate([fare,duration,meter_waiting,meter_waiting_fare])\n",
    "    \n",
    "    for nodes in model_def:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model([fare_input,duration_input,meter_waiting_input,meter_waiting_fare_input],output_layer)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule), \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "fare_representation = tf.keras.models.load_model('models/fare_representation')\n",
    "duration_representation = tf.keras.models.load_model('models/duration_representation')\n",
    "meter_waiting_representation = tf.keras.models.load_model('models/meter_waiting_representation')\n",
    "meter_waiting_fare_representation = tf.keras.models.load_model('models/meter_waiting_fare_representation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference'\n",
    "]\n",
    "\n",
    "fare_features = ['additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "duration_features = ['additional_fare', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_features = ['additional_fare', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_fare_features = ['additional_fare', \n",
    "    'meter_waiting',    \n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])\n",
    "\n",
    "train = train_df.copy()\n",
    "train[features] = X_scale\n",
    "\n",
    "test = test_df.copy()\n",
    "test[features] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Epoch 1/500\n",
      "23/23 [==============================] - 1s 42ms/step - loss: 0.1081 - f1_score: 0.9530 - val_loss: 0.1236 - val_f1_score: 0.9532\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0592 - f1_score: 0.9530 - val_loss: 0.0579 - val_f1_score: 0.9531\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0417 - f1_score: 0.9529 - val_loss: 0.0368 - val_f1_score: 0.9529\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0365 - f1_score: 0.9529 - val_loss: 0.0359 - val_f1_score: 0.9529\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0353 - f1_score: 0.9529 - val_loss: 0.0346 - val_f1_score: 0.9529\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0324 - f1_score: 0.9529 - val_loss: 0.0445 - val_f1_score: 0.9529\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0334 - f1_score: 0.9529 - val_loss: 0.0503 - val_f1_score: 0.9529\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0342 - f1_score: 0.9529 - val_loss: 0.0338 - val_f1_score: 0.9529\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0302 - f1_score: 0.9529 - val_loss: 0.0584 - val_f1_score: 0.9529\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0345 - f1_score: 0.9530 - val_loss: 0.0315 - val_f1_score: 0.9529\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0284 - f1_score: 0.9530 - val_loss: 0.0293 - val_f1_score: 0.9529\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.0282 - f1_score: 0.9530 - val_loss: 0.0292 - val_f1_score: 0.9529\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.0296 - f1_score: 0.9530 - val_loss: 0.0410 - val_f1_score: 0.9529\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 1s 40ms/step - loss: 0.0309 - f1_score: 0.9530 - val_loss: 0.0325 - val_f1_score: 0.9529\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0281 - f1_score: 0.9529 - val_loss: 0.0294 - val_f1_score: 0.9529\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.0270 - f1_score: 0.9530 - val_loss: 0.0270 - val_f1_score: 0.9529\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.0259 - f1_score: 0.9530 - val_loss: 0.0324 - val_f1_score: 0.9529\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.0281 - f1_score: 0.9529 - val_loss: 0.0392 - val_f1_score: 0.9529\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0289 - f1_score: 0.9529 - val_loss: 0.0298 - val_f1_score: 0.9529\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0255 - f1_score: 0.9530 - val_loss: 0.0280 - val_f1_score: 0.9529\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0254 - f1_score: 0.9529 - val_loss: 0.0288 - val_f1_score: 0.9529\n",
      "fold: 2\n",
      "Epoch 1/500\n",
      "23/23 [==============================] - 1s 37ms/step - loss: 0.1467 - f1_score: 0.9530 - val_loss: 0.1303 - val_f1_score: 0.9529\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0667 - f1_score: 0.9529 - val_loss: 0.1397 - val_f1_score: 0.9531\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0819 - f1_score: 0.9530 - val_loss: 0.0453 - val_f1_score: 0.9529\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0429 - f1_score: 0.9529 - val_loss: 0.0424 - val_f1_score: 0.9529\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0362 - f1_score: 0.9529 - val_loss: 0.0321 - val_f1_score: 0.9529\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0336 - f1_score: 0.9530 - val_loss: 0.0333 - val_f1_score: 0.9530\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0346 - f1_score: 0.9530 - val_loss: 0.0350 - val_f1_score: 0.9529\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0341 - f1_score: 0.9529 - val_loss: 0.0383 - val_f1_score: 0.9529\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0334 - f1_score: 0.9530 - val_loss: 0.0293 - val_f1_score: 0.9529\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0318 - f1_score: 0.9530 - val_loss: 0.0387 - val_f1_score: 0.9531\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0333 - f1_score: 0.9530 - val_loss: 0.0298 - val_f1_score: 0.9529\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0305 - f1_score: 0.9530 - val_loss: 0.0295 - val_f1_score: 0.9529\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0301 - f1_score: 0.9530 - val_loss: 0.0257 - val_f1_score: 0.9530\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0291 - f1_score: 0.9530 - val_loss: 0.0297 - val_f1_score: 0.9530\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0302 - f1_score: 0.9529 - val_loss: 0.0274 - val_f1_score: 0.9531\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0289 - f1_score: 0.9531 - val_loss: 0.0270 - val_f1_score: 0.9530\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0284 - f1_score: 0.9531 - val_loss: 0.0274 - val_f1_score: 0.9531\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0283 - f1_score: 0.9530 - val_loss: 0.0242 - val_f1_score: 0.9529\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0262 - f1_score: 0.9530 - val_loss: 0.0241 - val_f1_score: 0.9529\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0269 - f1_score: 0.9530 - val_loss: 0.0394 - val_f1_score: 0.9529\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0323 - f1_score: 0.9530 - val_loss: 0.0278 - val_f1_score: 0.9529\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0287 - f1_score: 0.9531 - val_loss: 0.0285 - val_f1_score: 0.9529\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0274 - f1_score: 0.9530 - val_loss: 0.0229 - val_f1_score: 0.9531\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0261 - f1_score: 0.9530 - val_loss: 0.0247 - val_f1_score: 0.9529\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.0252 - f1_score: 0.9530 - val_loss: 0.0219 - val_f1_score: 0.9529\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0253 - f1_score: 0.9529 - val_loss: 0.0271 - val_f1_score: 0.9529\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0253 - f1_score: 0.9530 - val_loss: 0.0253 - val_f1_score: 0.9530\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0267 - f1_score: 0.9530 - val_loss: 0.0287 - val_f1_score: 0.9529\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0284 - f1_score: 0.9530 - val_loss: 0.0250 - val_f1_score: 0.9529\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0254 - f1_score: 0.9529 - val_loss: 0.0225 - val_f1_score: 0.9529\n",
      "fold: 3\n",
      "Epoch 1/500\n",
      "23/23 [==============================] - 1s 41ms/step - loss: 0.2272 - f1_score: 0.9529 - val_loss: 0.1115 - val_f1_score: 0.9530\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0952 - f1_score: 0.9529 - val_loss: 0.1839 - val_f1_score: 0.9530\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1057 - f1_score: 0.9529 - val_loss: 0.0505 - val_f1_score: 0.9530\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0514 - f1_score: 0.9529 - val_loss: 0.0742 - val_f1_score: 0.9530\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.0448 - f1_score: 0.9529 - val_loss: 0.0415 - val_f1_score: 0.9530\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0363 - f1_score: 0.9529 - val_loss: 0.0390 - val_f1_score: 0.9530\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0350 - f1_score: 0.9529 - val_loss: 0.0328 - val_f1_score: 0.9530\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0320 - f1_score: 0.9529 - val_loss: 0.0315 - val_f1_score: 0.9531\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0312 - f1_score: 0.9529 - val_loss: 0.0410 - val_f1_score: 0.9531\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0443 - f1_score: 0.9530 - val_loss: 0.0345 - val_f1_score: 0.9530\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0314 - f1_score: 0.9529 - val_loss: 0.0313 - val_f1_score: 0.9531\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0298 - f1_score: 0.9529 - val_loss: 0.0356 - val_f1_score: 0.9531\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0324 - f1_score: 0.9529 - val_loss: 0.0370 - val_f1_score: 0.9531\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0315 - f1_score: 0.9529 - val_loss: 0.0309 - val_f1_score: 0.9531\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0288 - f1_score: 0.9529 - val_loss: 0.0317 - val_f1_score: 0.9531\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0306 - val_f1_score: 0.9531\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0313 - f1_score: 0.9529 - val_loss: 0.0312 - val_f1_score: 0.9530\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0283 - f1_score: 0.9529 - val_loss: 0.0329 - val_f1_score: 0.9530\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0275 - f1_score: 0.9530 - val_loss: 0.0285 - val_f1_score: 0.9530\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0259 - f1_score: 0.9529 - val_loss: 0.0312 - val_f1_score: 0.9530\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0269 - f1_score: 0.9529 - val_loss: 0.0273 - val_f1_score: 0.9530\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0270 - f1_score: 0.9530 - val_loss: 0.0288 - val_f1_score: 0.9530\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0254 - f1_score: 0.9529 - val_loss: 0.0302 - val_f1_score: 0.9531\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0241 - f1_score: 0.9529 - val_loss: 0.0278 - val_f1_score: 0.9531\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0239 - f1_score: 0.9529 - val_loss: 0.0357 - val_f1_score: 0.9531\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0251 - f1_score: 0.9529 - val_loss: 0.0293 - val_f1_score: 0.9530\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "model_def=(400, 800, 400, 100, 50, 20, 10)\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_fare_train, X_fare_test = train[fare_features].iloc[train_index,:],train[fare_features].iloc[test_index,:]\n",
    "    X_duration_train, X_duration_test = train[duration_features].iloc[train_index,:],train[duration_features].iloc[test_index,:]\n",
    "    X_meter_waiting_train, X_meter_waiting_test = train[meter_waiting_features].iloc[train_index,:],train[meter_waiting_features].iloc[test_index,:]\n",
    "    X_meter_waiting_fare_train, X_meter_waiting_fare_test = train[meter_waiting_fare_features].iloc[train_index,:],train[meter_waiting_fare_features].iloc[test_index,:]\n",
    "    \n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_combined_model(fare_representation,\n",
    "                           duration_representation,\n",
    "                           meter_waiting_representation,\n",
    "                           meter_waiting_fare_representation,\n",
    "                           model_def=model_def)\n",
    "    model.fit({'fare_input':X_fare_train,\n",
    "              'duration_input':X_duration_train,\n",
    "              'meter_waiting_input':X_meter_waiting_train,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_train},\n",
    "              y_train,\n",
    "              batch_size=512,\n",
    "              epochs=500,\n",
    "              validation_data=({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test},y_valid),callbacks=callbacks)\n",
    "    y_hat = model.predict({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test}).reshape(y_valid.shape)\n",
    "    train_preds[test_index] = y_hat\n",
    " \n",
    "    X_fare, X_duration, X_meter_waiting,X_X_meter_waiting_fare = test[fare_features],test[duration_features],test[meter_waiting_features],test[meter_waiting_fare_features]\n",
    "    \n",
    "    preds = model.predict({'fare_input':X_fare,\n",
    "              'duration_input':X_duration,\n",
    "              'meter_waiting_input':X_meter_waiting,\n",
    "              'meter_waiting_fare_input':X_X_meter_waiting_fare}).reshape(test_preds.shape)\n",
    "    test_preds += preds/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'multihead_nn'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat,average='micro'), True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "train_X = train_df[features]\n",
    "test_X = test_df[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bagging_fraction': 0.7528277381788788,\n",
    "    'class_weight': None,\n",
    "    'feature_fraction': 0.5625261317624038,\n",
    "    'lambda_l2_positive': 0.01363014388342585,\n",
    "    'learning_rate': 0.11231814419878085,\n",
    "    'min_child_weight': 20.69211631593017,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'num_leaves': 86,\n",
    "    'subsample_for_bin': 60000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "test_preds = np.zeros(test_X.shape[0])\n",
    "train_preds = np.zeros(train_X.shape[0])\n",
    "for train_index, test_index in skf.split(train_df, y):\n",
    "    X_train, X_test = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train = lgb.Dataset(X_train,y_train)\n",
    "    valid = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test_X) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_all'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'fare',\n",
    "    'predicted_fare',\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'fare_per_distance',\n",
    "    'predicted_fare_per_distance', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duration',\n",
    "    'predicted_duration_diff', \n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'fare_per_duration',\n",
    "    'predicted_fare_per_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'avg_speed', \n",
    "    'predicted_avg_speed', \n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting', \n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'meter_waiting_per_duration', \n",
    "    'predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare', \n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare', \n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_per_fare', \n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'predicted_addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration', \n",
    "    'predicted_addtional_fare_per_duration',\n",
    "]\n",
    "train_X = train_df[features]\n",
    "test_X = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bagging_fraction': 0.9582184397618998,\n",
    "    'class_weight': 'balanced',\n",
    "    'feature_fraction': 0.6584730253641345,\n",
    "    'lambda_l1_positive': 0.004131014051823846,\n",
    "    'lambda_l2_positive': 2.021463074958273,\n",
    "    'learning_rate': 0.1292032123987036,\n",
    "    'min_child_weight': 27.329223863721854,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_leaves': 120,\n",
    "    'subsample_for_bin': 20000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "test_preds = np.zeros(test_X.shape[0])\n",
    "train_preds = np.zeros(train_X.shape[0])\n",
    "for train_index, test_index in skf.split(train_df, y):\n",
    "    X_train, X_test = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train = lgb.Dataset(X_train,y_train)\n",
    "    valid = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test_X) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_catfeatures'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f54f80a2290>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(model_predictions_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train.to_csv('stack_train.csv',index=False)\n",
    "model_predictions_test.to_csv('stack_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_predictions_test.columns\n",
    "cat_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9752535\ttest: 0.9784450\tbest: 0.9784450 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "10:\tlearn: 0.9755605\ttest: 0.9785921\tbest: 0.9785921 (10)\ttotal: 52.4ms\tremaining: 4.71s\n",
      "20:\tlearn: 0.9755722\ttest: 0.9782232\tbest: 0.9787931 (12)\ttotal: 90.2ms\tremaining: 4.2s\n",
      "30:\tlearn: 0.9759007\ttest: 0.9779235\tbest: 0.9787931 (12)\ttotal: 127ms\tremaining: 3.96s\n",
      "40:\tlearn: 0.9760770\ttest: 0.9779149\tbest: 0.9787931 (12)\ttotal: 163ms\tremaining: 3.81s\n",
      "50:\tlearn: 0.9761733\ttest: 0.9777264\tbest: 0.9787931 (12)\ttotal: 205ms\tremaining: 3.82s\n",
      "60:\tlearn: 0.9763635\ttest: 0.9774306\tbest: 0.9787931 (12)\ttotal: 254ms\tremaining: 3.91s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9787931367\n",
      "bestIteration = 12\n",
      "\n",
      "Shrink model to first 13 iterations.\n",
      "Validation f1 0.9787931366878735\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9724521\ttest: 0.9725559\tbest: 0.9725559 (0)\ttotal: 25.4ms\tremaining: 25.4s\n",
      "10:\tlearn: 0.9758938\ttest: 0.9787111\tbest: 0.9787152 (9)\ttotal: 84ms\tremaining: 7.55s\n",
      "20:\tlearn: 0.9760554\ttest: 0.9786333\tbest: 0.9787152 (9)\ttotal: 117ms\tremaining: 5.47s\n",
      "30:\tlearn: 0.9758961\ttest: 0.9784242\tbest: 0.9787152 (9)\ttotal: 153ms\tremaining: 4.77s\n",
      "40:\tlearn: 0.9760370\ttest: 0.9786127\tbest: 0.9787152 (9)\ttotal: 189ms\tremaining: 4.42s\n",
      "50:\tlearn: 0.9762271\ttest: 0.9786251\tbest: 0.9787152 (9)\ttotal: 256ms\tremaining: 4.77s\n",
      "60:\tlearn: 0.9762249\ttest: 0.9787357\tbest: 0.9787357 (59)\ttotal: 318ms\tremaining: 4.9s\n",
      "70:\tlearn: 0.9763726\ttest: 0.9783425\tbest: 0.9789241 (61)\ttotal: 357ms\tremaining: 4.68s\n",
      "80:\tlearn: 0.9764689\ttest: 0.9782357\tbest: 0.9789241 (61)\ttotal: 395ms\tremaining: 4.48s\n",
      "90:\tlearn: 0.9768964\ttest: 0.9778548\tbest: 0.9789241 (61)\ttotal: 435ms\tremaining: 4.34s\n",
      "100:\tlearn: 0.9770889\ttest: 0.9781626\tbest: 0.9789241 (61)\ttotal: 472ms\tremaining: 4.2s\n",
      "110:\tlearn: 0.9774697\ttest: 0.9782190\tbest: 0.9789241 (61)\ttotal: 512ms\tremaining: 4.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9789240689\n",
      "bestIteration = 61\n",
      "\n",
      "Shrink model to first 62 iterations.\n",
      "Validation f1 0.9789240689057839\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9786171\ttest: 0.9706248\tbest: 0.9706248 (0)\ttotal: 3.58ms\tremaining: 3.58s\n",
      "10:\tlearn: 0.9788665\ttest: 0.9717568\tbest: 0.9720307 (6)\ttotal: 37.9ms\tremaining: 3.41s\n",
      "20:\tlearn: 0.9788113\ttest: 0.9717514\tbest: 0.9720307 (6)\ttotal: 76.2ms\tremaining: 3.55s\n",
      "30:\tlearn: 0.9788993\ttest: 0.9718445\tbest: 0.9720307 (6)\ttotal: 112ms\tremaining: 3.49s\n",
      "40:\tlearn: 0.9793720\ttest: 0.9720307\tbest: 0.9720307 (6)\ttotal: 164ms\tremaining: 3.83s\n",
      "50:\tlearn: 0.9794603\ttest: 0.9720307\tbest: 0.9720307 (6)\ttotal: 232ms\tremaining: 4.31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9720306513\n",
      "bestIteration = 6\n",
      "\n",
      "Shrink model to first 7 iterations.\n",
      "Validation f1 0.9720306513409962\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.976582618978218, 0.003219170994646158)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>catboost_base_6_3.0</td>\n",
       "      <td>12.647012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>catboost_base_6_1.0</td>\n",
       "      <td>6.316308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>catboost_base_3_1.0</td>\n",
       "      <td>5.846901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>autoencoder_catboost_8_1.0</td>\n",
       "      <td>5.468975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>autoencoder_catboost_6_1.0</td>\n",
       "      <td>5.232470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>lgb_all</td>\n",
       "      <td>4.725591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>catboost_base_3_3.0</td>\n",
       "      <td>4.546237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>catboost_base_8_3.0</td>\n",
       "      <td>4.345538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>catboost_base_6_6.0</td>\n",
       "      <td>4.153760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>catboost_base_3_6.0</td>\n",
       "      <td>4.135317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>simple_nn</td>\n",
       "      <td>3.488011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>catboost_base_8_1.0</td>\n",
       "      <td>3.455618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>autoencoder_catboost_6_3.0</td>\n",
       "      <td>3.328285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>lgb_catfeatures</td>\n",
       "      <td>3.327731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>simple_nn_with_linear_predictions</td>\n",
       "      <td>3.022556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>multihead_nn</td>\n",
       "      <td>2.896878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>catboost_base_8_6.0</td>\n",
       "      <td>2.783318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>catboost_anomaly_3_6.0</td>\n",
       "      <td>2.600299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>autoencoder_catboost_8_3.0</td>\n",
       "      <td>1.959532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>autoencoder_catboost_8_6.0</td>\n",
       "      <td>1.927844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>catboost_anomaly_6_1.0</td>\n",
       "      <td>1.770845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>autoencoder_catboost_3_1.0</td>\n",
       "      <td>1.351496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>catboost_anomaly_3_3.0</td>\n",
       "      <td>1.255595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>autoencoder_catboost_3_6.0</td>\n",
       "      <td>1.195575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>catboost_anomaly_8_3.0</td>\n",
       "      <td>1.189449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>autoencoder_catboost_3_3.0</td>\n",
       "      <td>1.144368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>catboost_anomaly_8_6.0</td>\n",
       "      <td>1.143341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>autoencoder_catboost_6_6.0</td>\n",
       "      <td>1.094970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>catboost_anomaly_8_1.0</td>\n",
       "      <td>1.051093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>catboost_anomaly_3_1.0</td>\n",
       "      <td>0.953509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>catboost_anomaly_6_6.0</td>\n",
       "      <td>0.838023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>catboost_anomaly_6_3.0</td>\n",
       "      <td>0.803554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature Id  Importances\n",
       "0                 catboost_base_6_3.0    12.647012\n",
       "1                 catboost_base_6_1.0     6.316308\n",
       "2                 catboost_base_3_1.0     5.846901\n",
       "3          autoencoder_catboost_8_1.0     5.468975\n",
       "4          autoencoder_catboost_6_1.0     5.232470\n",
       "5                             lgb_all     4.725591\n",
       "6                 catboost_base_3_3.0     4.546237\n",
       "7                 catboost_base_8_3.0     4.345538\n",
       "8                 catboost_base_6_6.0     4.153760\n",
       "9                 catboost_base_3_6.0     4.135317\n",
       "10                          simple_nn     3.488011\n",
       "11                catboost_base_8_1.0     3.455618\n",
       "12         autoencoder_catboost_6_3.0     3.328285\n",
       "13                    lgb_catfeatures     3.327731\n",
       "14  simple_nn_with_linear_predictions     3.022556\n",
       "15                       multihead_nn     2.896878\n",
       "16                catboost_base_8_6.0     2.783318\n",
       "17             catboost_anomaly_3_6.0     2.600299\n",
       "18         autoencoder_catboost_8_3.0     1.959532\n",
       "19         autoencoder_catboost_8_6.0     1.927844\n",
       "20             catboost_anomaly_6_1.0     1.770845\n",
       "21         autoencoder_catboost_3_1.0     1.351496\n",
       "22             catboost_anomaly_3_3.0     1.255595\n",
       "23         autoencoder_catboost_3_6.0     1.195575\n",
       "24             catboost_anomaly_8_3.0     1.189449\n",
       "25         autoencoder_catboost_3_3.0     1.144368\n",
       "26             catboost_anomaly_8_6.0     1.143341\n",
       "27         autoencoder_catboost_6_6.0     1.094970\n",
       "28             catboost_anomaly_8_1.0     1.051093\n",
       "29             catboost_anomaly_3_1.0     0.953509\n",
       "30             catboost_anomaly_6_6.0     0.838023\n",
       "31             catboost_anomaly_6_3.0     0.803554"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 0.5, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "cat_features = []\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9729292\ttest: 0.9695417\tbest: 0.9695417 (0)\ttotal: 10.6ms\tremaining: 10.6s\n",
      "10:\tlearn: 0.9755441\ttest: 0.9785714\tbest: 0.9788095 (7)\ttotal: 68.8ms\tremaining: 6.19s\n",
      "20:\tlearn: 0.9761493\ttest: 0.9779022\tbest: 0.9788095 (7)\ttotal: 108ms\tremaining: 5.05s\n",
      "30:\tlearn: 0.9759523\ttest: 0.9779064\tbest: 0.9788095 (7)\ttotal: 140ms\tremaining: 4.36s\n",
      "40:\tlearn: 0.9761870\ttest: 0.9777135\tbest: 0.9788095 (7)\ttotal: 170ms\tremaining: 3.98s\n",
      "50:\tlearn: 0.9760862\ttest: 0.9777135\tbest: 0.9788095 (7)\ttotal: 203ms\tremaining: 3.77s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9788094779\n",
      "bestIteration = 7\n",
      "\n",
      "Shrink model to first 8 iterations.\n",
      "Validation f1 0.978809477942593\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9718214\ttest: 0.9701419\tbest: 0.9701419 (0)\ttotal: 3.46ms\tremaining: 3.46s\n",
      "10:\tlearn: 0.9753657\ttest: 0.9790385\tbest: 0.9796783 (4)\ttotal: 35ms\tremaining: 3.15s\n",
      "20:\tlearn: 0.9757599\ttest: 0.9784533\tbest: 0.9796783 (4)\ttotal: 66.8ms\tremaining: 3.11s\n",
      "30:\tlearn: 0.9755041\ttest: 0.9789241\tbest: 0.9796783 (4)\ttotal: 98.4ms\tremaining: 3.07s\n",
      "40:\tlearn: 0.9755369\ttest: 0.9788217\tbest: 0.9796783 (4)\ttotal: 149ms\tremaining: 3.48s\n",
      "50:\tlearn: 0.9757319\ttest: 0.9790183\tbest: 0.9796783 (4)\ttotal: 186ms\tremaining: 3.45s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9796783203\n",
      "bestIteration = 4\n",
      "\n",
      "Shrink model to first 5 iterations.\n",
      "Validation f1 0.9796783203313107\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9764460\ttest: 0.9729364\tbest: 0.9729364 (0)\ttotal: 3.62ms\tremaining: 3.61s\n",
      "10:\tlearn: 0.9788993\ttest: 0.9718337\tbest: 0.9735827 (1)\ttotal: 34.1ms\tremaining: 3.06s\n",
      "20:\tlearn: 0.9785391\ttest: 0.9717298\tbest: 0.9735827 (1)\ttotal: 64.5ms\tremaining: 3s\n",
      "30:\tlearn: 0.9785821\ttest: 0.9720199\tbest: 0.9735827 (1)\ttotal: 98.4ms\tremaining: 3.08s\n",
      "40:\tlearn: 0.9787214\ttest: 0.9719268\tbest: 0.9735827 (1)\ttotal: 147ms\tremaining: 3.43s\n",
      "50:\tlearn: 0.9789651\ttest: 0.9720199\tbest: 0.9735827 (1)\ttotal: 179ms\tremaining: 3.33s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9735827227\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Validation f1 0.973582722715002\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9773568403296352, 0.002692173174336035)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>catboost_base_6_3.0</td>\n",
       "      <td>48.495452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lgb_catfeatures</td>\n",
       "      <td>21.102987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lgb_all</td>\n",
       "      <td>18.975519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>catboost_base_3_1.0</td>\n",
       "      <td>5.543193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>simple_nn_with_linear_predictions</td>\n",
       "      <td>4.197247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>multihead_nn</td>\n",
       "      <td>0.973950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>autoencoder_catboost_8_1.0</td>\n",
       "      <td>0.711653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>simple_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>catboost_anomaly_3_6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature Id  Importances\n",
       "0                catboost_base_6_3.0    48.495452\n",
       "1                    lgb_catfeatures    21.102987\n",
       "2                            lgb_all    18.975519\n",
       "3                catboost_base_3_1.0     5.543193\n",
       "4  simple_nn_with_linear_predictions     4.197247\n",
       "5                       multihead_nn     0.973950\n",
       "6         autoencoder_catboost_8_1.0     0.711653\n",
       "7                          simple_nn     0.000000\n",
       "8             catboost_anomaly_3_6.0     0.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>catboost_base_6_3.0</td>\n",
       "      <td>50.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lgb_catfeatures</td>\n",
       "      <td>37.208726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>simple_nn_with_linear_predictions</td>\n",
       "      <td>8.424649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>multihead_nn</td>\n",
       "      <td>4.086892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>catboost_base_3_1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>autoencoder_catboost_8_1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>lgb_all</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>simple_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>catboost_anomaly_3_6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature Id  Importances\n",
       "0                catboost_base_6_3.0    50.279733\n",
       "1                    lgb_catfeatures    37.208726\n",
       "2  simple_nn_with_linear_predictions     8.424649\n",
       "3                       multihead_nn     4.086892\n",
       "4                catboost_base_3_1.0     0.000000\n",
       "5         autoencoder_catboost_8_1.0     0.000000\n",
       "6                            lgb_all     0.000000\n",
       "7                          simple_nn     0.000000\n",
       "8             catboost_anomaly_3_6.0     0.000000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_model = models[np.argmin(validation_scores)]\n",
    "worst_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1238pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 1237.77 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 1233.7739,-301 1233.7739,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"614.887\" cy=\"-279\" rx=\"198.4651\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.887\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">simple_nn_with_linear_predictions, value&gt;0.772813</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.206095</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M582.9416,-261.1843C558.701,-247.6655 525.2147,-228.9905 499.1422,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"500.6949,-211.3085 490.2565,-209.4946 497.2854,-217.4221 500.6949,-211.3085\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.387\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.206095</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M646.8323,-261.1843C671.0729,-247.6655 704.5592,-228.9905 730.6317,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"732.4885,-217.4221 739.5174,-209.4946 729.079,-211.3085 732.4885,-217.4221\"/>\n",
       "<text text-anchor=\"middle\" x=\"713.887\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"146.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401.2978,-175.9415C348.8925,-161.3285 271.4441,-139.7323 215.7769,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.5682,-120.7969 205.9956,-121.4822 214.688,-127.5397 216.5682,-120.7969\"/>\n",
       "<text text-anchor=\"middle\" x=\"330.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M458.887,-173.9735C458.887,-162.1918 458.887,-146.5607 458.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.3871,-133.0033 458.887,-123.0034 455.3871,-133.0034 462.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M770.887,-173.9735C770.887,-162.1918 770.887,-146.5607 770.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"774.3871,-133.0033 770.887,-123.0034 767.3871,-133.0034 774.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"779.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1082.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1082.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M828.4762,-175.9415C880.8815,-161.3285 958.3298,-139.7323 1013.997,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1015.0859,-127.5397 1023.7783,-121.4822 1013.2057,-120.7969 1015.0859,-127.5397\"/>\n",
       "<text text-anchor=\"middle\" x=\"956.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"138.887,-36 54.887,-36 54.887,0 138.887,0 138.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.139</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136.5269,-86.9735C129.5547,-74.8418 120.2368,-58.6287 112.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.2512,-42.9295 107.2337,-36.0034 109.1821,-46.4175 115.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"236.887,-36 156.887,-36 156.887,0 236.887,0 236.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.000</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M157.247,-86.9735C164.2193,-74.8418 173.5372,-58.6287 181.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5919,-46.4175 186.5402,-36.0034 178.5228,-42.9295 184.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"450.887,-36 366.887,-36 366.887,0 450.887,0 450.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.013</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M448.5269,-86.9735C441.5547,-74.8418 432.2368,-58.6287 424.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.2512,-42.9295 419.2337,-36.0034 421.1821,-46.4175 427.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"445.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"548.887,-36 468.887,-36 468.887,0 548.887,0 548.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"508.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.211</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M469.247,-86.9735C476.2193,-74.8418 485.5372,-58.6287 493.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"496.5919,-46.4175 498.5402,-36.0034 490.5228,-42.9295 496.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"762.887,-36 678.887,-36 678.887,0 762.887,0 762.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"720.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.032</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M760.5269,-86.9735C753.5547,-74.8418 744.2368,-58.6287 736.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"739.2512,-42.9295 731.2337,-36.0034 733.1821,-46.4175 739.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"860.887,-36 780.887,-36 780.887,0 860.887,0 860.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.000</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M781.247,-86.9735C788.2193,-74.8418 797.5372,-58.6287 805.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"808.5919,-46.4175 810.5402,-36.0034 802.5228,-42.9295 808.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"809.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1073.887,-36 993.887,-36 993.887,0 1073.887,0 1073.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1033.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.023</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1072.7341,-86.9735C1065.9013,-74.8418 1056.7698,-58.6287 1049.0769,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.9838,-42.9989 1044.0268,-36.0034 1045.8846,-46.4341 1051.9838,-42.9989\"/>\n",
       "<text text-anchor=\"middle\" x=\"1070.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1171.887,-36 1091.887,-36 1091.887,0 1171.887,0 1171.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1131.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.328</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1093.0398,-86.9735C1099.8726,-74.8418 1109.0041,-58.6287 1116.6971,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1119.8893,-46.4341 1121.7471,-36.0034 1113.7901,-42.9989 1119.8893,-46.4341\"/>\n",
       "<text text-anchor=\"middle\" x=\"1120.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f07c86714d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1238pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 1237.77 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 1233.7739,-301 1233.7739,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"614.887\" cy=\"-279\" rx=\"193.8658\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.887\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">simple_nn_with_linear_predictions, value&gt;0.80114</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.968647</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M582.9416,-261.1843C558.701,-247.6655 525.2147,-228.9905 499.1422,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"500.6949,-211.3085 490.2565,-209.4946 497.2854,-217.4221 500.6949,-211.3085\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.387\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.968647</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M646.8323,-261.1843C671.0729,-247.6655 704.5592,-228.9905 730.6317,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"732.4885,-217.4221 739.5174,-209.4946 729.079,-211.3085 732.4885,-217.4221\"/>\n",
       "<text text-anchor=\"middle\" x=\"713.887\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"146.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.750846</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401.2978,-175.9415C348.8925,-161.3285 271.4441,-139.7323 215.7769,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.5682,-120.7969 205.9956,-121.4822 214.688,-127.5397 216.5682,-120.7969\"/>\n",
       "<text text-anchor=\"middle\" x=\"330.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.750846</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M458.887,-173.9735C458.887,-162.1918 458.887,-146.5607 458.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.3871,-133.0033 458.887,-123.0034 455.3871,-133.0034 462.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.750846</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M770.887,-173.9735C770.887,-162.1918 770.887,-146.5607 770.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"774.3871,-133.0033 770.887,-123.0034 767.3871,-133.0034 774.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"779.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1082.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1082.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.750846</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M828.4762,-175.9415C880.8815,-161.3285 958.3298,-139.7323 1013.997,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1015.0859,-127.5397 1023.7783,-121.4822 1013.2057,-120.7969 1015.0859,-127.5397\"/>\n",
       "<text text-anchor=\"middle\" x=\"956.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"138.887,-36 54.887,-36 54.887,0 138.887,0 138.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.067</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136.5269,-86.9735C129.5547,-74.8418 120.2368,-58.6287 112.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.2512,-42.9295 107.2337,-36.0034 109.1821,-46.4175 115.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"236.887,-36 156.887,-36 156.887,0 236.887,0 236.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.171</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M157.247,-86.9735C164.2193,-74.8418 173.5372,-58.6287 181.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5919,-46.4175 186.5402,-36.0034 178.5228,-42.9295 184.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"450.887,-36 366.887,-36 366.887,0 450.887,0 450.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.035</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M448.5269,-86.9735C441.5547,-74.8418 432.2368,-58.6287 424.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.2512,-42.9295 419.2337,-36.0034 421.1821,-46.4175 427.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"445.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"548.887,-36 468.887,-36 468.887,0 548.887,0 548.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"508.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.243</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M469.247,-86.9735C476.2193,-74.8418 485.5372,-58.6287 493.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"496.5919,-46.4175 498.5402,-36.0034 490.5228,-42.9295 496.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"762.887,-36 678.887,-36 678.887,0 762.887,0 762.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"720.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.035</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M760.5269,-86.9735C753.5547,-74.8418 744.2368,-58.6287 736.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"739.2512,-42.9295 731.2337,-36.0034 733.1821,-46.4175 739.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"860.887,-36 780.887,-36 780.887,0 860.887,0 860.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.212</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M781.247,-86.9735C788.2193,-74.8418 797.5372,-58.6287 805.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"808.5919,-46.4175 810.5402,-36.0034 802.5228,-42.9295 808.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"809.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1073.887,-36 993.887,-36 993.887,0 1073.887,0 1073.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1033.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.000</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1072.7341,-86.9735C1065.9013,-74.8418 1056.7698,-58.6287 1049.0769,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.9838,-42.9989 1044.0268,-36.0034 1045.8846,-46.4341 1051.9838,-42.9989\"/>\n",
       "<text text-anchor=\"middle\" x=\"1070.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1171.887,-36 1091.887,-36 1091.887,0 1171.887,0 1171.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1131.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.380</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1093.0398,-86.9735C1099.8726,-74.8418 1109.0041,-58.6287 1116.6971,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1119.8893,-46.4341 1121.7471,-36.0034 1113.7901,-42.9989 1119.8893,-46.4341\"/>\n",
       "<text text-anchor=\"middle\" x=\"1120.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f07c8671c50>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_model.plot_tree(0,train_pools[np.argmin(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "predictions_df['target'] = labels\n",
    "predictions_df['worst_model'] = worst_model.predict(train)\n",
    "predictions_df['best_model'] = best_model.predict(train)\n",
    "\n",
    "predictions_df['worst_incorrect'] = np.abs(predictions_df['target']-predictions_df['worst_model'])\n",
    "predictions_df['best_incorrect'] = np.abs(predictions_df['target']-predictions_df['best_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>worst_model</th>\n",
       "      <th>best_model</th>\n",
       "      <th>worst_incorrect</th>\n",
       "      <th>best_incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16962</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16964</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16965</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16967 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  worst_model  best_model  worst_incorrect  best_incorrect\n",
       "0           1            1           1                0               0\n",
       "1           1            1           1                0               0\n",
       "2           1            1           1                0               0\n",
       "3           1            1           1                0               0\n",
       "4           1            1           1                0               0\n",
       "...       ...          ...         ...              ...             ...\n",
       "16962       1            1           1                0               0\n",
       "16963       1            1           1                0               0\n",
       "16964       1            1           1                0               0\n",
       "16965       1            1           1                0               0\n",
       "16966       1            1           1                0               0\n",
       "\n",
       "[16967 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f07c8671250>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_df['worst_incorrect'][:1_000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f07c86f3590>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_df['best_incorrect'][:1_000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 0.5, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta predictions feature engineerings\n",
    "\n",
    "All the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = list(model_predictions_test.columns)\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]\n",
    "labels = model_predictions_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9756144\ttest: 0.9782129\tbest: 0.9782129 (0)\ttotal: 14.8ms\tremaining: 14.8s\n",
      "10:\tlearn: 0.9760862\ttest: 0.9786412\tbest: 0.9791586 (7)\ttotal: 152ms\tremaining: 13.6s\n",
      "20:\tlearn: 0.9759546\ttest: 0.9792371\tbest: 0.9792731 (13)\ttotal: 303ms\tremaining: 14.1s\n",
      "30:\tlearn: 0.9765854\ttest: 0.9783617\tbest: 0.9792731 (13)\ttotal: 439ms\tremaining: 13.7s\n",
      "40:\tlearn: 0.9770082\ttest: 0.9784728\tbest: 0.9792731 (13)\ttotal: 595ms\tremaining: 13.9s\n",
      "50:\tlearn: 0.9770485\ttest: 0.9783282\tbest: 0.9792731 (13)\ttotal: 736ms\tremaining: 13.7s\n",
      "60:\tlearn: 0.9774740\ttest: 0.9781347\tbest: 0.9792731 (13)\ttotal: 894ms\tremaining: 13.8s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9792731129\n",
      "bestIteration = 13\n",
      "\n",
      "Shrink model to first 14 iterations.\n",
      "Validation f1 0.9792731128892316\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9722033\ttest: 0.9744586\tbest: 0.9744586 (0)\ttotal: 15.7ms\tremaining: 15.7s\n",
      "10:\tlearn: 0.9756637\ttest: 0.9789160\tbest: 0.9789160 (10)\ttotal: 151ms\tremaining: 13.6s\n",
      "20:\tlearn: 0.9758770\ttest: 0.9786621\tbest: 0.9789281 (11)\ttotal: 304ms\tremaining: 14.2s\n",
      "30:\tlearn: 0.9762901\ttest: 0.9786662\tbest: 0.9789281 (11)\ttotal: 449ms\tremaining: 14s\n",
      "40:\tlearn: 0.9767666\ttest: 0.9789565\tbest: 0.9790586 (38)\ttotal: 602ms\tremaining: 14.1s\n",
      "50:\tlearn: 0.9772388\ttest: 0.9789686\tbest: 0.9790586 (38)\ttotal: 745ms\tremaining: 13.9s\n",
      "60:\tlearn: 0.9776773\ttest: 0.9786989\tbest: 0.9790787 (52)\ttotal: 898ms\tremaining: 13.8s\n",
      "70:\tlearn: 0.9777649\ttest: 0.9788827\tbest: 0.9790787 (52)\ttotal: 1.03s\tremaining: 13.5s\n",
      "80:\tlearn: 0.9781542\ttest: 0.9784090\tbest: 0.9790787 (52)\ttotal: 1.19s\tremaining: 13.5s\n",
      "90:\tlearn: 0.9785329\ttest: 0.9781274\tbest: 0.9790787 (52)\ttotal: 1.33s\tremaining: 13.3s\n",
      "100:\tlearn: 0.9789160\ttest: 0.9784297\tbest: 0.9790787 (52)\ttotal: 1.48s\tremaining: 13.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9790786948\n",
      "bestIteration = 52\n",
      "\n",
      "Shrink model to first 53 iterations.\n",
      "Validation f1 0.9790786948176583\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9768908\ttest: 0.9711401\tbest: 0.9711401 (0)\ttotal: 14.4ms\tremaining: 14.4s\n",
      "10:\tlearn: 0.9791266\ttest: 0.9712313\tbest: 0.9718296 (4)\ttotal: 177ms\tremaining: 15.9s\n",
      "20:\tlearn: 0.9791246\ttest: 0.9714559\tbest: 0.9718296 (4)\ttotal: 358ms\tremaining: 16.7s\n",
      "30:\tlearn: 0.9793190\ttest: 0.9712589\tbest: 0.9718296 (4)\ttotal: 516ms\tremaining: 16.1s\n",
      "40:\tlearn: 0.9794603\ttest: 0.9715490\tbest: 0.9718296 (4)\ttotal: 673ms\tremaining: 15.7s\n",
      "50:\tlearn: 0.9795506\ttest: 0.9718337\tbest: 0.9718337 (50)\ttotal: 815ms\tremaining: 15.2s\n",
      "60:\tlearn: 0.9797902\ttest: 0.9722009\tbest: 0.9722009 (60)\ttotal: 992ms\tremaining: 15.3s\n",
      "70:\tlearn: 0.9799808\ttest: 0.9718337\tbest: 0.9722009 (60)\ttotal: 1.13s\tremaining: 14.8s\n",
      "80:\tlearn: 0.9803148\ttest: 0.9718175\tbest: 0.9722009 (60)\ttotal: 1.28s\tremaining: 14.6s\n",
      "90:\tlearn: 0.9807415\ttest: 0.9721077\tbest: 0.9722009 (60)\ttotal: 1.43s\tremaining: 14.3s\n",
      "100:\tlearn: 0.9811757\ttest: 0.9714450\tbest: 0.9722009 (60)\ttotal: 1.61s\tremaining: 14.4s\n",
      "110:\tlearn: 0.9815591\ttest: 0.9715435\tbest: 0.9722009 (60)\ttotal: 1.77s\tremaining: 14.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9722009202\n",
      "bestIteration = 60\n",
      "\n",
      "Shrink model to first 61 iterations.\n",
      "Validation f1 0.9722009202453987\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9768509093174295, 0.0032889966427613383)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "labels = model_predictions_train['label']\n",
    "model_predictions_train = model_predictions_train[features]\n",
    "model_predictions_test = model_predictions_test[features]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[features], cat_features=cat_features)\n",
    "train = model_predictions_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9742798\ttest: 0.9773013\tbest: 0.9773013 (0)\ttotal: 12.3ms\tremaining: 12.3s\n",
      "10:\tlearn: 0.9756637\ttest: 0.9778851\tbest: 0.9783617 (8)\ttotal: 56.3ms\tremaining: 5.06s\n",
      "20:\tlearn: 0.9760977\ttest: 0.9781811\tbest: 0.9783617 (8)\ttotal: 95ms\tremaining: 4.43s\n",
      "30:\tlearn: 0.9764779\ttest: 0.9780740\tbest: 0.9783742 (23)\ttotal: 131ms\tremaining: 4.09s\n",
      "40:\tlearn: 0.9764779\ttest: 0.9779838\tbest: 0.9783742 (23)\ttotal: 171ms\tremaining: 3.99s\n",
      "50:\tlearn: 0.9768717\ttest: 0.9779880\tbest: 0.9783742 (23)\ttotal: 232ms\tremaining: 4.32s\n",
      "60:\tlearn: 0.9770552\ttest: 0.9779880\tbest: 0.9783742 (23)\ttotal: 271ms\tremaining: 4.17s\n",
      "70:\tlearn: 0.9772432\ttest: 0.9775975\tbest: 0.9783742 (23)\ttotal: 311ms\tremaining: 4.07s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9783742035\n",
      "bestIteration = 23\n",
      "\n",
      "Shrink model to first 24 iterations.\n",
      "Validation f1 0.978374203514192\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9745198\ttest: 0.9757846\tbest: 0.9757846 (0)\ttotal: 15.8ms\tremaining: 15.7s\n",
      "10:\tlearn: 0.9753396\ttest: 0.9791827\tbest: 0.9791827 (10)\ttotal: 58.8ms\tremaining: 5.29s\n",
      "20:\tlearn: 0.9755511\ttest: 0.9791125\tbest: 0.9792891 (11)\ttotal: 96.6ms\tremaining: 4.5s\n",
      "30:\tlearn: 0.9759361\ttest: 0.9792068\tbest: 0.9794033 (25)\ttotal: 138ms\tremaining: 4.3s\n",
      "40:\tlearn: 0.9761710\ttest: 0.9792068\tbest: 0.9794033 (25)\ttotal: 176ms\tremaining: 4.11s\n",
      "50:\tlearn: 0.9765493\ttest: 0.9793130\tbest: 0.9794033 (25)\ttotal: 228ms\tremaining: 4.24s\n",
      "60:\tlearn: 0.9767375\ttest: 0.9791246\tbest: 0.9794033 (25)\ttotal: 273ms\tremaining: 4.2s\n",
      "70:\tlearn: 0.9773132\ttest: 0.9793249\tbest: 0.9794033 (25)\ttotal: 313ms\tremaining: 4.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9794032724\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n",
      "Validation f1 0.9794032723772859\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9778013\ttest: 0.9728953\tbest: 0.9728953 (0)\ttotal: 10.2ms\tremaining: 10.2s\n",
      "10:\tlearn: 0.9787991\ttest: 0.9720574\tbest: 0.9728953 (0)\ttotal: 55.2ms\tremaining: 4.96s\n",
      "20:\tlearn: 0.9788401\ttest: 0.9717946\tbest: 0.9728953 (0)\ttotal: 95ms\tremaining: 4.43s\n",
      "30:\tlearn: 0.9787807\ttest: 0.9718929\tbest: 0.9728953 (0)\ttotal: 132ms\tremaining: 4.13s\n",
      "40:\tlearn: 0.9790694\ttest: 0.9719912\tbest: 0.9728953 (0)\ttotal: 172ms\tremaining: 4.03s\n",
      "50:\tlearn: 0.9793542\ttest: 0.9718929\tbest: 0.9728953 (0)\ttotal: 246ms\tremaining: 4.58s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9728953165\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "Validation f1 0.9728953165405613\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9768909308106797, 0.0028563899976401363)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1238pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 1237.77 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 1233.7739,-301 1233.7739,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"614.887\" cy=\"-279\" rx=\"198.4651\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.887\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">simple_nn_with_linear_predictions, value&gt;0.772813</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.206095</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M582.9416,-261.1843C558.701,-247.6655 525.2147,-228.9905 499.1422,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"500.6949,-211.3085 490.2565,-209.4946 497.2854,-217.4221 500.6949,-211.3085\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.387\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-192\" rx=\"126.978\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lgb_catfeatures, value&gt;0.206095</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M646.8323,-261.1843C671.0729,-247.6655 704.5592,-228.9905 730.6317,-214.45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"732.4885,-217.4221 739.5174,-209.4946 729.079,-211.3085 732.4885,-217.4221\"/>\n",
       "<text text-anchor=\"middle\" x=\"713.887\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"146.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"146.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401.2978,-175.9415C348.8925,-161.3285 271.4441,-139.7323 215.7769,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.5682,-120.7969 205.9956,-121.4822 214.688,-127.5397 216.5682,-120.7969\"/>\n",
       "<text text-anchor=\"middle\" x=\"330.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"458.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M458.887,-173.9735C458.887,-162.1918 458.887,-146.5607 458.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.3871,-133.0033 458.887,-123.0034 455.3871,-133.0034 462.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"770.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"770.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M770.887,-173.9735C770.887,-162.1918 770.887,-146.5607 770.887,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"774.3871,-133.0033 770.887,-123.0034 767.3871,-133.0034 774.3871,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"779.387\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1082.887\" cy=\"-105\" rx=\"146.774\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1082.887\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">catboost_base_6_3.0, value&gt;0.828489</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M828.4762,-175.9415C880.8815,-161.3285 958.3298,-139.7323 1013.997,-124.2097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1015.0859,-127.5397 1023.7783,-121.4822 1013.2057,-120.7969 1015.0859,-127.5397\"/>\n",
       "<text text-anchor=\"middle\" x=\"956.887\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"138.887,-36 54.887,-36 54.887,0 138.887,0 138.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.139</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136.5269,-86.9735C129.5547,-74.8418 120.2368,-58.6287 112.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.2512,-42.9295 107.2337,-36.0034 109.1821,-46.4175 115.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"236.887,-36 156.887,-36 156.887,0 236.887,0 236.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.000</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M157.247,-86.9735C164.2193,-74.8418 173.5372,-58.6287 181.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5919,-46.4175 186.5402,-36.0034 178.5228,-42.9295 184.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"450.887,-36 366.887,-36 366.887,0 450.887,0 450.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.013</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M448.5269,-86.9735C441.5547,-74.8418 432.2368,-58.6287 424.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.2512,-42.9295 419.2337,-36.0034 421.1821,-46.4175 427.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"445.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"548.887,-36 468.887,-36 468.887,0 548.887,0 548.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"508.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.211</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M469.247,-86.9735C476.2193,-74.8418 485.5372,-58.6287 493.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"496.5919,-46.4175 498.5402,-36.0034 490.5228,-42.9295 496.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"762.887,-36 678.887,-36 678.887,0 762.887,0 762.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"720.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = &#45;0.032</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M760.5269,-86.9735C753.5547,-74.8418 744.2368,-58.6287 736.3869,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"739.2512,-42.9295 731.2337,-36.0034 733.1821,-46.4175 739.2512,-42.9295\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"860.887,-36 780.887,-36 780.887,0 860.887,0 860.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.000</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M781.247,-86.9735C788.2193,-74.8418 797.5372,-58.6287 805.3871,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"808.5919,-46.4175 810.5402,-36.0034 802.5228,-42.9295 808.5919,-46.4175\"/>\n",
       "<text text-anchor=\"middle\" x=\"809.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1073.887,-36 993.887,-36 993.887,0 1073.887,0 1073.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1033.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.023</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1072.7341,-86.9735C1065.9013,-74.8418 1056.7698,-58.6287 1049.0769,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.9838,-42.9989 1044.0268,-36.0034 1045.8846,-46.4341 1051.9838,-42.9989\"/>\n",
       "<text text-anchor=\"middle\" x=\"1070.387\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">No</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"1171.887,-36 1091.887,-36 1091.887,0 1171.887,0 1171.887,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1131.887\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">val = 0.328</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1093.0398,-86.9735C1099.8726,-74.8418 1109.0041,-58.6287 1116.6971,-44.9698\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1119.8893,-46.4341 1121.7471,-36.0034 1113.7901,-42.9989 1119.8893,-46.4341\"/>\n",
       "<text text-anchor=\"middle\" x=\"1120.887\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f07c4293e50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>lgb_all</td>\n",
       "      <td>14.388914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>catboost_base_6_3.0_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>12.446231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>catboost_base_3_1.0_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>10.961921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>catboost_base_6_3.0</td>\n",
       "      <td>10.534407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>catboost_base_6_3.0_simple_nn_with_linear_pred...</td>\n",
       "      <td>9.361810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>catboost_base_3_1.0</td>\n",
       "      <td>9.107421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>lgb_all_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>7.348002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>catboost_base_6_3.0_simple_nn_diff</td>\n",
       "      <td>4.643219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>simple_nn_with_linear_predictions</td>\n",
       "      <td>3.707852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>lgb_catfeatures</td>\n",
       "      <td>2.976878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>catboost_anomaly_3_6.0</td>\n",
       "      <td>2.092060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>lgb_catfeatures_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>1.991401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>catboost_base_3_1.0_autoencoder_catboost_8_1.0...</td>\n",
       "      <td>1.490582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>catboost_base_3_1.0_simple_nn_with_linear_pred...</td>\n",
       "      <td>1.190378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>multihead_nn</td>\n",
       "      <td>1.172186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>catboost_base_6_3.0_catboost_base_3_1.0_diff</td>\n",
       "      <td>1.097513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>catboost_base_3_1.0_lgb_all_diff</td>\n",
       "      <td>0.941590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>lgb_all_multihead_nn_diff</td>\n",
       "      <td>0.719983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>catboost_base_6_3.0_autoencoder_catboost_8_1.0...</td>\n",
       "      <td>0.646448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>lgb_all_simple_nn_with_linear_predictions_diff</td>\n",
       "      <td>0.631702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>autoencoder_catboost_8_1.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.438788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>autoencoder_catboost_8_1.0_simple_nn_with_line...</td>\n",
       "      <td>0.362119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>catboost_base_6_3.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.355375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>simple_nn_multihead_nn_diff</td>\n",
       "      <td>0.348405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>autoencoder_catboost_8_1.0</td>\n",
       "      <td>0.223882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>simple_nn_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.185224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>catboost_base_6_3.0_lgb_all_diff</td>\n",
       "      <td>0.180607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>autoencoder_catboost_8_1.0_multihead_nn_diff</td>\n",
       "      <td>0.153913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>lgb_catfeatures_multihead_nn_diff</td>\n",
       "      <td>0.098558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>autoencoder_catboost_8_1.0_catboost_anomaly_3_...</td>\n",
       "      <td>0.090418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>catboost_base_6_3.0_multihead_nn_diff</td>\n",
       "      <td>0.063177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>lgb_catfeatures_simple_nn_with_linear_predicti...</td>\n",
       "      <td>0.049038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>simple_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>catboost_base_3_1.0_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>catboost_base_3_1.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>catboost_base_3_1.0_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>autoencoder_catboost_8_1.0_lgb_all_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>autoencoder_catboost_8_1.0_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>lgb_all_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>lgb_all_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>simple_nn_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>simple_nn_simple_nn_with_linear_predictions_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>simple_nn_with_linear_predictions_multihead_nn...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>simple_nn_with_linear_predictions_catboost_ano...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>multihead_nn_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Feature Id  Importances\n",
       "0                                             lgb_all    14.388914\n",
       "1     catboost_base_6_3.0_catboost_anomaly_3_6.0_diff    12.446231\n",
       "2     catboost_base_3_1.0_catboost_anomaly_3_6.0_diff    10.961921\n",
       "3                                 catboost_base_6_3.0    10.534407\n",
       "4   catboost_base_6_3.0_simple_nn_with_linear_pred...     9.361810\n",
       "5                                 catboost_base_3_1.0     9.107421\n",
       "6                 lgb_all_catboost_anomaly_3_6.0_diff     7.348002\n",
       "7                  catboost_base_6_3.0_simple_nn_diff     4.643219\n",
       "8                   simple_nn_with_linear_predictions     3.707852\n",
       "9                                     lgb_catfeatures     2.976878\n",
       "10                             catboost_anomaly_3_6.0     2.092060\n",
       "11        lgb_catfeatures_catboost_anomaly_3_6.0_diff     1.991401\n",
       "12  catboost_base_3_1.0_autoencoder_catboost_8_1.0...     1.490582\n",
       "13  catboost_base_3_1.0_simple_nn_with_linear_pred...     1.190378\n",
       "14                                       multihead_nn     1.172186\n",
       "15       catboost_base_6_3.0_catboost_base_3_1.0_diff     1.097513\n",
       "16                   catboost_base_3_1.0_lgb_all_diff     0.941590\n",
       "17                          lgb_all_multihead_nn_diff     0.719983\n",
       "18  catboost_base_6_3.0_autoencoder_catboost_8_1.0...     0.646448\n",
       "19     lgb_all_simple_nn_with_linear_predictions_diff     0.631702\n",
       "20    autoencoder_catboost_8_1.0_lgb_catfeatures_diff     0.438788\n",
       "21  autoencoder_catboost_8_1.0_simple_nn_with_line...     0.362119\n",
       "22           catboost_base_6_3.0_lgb_catfeatures_diff     0.355375\n",
       "23                        simple_nn_multihead_nn_diff     0.348405\n",
       "24                         autoencoder_catboost_8_1.0     0.223882\n",
       "25              simple_nn_catboost_anomaly_3_6.0_diff     0.185224\n",
       "26                   catboost_base_6_3.0_lgb_all_diff     0.180607\n",
       "27       autoencoder_catboost_8_1.0_multihead_nn_diff     0.153913\n",
       "28                  lgb_catfeatures_multihead_nn_diff     0.098558\n",
       "29  autoencoder_catboost_8_1.0_catboost_anomaly_3_...     0.090418\n",
       "30              catboost_base_6_3.0_multihead_nn_diff     0.063177\n",
       "31  lgb_catfeatures_simple_nn_with_linear_predicti...     0.049038\n",
       "32                                          simple_nn     0.000000\n",
       "33                 catboost_base_3_1.0_simple_nn_diff     0.000000\n",
       "34           catboost_base_3_1.0_lgb_catfeatures_diff     0.000000\n",
       "35              catboost_base_3_1.0_multihead_nn_diff     0.000000\n",
       "36            autoencoder_catboost_8_1.0_lgb_all_diff     0.000000\n",
       "37          autoencoder_catboost_8_1.0_simple_nn_diff     0.000000\n",
       "38                             lgb_all_simple_nn_diff     0.000000\n",
       "39                       lgb_all_lgb_catfeatures_diff     0.000000\n",
       "40                     simple_nn_lgb_catfeatures_diff     0.000000\n",
       "41   simple_nn_simple_nn_with_linear_predictions_diff     0.000000\n",
       "42  simple_nn_with_linear_predictions_multihead_nn...     0.000000\n",
       "43  simple_nn_with_linear_predictions_catboost_ano...     0.000000\n",
       "44           multihead_nn_catboost_anomaly_3_6.0_diff     0.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>lgb_all_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>44.516631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lgb_all</td>\n",
       "      <td>33.067422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>autoencoder_catboost_8_1.0_lgb_all_diff</td>\n",
       "      <td>22.415947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>catboost_base_6_3.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>catboost_base_3_1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>autoencoder_catboost_8_1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>simple_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lgb_catfeatures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>simple_nn_with_linear_predictions</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>multihead_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>catboost_anomaly_3_6.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>catboost_base_6_3.0_catboost_base_3_1.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>catboost_base_6_3.0_autoencoder_catboost_8_1.0...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>catboost_base_6_3.0_lgb_all_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>catboost_base_6_3.0_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>catboost_base_6_3.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>catboost_base_6_3.0_simple_nn_with_linear_pred...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>catboost_base_6_3.0_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>catboost_base_6_3.0_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>catboost_base_3_1.0_autoencoder_catboost_8_1.0...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>catboost_base_3_1.0_lgb_all_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>catboost_base_3_1.0_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>catboost_base_3_1.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>catboost_base_3_1.0_simple_nn_with_linear_pred...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>catboost_base_3_1.0_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>catboost_base_3_1.0_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>autoencoder_catboost_8_1.0_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>autoencoder_catboost_8_1.0_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>autoencoder_catboost_8_1.0_simple_nn_with_line...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>autoencoder_catboost_8_1.0_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>autoencoder_catboost_8_1.0_catboost_anomaly_3_...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>lgb_all_simple_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>lgb_all_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>lgb_all_simple_nn_with_linear_predictions_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>lgb_all_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>simple_nn_lgb_catfeatures_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>simple_nn_simple_nn_with_linear_predictions_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>simple_nn_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>simple_nn_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>lgb_catfeatures_simple_nn_with_linear_predicti...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>lgb_catfeatures_multihead_nn_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>lgb_catfeatures_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>simple_nn_with_linear_predictions_multihead_nn...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>simple_nn_with_linear_predictions_catboost_ano...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>multihead_nn_catboost_anomaly_3_6.0_diff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Feature Id  Importances\n",
       "0                 lgb_all_catboost_anomaly_3_6.0_diff    44.516631\n",
       "1                                             lgb_all    33.067422\n",
       "2             autoencoder_catboost_8_1.0_lgb_all_diff    22.415947\n",
       "3                                 catboost_base_6_3.0     0.000000\n",
       "4                                 catboost_base_3_1.0     0.000000\n",
       "5                          autoencoder_catboost_8_1.0     0.000000\n",
       "6                                           simple_nn     0.000000\n",
       "7                                     lgb_catfeatures     0.000000\n",
       "8                   simple_nn_with_linear_predictions     0.000000\n",
       "9                                        multihead_nn     0.000000\n",
       "10                             catboost_anomaly_3_6.0     0.000000\n",
       "11       catboost_base_6_3.0_catboost_base_3_1.0_diff     0.000000\n",
       "12  catboost_base_6_3.0_autoencoder_catboost_8_1.0...     0.000000\n",
       "13                   catboost_base_6_3.0_lgb_all_diff     0.000000\n",
       "14                 catboost_base_6_3.0_simple_nn_diff     0.000000\n",
       "15           catboost_base_6_3.0_lgb_catfeatures_diff     0.000000\n",
       "16  catboost_base_6_3.0_simple_nn_with_linear_pred...     0.000000\n",
       "17              catboost_base_6_3.0_multihead_nn_diff     0.000000\n",
       "18    catboost_base_6_3.0_catboost_anomaly_3_6.0_diff     0.000000\n",
       "19  catboost_base_3_1.0_autoencoder_catboost_8_1.0...     0.000000\n",
       "20                   catboost_base_3_1.0_lgb_all_diff     0.000000\n",
       "21                 catboost_base_3_1.0_simple_nn_diff     0.000000\n",
       "22           catboost_base_3_1.0_lgb_catfeatures_diff     0.000000\n",
       "23  catboost_base_3_1.0_simple_nn_with_linear_pred...     0.000000\n",
       "24              catboost_base_3_1.0_multihead_nn_diff     0.000000\n",
       "25    catboost_base_3_1.0_catboost_anomaly_3_6.0_diff     0.000000\n",
       "26          autoencoder_catboost_8_1.0_simple_nn_diff     0.000000\n",
       "27    autoencoder_catboost_8_1.0_lgb_catfeatures_diff     0.000000\n",
       "28  autoencoder_catboost_8_1.0_simple_nn_with_line...     0.000000\n",
       "29       autoencoder_catboost_8_1.0_multihead_nn_diff     0.000000\n",
       "30  autoencoder_catboost_8_1.0_catboost_anomaly_3_...     0.000000\n",
       "31                             lgb_all_simple_nn_diff     0.000000\n",
       "32                       lgb_all_lgb_catfeatures_diff     0.000000\n",
       "33     lgb_all_simple_nn_with_linear_predictions_diff     0.000000\n",
       "34                          lgb_all_multihead_nn_diff     0.000000\n",
       "35                     simple_nn_lgb_catfeatures_diff     0.000000\n",
       "36   simple_nn_simple_nn_with_linear_predictions_diff     0.000000\n",
       "37                        simple_nn_multihead_nn_diff     0.000000\n",
       "38              simple_nn_catboost_anomaly_3_6.0_diff     0.000000\n",
       "39  lgb_catfeatures_simple_nn_with_linear_predicti...     0.000000\n",
       "40                  lgb_catfeatures_multihead_nn_diff     0.000000\n",
       "41        lgb_catfeatures_catboost_anomaly_3_6.0_diff     0.000000\n",
       "42  simple_nn_with_linear_predictions_multihead_nn...     0.000000\n",
       "43  simple_nn_with_linear_predictions_catboost_ano...     0.000000\n",
       "44           multihead_nn_catboost_anomaly_3_6.0_diff     0.000000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_model = models[np.argmin(validation_scores)]\n",
    "worst_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = best_model.get_feature_importance(prettified=True)\n",
    "important_features = f_i[f_i['Importances'] > 0]['Feature Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = model_predictions_train[important_features]\n",
    "model_predictions_test = model_predictions_test[important_features]\n",
    "\n",
    "submission_pool = Pool(data=model_predictions_test[important_features], cat_features=cat_features)\n",
    "train = model_predictions_train[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9747834\ttest: 0.9773450\tbest: 0.9773450 (0)\ttotal: 10.4ms\tremaining: 10.4s\n",
      "10:\tlearn: 0.9756355\ttest: 0.9787604\tbest: 0.9788508 (5)\ttotal: 61.2ms\tremaining: 5.5s\n",
      "20:\tlearn: 0.9759685\ttest: 0.9785632\tbest: 0.9789372 (14)\ttotal: 97.3ms\tremaining: 4.53s\n",
      "30:\tlearn: 0.9761023\ttest: 0.9784687\tbest: 0.9789372 (14)\ttotal: 132ms\tremaining: 4.12s\n",
      "40:\tlearn: 0.9763348\ttest: 0.9784603\tbest: 0.9789372 (14)\ttotal: 167ms\tremaining: 3.91s\n",
      "50:\tlearn: 0.9766279\ttest: 0.9782714\tbest: 0.9789372 (14)\ttotal: 209ms\tremaining: 3.9s\n",
      "60:\tlearn: 0.9772924\ttest: 0.9778808\tbest: 0.9789372 (14)\ttotal: 264ms\tremaining: 4.06s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9789371981\n",
      "bestIteration = 14\n",
      "\n",
      "Shrink model to first 15 iterations.\n",
      "Validation f1 0.9789371980676328\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9751574\ttest: 0.9774131\tbest: 0.9774131 (0)\ttotal: 4.01ms\tremaining: 4.01s\n",
      "10:\tlearn: 0.9755863\ttest: 0.9778846\tbest: 0.9778846 (10)\ttotal: 40.3ms\tremaining: 3.62s\n",
      "20:\tlearn: 0.9760554\ttest: 0.9783508\tbest: 0.9783508 (18)\ttotal: 82.2ms\tremaining: 3.83s\n",
      "30:\tlearn: 0.9762947\ttest: 0.9783633\tbest: 0.9784450 (22)\ttotal: 132ms\tremaining: 4.13s\n",
      "40:\tlearn: 0.9764310\ttest: 0.9784574\tbest: 0.9784574 (38)\ttotal: 167ms\tremaining: 3.9s\n",
      "50:\tlearn: 0.9766144\ttest: 0.9786580\tbest: 0.9786580 (50)\ttotal: 205ms\tremaining: 3.81s\n",
      "60:\tlearn: 0.9769479\ttest: 0.9784822\tbest: 0.9786703 (54)\ttotal: 242ms\tremaining: 3.72s\n",
      "70:\tlearn: 0.9771874\ttest: 0.9785845\tbest: 0.9786744 (65)\ttotal: 280ms\tremaining: 3.66s\n",
      "80:\tlearn: 0.9775167\ttest: 0.9785845\tbest: 0.9786744 (65)\ttotal: 339ms\tremaining: 3.84s\n",
      "90:\tlearn: 0.9778120\ttest: 0.9785029\tbest: 0.9786825 (81)\ttotal: 377ms\tremaining: 3.76s\n",
      "100:\tlearn: 0.9780474\ttest: 0.9784131\tbest: 0.9786825 (81)\ttotal: 415ms\tremaining: 3.7s\n",
      "110:\tlearn: 0.9786251\ttest: 0.9778417\tbest: 0.9786825 (81)\ttotal: 452ms\tremaining: 3.62s\n",
      "120:\tlearn: 0.9788197\ttest: 0.9779482\tbest: 0.9786825 (81)\ttotal: 494ms\tremaining: 3.59s\n",
      "130:\tlearn: 0.9792088\ttest: 0.9781358\tbest: 0.9786825 (81)\ttotal: 539ms\tremaining: 3.58s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9786825427\n",
      "bestIteration = 81\n",
      "\n",
      "Shrink model to first 82 iterations.\n",
      "Validation f1 0.978682542730939\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9751777\ttest: 0.9720151\tbest: 0.9720151 (0)\ttotal: 3.92ms\tremaining: 3.92s\n",
      "10:\tlearn: 0.9788952\ttest: 0.9722753\tbest: 0.9728433 (2)\ttotal: 38.4ms\tremaining: 3.45s\n",
      "20:\tlearn: 0.9788380\ttest: 0.9718108\tbest: 0.9728433 (2)\ttotal: 75.5ms\tremaining: 3.52s\n",
      "30:\tlearn: 0.9789261\ttest: 0.9720948\tbest: 0.9728433 (2)\ttotal: 132ms\tremaining: 4.12s\n",
      "40:\tlearn: 0.9790674\ttest: 0.9720019\tbest: 0.9728433 (2)\ttotal: 167ms\tremaining: 3.91s\n",
      "50:\tlearn: 0.9793030\ttest: 0.9721001\tbest: 0.9728433 (2)\ttotal: 203ms\tremaining: 3.78s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9728432972\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "Validation f1 0.9728432971883697\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train, labels):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9768210126623139, 0.0028145902755543446)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra trees stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_predictions_test.columns\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':10,\n",
    "    'random_state':0,\n",
    "    'max_depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.9588048090523338\n",
      "Validation f1 0.9582743988684582\n",
      "Validation f1 0.9485411140583554\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9552067739930491, 0.004718304816670618)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':10,\n",
    "    'random_state':0,\n",
    "    'max_depth':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.9602192362093352\n",
      "Validation f1 0.9609264497878359\n",
      "Validation f1 0.946949602122016\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9560317627063957, 0.006428544076836778)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.9602192362093352\n",
      "Validation f1 0.9586280056577087\n",
      "Validation f1 0.9471264367816092\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9553245595495511, 0.0058332333147116)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = model_predictions_test.columns\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {    \n",
    "    'random_state':0,\n",
    "    'penalty':'l2',\n",
    "    'solver':'lbfgs',\n",
    "    'max_iter':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.9584512022630834\n",
      "Validation f1 0.96004243281471\n",
      "Validation f1 0.9465959328028294\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9550298559602076, 0.0059989609397810475)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n",
    "y = model_predictions_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {    \n",
    "    'random_state':0,\n",
    "    'penalty':'l2',\n",
    "    'solver':'lbfgs',\n",
    "    'max_iter':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.958981612446959\n",
      "Validation f1 0.9595120226308345\n",
      "Validation f1 0.9474801061007958\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.955324580392863, 0.005551105981692184)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.read_csv('stack_train.csv')\n",
    "model_predictions_test = pd.read_csv('stack_test.csv')\n",
    "\n",
    "features = [\n",
    "    'catboost_base_6_3.0',\n",
    "    'catboost_base_3_1.0',\n",
    "    'autoencoder_catboost_8_1.0',\n",
    "    'lgb_all',\n",
    "    'simple_nn',\n",
    "    'lgb_catfeatures',\n",
    "    'simple_nn_with_linear_predictions',\n",
    "    'multihead_nn',\n",
    "    'catboost_anomaly_3_6.0'\n",
    "]\n",
    "y = model_predictions_train['label'].values\n",
    "model_predictions_train = model_predictions_train[features]\n",
    "model_predictions_test = model_predictions_test[features]\n",
    "\n",
    "new_featuers = []\n",
    "\n",
    "for i,col1 in enumerate(features):\n",
    "        for col2 in features[i+1:]:\n",
    "            col_name = f'{col1}_{col2}_diff'\n",
    "            model_predictions_train[col_name] = model_predictions_train[col1] - model_predictions_train[col2]\n",
    "            model_predictions_test[col_name] = model_predictions_test[col1] - model_predictions_test[col2]\n",
    "            new_featuers.append(col_name)\n",
    "            \n",
    "features = features + new_featuers\n",
    "\n",
    "train_X = model_predictions_train[features].values\n",
    "test_X = model_predictions_test[features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 0.9588048090523338\n",
      "Validation f1 0.9598656294200849\n",
      "Validation f1 0.946949602122016\n"
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "models = []\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, test_index in skf.split(train_X, y):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    validation_score = f1_score(y_test, pred,average='micro')\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)    \n",
    "    submission_preds += model.predict(test_X)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9552066801981449, 0.005854675552048162)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
