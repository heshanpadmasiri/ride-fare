{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.metrics import f1_score,mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(\n",
    "    0\n",
    ")\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate,Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(value=0)\n",
    "test_df = test_df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features+['label']]\n",
    "test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,45*4))\n",
    "gs = gridspec.GridSpec(45, 1)\n",
    "for i, cn in enumerate(train[features]):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    sns.distplot(train[cn][train.label == 1], bins=50)\n",
    "    sns.distplot(train[cn][train.label == 0], bins=50)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('histogram of feature: ' + str(cn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "Y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(x1, y1, name=\"graph.png\",random_state=0):\n",
    "    tsne = TSNE(n_components=2, random_state=random_state)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='Correct')\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Incorrect')\n",
    "    \n",
    "    plt.legend(loc='best');\n",
    "    plt.savefig(name);\n",
    "    plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne_plot(X, Y, \"original.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_scale = scaler.fit_transform(X)\n",
    "x_correct, x_incorrect = x_scale[Y == 1], x_scale[Y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    ## input layer \n",
    "    input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "    ## encoding part\n",
    "    encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "    ## decoding part\n",
    "    decoded = Dense(50, activation='tanh')(encoded)\n",
    "    decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "    ## output layer\n",
    "    output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterations(iterations,size=2000):\n",
    "    autoencoder = get_model()\n",
    "    autoencoder.fit(x_correct[:size], x_correct[:size], \n",
    "                    batch_size = 256, epochs = iterations, \n",
    "                    shuffle = True, validation_split = 0.20,verbose=False)\n",
    "    \n",
    "    hidden_representation = Sequential()\n",
    "    hidden_representation.add(autoencoder.layers[0])\n",
    "    hidden_representation.add(autoencoder.layers[1])\n",
    "    hidden_representation.add(autoencoder.layers[2])\n",
    "    \n",
    "    correct_hid_rep = hidden_representation.predict(x_correct[:3000])\n",
    "    incorrect_hid_rep = hidden_representation.predict(x_incorrect)\n",
    "    \n",
    "    rep_x = np.append(correct_hid_rep, incorrect_hid_rep, axis = 0)\n",
    "    y_c = np.ones(correct_hid_rep.shape[0])\n",
    "    y_i = np.zeros(incorrect_hid_rep.shape[0])\n",
    "    rep_y = np.append(y_c, y_i)\n",
    "    tsne_plot(rep_x, rep_y, f\"latent_representation_{size}_{iterations}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in range(2_000,14_000,5_000):\n",
    "#     for it in range(10,101,10):\n",
    "#         run_iterations(it,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = get_model()\n",
    "autoencoder.fit(x_correct, x_correct, \n",
    "                batch_size = 256, epochs = 50, \n",
    "                shuffle = True, validation_split = 0.20,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_hid_rep = hidden_representation.predict(x_correct)\n",
    "incorrect_hid_rep = hidden_representation.predict(x_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_x = np.append(correct_hid_rep, incorrect_hid_rep, axis = 0)\n",
    "y_c = np.ones(correct_hid_rep.shape[0])\n",
    "y_i = np.zeros(incorrect_hid_rep.shape[0])\n",
    "rep_y = np.append(y_c, y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = hidden_representation.predict(scaler.transform(test_df[features]))\n",
    " = hidden_representation.predict(x_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "for train_index, test_index in skf.split(rep_x, rep_y):\n",
    "    X_train, X_test = rep_x[train_index], rep_x[test_index]\n",
    "    y_train, y_test = rep_y[train_index], rep_y[test_index]\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test),verbose=10)\n",
    "    \n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    test_preds += model.predict(x_test)\n",
    "    train_preds += model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df = pd.read_csv('stacking_train_df.csv')\n",
    "stacking_test_df = pd.read_csv('stacking_test_df.csv')\n",
    "\n",
    "stacking_train_df['catboost_autoencoder'] = train_preds\n",
    "stacking_test_df['catboost_autoencoder'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_model(input_size,layers=[40,20,10]):\n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    \n",
    "    X = Dense(layers[0],activation='relu')(input_layer)\n",
    "    for nodes in layers[1:]:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('predicted' not in each) and ('anomaly' not in each) and (each != 'label'), train_df.columns))\n",
    "train = train_df[features+['label']]\n",
    "test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X.shape[1],[100,50,50])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds\n",
    "    train_preds += model.predict(X_scale).reshape(train_preds.shape)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df['nn_base'] = train_preds\n",
    "stacking_test_df['nn_base'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(test_preds > 1.5,1,0)\n",
    "submission_df.to_csv('submission_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(filter(lambda each: ('anomaly' not in each) and (each != 'label'), train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_model(X.shape[1],[50,100,150])\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),callbacks=[callbacks])\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "    test_preds += preds\n",
    "    train_preds += model.predict(X_scale).reshape(train_preds.shape)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df['nn_linear_pred'] = train_preds\n",
    "stacking_test_df['nn_linear_pred'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(test_preds > 1.5,1,0)\n",
    "submission_df.to_csv('submission_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_validation_score(params):\n",
    "    folds = params['folds']\n",
    "    layer_1 = params['layer_1']\n",
    "    layer_2 = params['layer_2']\n",
    "    layer_3 = params['layer_3']\n",
    "    \n",
    "    validation_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    for train_index, test_index in skf.split(X_scale, y):\n",
    "        X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        model = get_model(X.shape[1],[layer_1,layer_2,layer_3])\n",
    "        model.fit(x=X_train,y=y_train,batch_size=512,epochs=100,validation_data=(X_valid,y_valid),verbose=False,callbacks=[callbacks])\n",
    "\n",
    "        y_hat = model.predict(X_valid)\n",
    "        y_hat = np.where(y_hat > 0.5,1,0)\n",
    "        score = f1_score(y_valid, y_hat, average='micro')\n",
    "        validation_scores.append(score)\n",
    "        \n",
    "    return np.mean(validation_scores) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_nodes = [i*10 for i in range(1,30)]\n",
    "folds = [2,3,5]\n",
    "space = {\n",
    "    'folds': hp.choice('folds', [2,3,5]),\n",
    "    'layer_1': hp.choice('layer_1', layer_nodes),\n",
    "    'layer_2': hp.choice('layer_2', layer_nodes),\n",
    "    'layer_3': hp.choice('layer_3', layer_nodes)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(get_mean_validation_score, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds[best['folds']-1] , layer_nodes[best['layer_1']-1] ,layer_nodes[best['layer_2']-1], layer_nodes[best['layer_3']-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds[best['folds']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "STEPS_PER_EPOCH = 3400//BATCH_SIZE\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "      0.001,\n",
    "      decay_steps=STEPS_PER_EPOCH*1000,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "\n",
    "def get_log_dir(model,dropout,residual):\n",
    "    model_name = '-'.join(map(lambda x: str(x),model)) + f':{dropout}' + f':{residual}'\n",
    "    return f'./logs/{model_name}'\n",
    "\n",
    "def get_pred_model(input_size,layers=[40,20,10],drop_out=0.2,residual=True):   \n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    intermediate_layers = []    \n",
    "    X = Dense(layers[0],activation='relu')(input_layer)\n",
    "    intermediate_layers.append(X)\n",
    "    X = Dropout(drop_out)(X)\n",
    "    for nodes in layers[1:]:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "        intermediate_layers.append(X)\n",
    "        X = Dropout(drop_out)(X)\n",
    "    conc = concatenate(intermediate_layers)\n",
    "    if residual:\n",
    "        output_layer = Dense(1, activation='relu')(conc)\n",
    "    else:\n",
    "        output_layer = Dense(1, activation='relu')(X)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule), \n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.RootMeanSquaredError()])\n",
    "    feature_extractor = Model(input_layer, conc)\n",
    "    return feature_extractor,model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'fare'\n",
    "# cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']\n",
    "cols = ['additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[train_df['label']==1][cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "\n",
    "y = train_df[train_df['label']==1][target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "model_def = [60,80,50,20,15]\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in kf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "        \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    _, model = get_pred_model(X.shape[1],model_def)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),callbacks=callbacks)\n",
    "    \n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores),validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "fare_representation, fare_model = get_pred_model(X_scale.shape[1],model_def)\n",
    "\n",
    "fare_model.fit(x=X_scale,y=y,batch_size=512,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(fare_representation, \"fare_representation_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_representation.save('models/fare_representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "# cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']\n",
    "cols = ['additional_fare', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[train_df['label']==1][cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "\n",
    "y = train_df[train_df['label']==1][target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparemeter tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scale, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(params):\n",
    "    model_def = params['model']\n",
    "    dropout = params['dropout']\n",
    "    residual = params['residual']\n",
    "    \n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session() \n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def,dropout,residual))\n",
    "\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout,residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),verbose=False,callbacks=callbacks+[tensorboard_callback])\n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    [60,80,80,60,40,20,10],\n",
    "    [60,80,80,60,40,20,10,5],\n",
    "    [60,80,100,80,60,40,20,10],\n",
    "    [60,80,100,80,60,40,20,10,5],    \n",
    "    [60,80,60,40,20,10],\n",
    "    [60,80,60,40,20,10,5],\n",
    "    \n",
    "    [60,80,60,80],\n",
    "    [60,80,60,80,60],\n",
    "    [60,80,60,80,60,80],\n",
    "    \n",
    "    [60,40,60,40],\n",
    "    [60,40,60,40,60],\n",
    "    [60,40,60,40,60,40],\n",
    "    \n",
    "    [60,60,60],\n",
    "    [60,60,60,60],\n",
    "    [80,80,80],\n",
    "    [80,80,80,80],\n",
    "    [40,40,40],\n",
    "    [40,40,40,40],\n",
    "    \n",
    "    [40,30,20,10],\n",
    "    [40,30,20,10,5]\n",
    "]\n",
    "\n",
    "dropouts = [\n",
    "    0.2,0.4,0.6,0.8\n",
    "]\n",
    "\n",
    "residuals = [\n",
    "    True, False\n",
    "]\n",
    "\n",
    "best_config = {}\n",
    "best_score = float('inf') \n",
    "score_config = {}\n",
    "for model in tqdm(models):\n",
    "    for dropout in dropouts:\n",
    "        for residual in residuals:\n",
    "            params = {\n",
    "                'model':model,\n",
    "                'dropout':dropout,\n",
    "                'residual':residual\n",
    "            }\n",
    "            score = get_score(params)\n",
    "            score_config[score] = params\n",
    "            if score < best_score:\n",
    "                best_config = params\n",
    "                best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score ,best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(score_config.values())\n",
    "\n",
    "def get_score(config):\n",
    "    for each in score_config:\n",
    "        if score_config[each] == config:\n",
    "            return each\n",
    "        \n",
    "sorted(list(score_config.values()),key=get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session() \n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "model_def =[60, 40, 60, 40, 60, 40]\n",
    "dropout = 0.2\n",
    "residual = True\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in kf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "#     tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def,fold))\n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout,residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),callbacks=callbacks)\n",
    "    \n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores),validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session() \n",
    "tf.random.set_seed(0)\n",
    "\n",
    "duration_representation,duration_model = get_pred_model(X_scale.shape[1],model_def,dropout,residual)\n",
    "\n",
    "duration_model.fit(x=X_scale,y=y,batch_size=512,epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(duration_representation, \"duration_representation.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_representation.save('models/duration_representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meter waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'meter_waiting'\n",
    "# cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']\n",
    "cols = ['additional_fare', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[train_df['label']==1][cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "\n",
    "y = train_df[train_df['label']==1][target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scale, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(params):\n",
    "    model_def = params['model']\n",
    "    dropout = params['dropout']\n",
    "    residual = params['residual']\n",
    "    \n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session() \n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def,dropout,residual))\n",
    "\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout,residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),verbose=False,callbacks=callbacks+[tensorboard_callback])\n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    [60,80,80,60,40,20,10],\n",
    "    [60,80,80,60,40,20,10,5],\n",
    "    [60,80,100,80,60,40,20,10],\n",
    "    [60,80,100,80,60,40,20,10,5],    \n",
    "    [60,80,60,40,20,10],\n",
    "    [60,80,60,40,20,10,5],\n",
    "    \n",
    "    [60,80,60,80],\n",
    "    [60,80,60,80,60],\n",
    "    [60,80,60,80,60,80],\n",
    "    \n",
    "    [60,40,60,40],\n",
    "    [60,40,60,40,60],\n",
    "    [60,40,60,40,60,40],\n",
    "    \n",
    "    [60,60,60],\n",
    "    [60,60,60,60],\n",
    "    [80,80,80],\n",
    "    [80,80,80,80],\n",
    "    [40,40,40],\n",
    "    [40,40,40,40],\n",
    "    \n",
    "    [40,30,20,10],\n",
    "    [40,30,20,10,5]\n",
    "]\n",
    "\n",
    "dropouts = [\n",
    "    0.2,0.4,0.6,0.8\n",
    "]\n",
    "\n",
    "residuals = [\n",
    "    True, False\n",
    "]\n",
    "\n",
    "best_config = {}\n",
    "best_score = float('inf') \n",
    "score_config = {}\n",
    "for model in tqdm(models):\n",
    "    for dropout in dropouts:\n",
    "        for residual in residuals:\n",
    "            params = {\n",
    "                'model':model,\n",
    "                'dropout':dropout,\n",
    "                'residual':residual\n",
    "            }\n",
    "            score = get_score(params)\n",
    "            score_config[score] = params\n",
    "            if score < best_score:\n",
    "                best_config = params\n",
    "                best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score ,best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(config):\n",
    "    for each in score_config:\n",
    "        if score_config[each] == config:\n",
    "            return each\n",
    "        \n",
    "sorted(list(score_config.values()),key=get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "model_def =[60, 40, 60, 40, 60, 40]\n",
    "dropout = 0.2\n",
    "residual = True\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in kf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "#     tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def,fold))\n",
    "    \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout,residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),callbacks=callbacks)\n",
    "    \n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "#     preds = model.predict(X_test).reshape(test_preds.shape)\n",
    "#     test_preds += preds\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores),validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session() \n",
    "tf.random.set_seed(0)\n",
    "\n",
    "meter_waiting_representation,meter_waiting_model = get_pred_model(X_scale.shape[1],model_def,dropout,residual)\n",
    "\n",
    "meter_waiting_model.fit(x=X_scale,y=y,batch_size=512,epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(meter_waiting_representation, \"meter_waiting_representation.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_waiting_representation.save('models/meter_waiting_representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meter waiting fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'meter_waiting_fare'\n",
    "# cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']\n",
    "cols = ['additional_fare', \n",
    "    'meter_waiting',    \n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[train_df['label']==1][cols]\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "\n",
    "y = train_df[train_df['label']==1][target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scale, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(params):\n",
    "    model_def = params['model']\n",
    "    dropout = params['dropout']\n",
    "    residual = params['residual']\n",
    "    \n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session() \n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def,dropout,residual))\n",
    "\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout,residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),verbose=False,callbacks=callbacks+[tensorboard_callback])\n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    [60,80,80,60,40,20,10],\n",
    "    [60,80,80,60,40,20,10,5],\n",
    "    [60,80,100,80,60,40,20,10],\n",
    "    [60,80,100,80,60,40,20,10,5],    \n",
    "    [60,80,60,40,20,10],\n",
    "    [60,80,60,40,20,10,5],\n",
    "    \n",
    "    [60,80,60,80],\n",
    "    [60,80,60,80,60],\n",
    "    [60,80,60,80,60,80],\n",
    "    \n",
    "    [60,40,60,40],\n",
    "    [60,40,60,40,60],\n",
    "    [60,40,60,40,60,40],\n",
    "    \n",
    "    [60,60,60],\n",
    "    [60,60,60,60],\n",
    "    [80,80,80],\n",
    "    [80,80,80,80],\n",
    "    [40,40,40],\n",
    "    [40,40,40,40],\n",
    "    \n",
    "    [40,30,20,10],\n",
    "    [40,30,20,10,5]\n",
    "]\n",
    "\n",
    "dropouts = [\n",
    "    0.2,0.4,0.6,0.8\n",
    "]\n",
    "\n",
    "residuals = [\n",
    "    True, False\n",
    "]\n",
    "\n",
    "best_config = {}\n",
    "best_score = float('inf') \n",
    "score_config = {}\n",
    "for model in tqdm(models):\n",
    "    for dropout in dropouts:\n",
    "        for residual in residuals:\n",
    "            params = {\n",
    "                'model':model,\n",
    "                'dropout':dropout,\n",
    "                'residual':residual\n",
    "            }\n",
    "            score = get_score(params)\n",
    "            score_config[score] = params\n",
    "            if score < best_score:\n",
    "                best_config = params\n",
    "                best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score ,best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(config):\n",
    "    for each in score_config:\n",
    "        if score_config[each] == config:\n",
    "            return each\n",
    "        \n",
    "sorted(list(score_config.values()),key=get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "# model_def = [60, 80, 100, 80, 60, 40, 20, 10]\n",
    "model_def = [60,60,60]\n",
    "dropout = 0.2\n",
    "residual = False\n",
    "\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in kf.split(X_scale, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "        \n",
    "    X_train, X_valid = X_scale[train_index], X_scale[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    _,model = get_pred_model(X.shape[1],model_def,dropout, residual)\n",
    "    model.fit(x=X_train,y=y_train,batch_size=512,epochs=500,validation_data=(X_valid,y_valid),callbacks=callbacks)\n",
    "    \n",
    "    y_hat = model.predict(X_valid)    \n",
    "    score = mean_squared_error(y_valid, y_hat) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores),validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_waiting_fare_representation ,meter_waiting_fare_model = get_pred_model(X_scale.shape[1],model_def,dropout, residual)\n",
    "\n",
    "meter_waiting_fare_model.fit(x=X_scale,y=y,batch_size=512,epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(meter_waiting_fare_representation, \"meter_waiting_fare_representation.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_waiting_fare_representation.save('models/meter_waiting_fare_representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "def get_log_dir(model):\n",
    "    model_name = '-'.join(map(lambda x: str(x),model))\n",
    "    return f'./logs/{model_name}'\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "def get_combined_model(fare_model, duration_model, meter_waiting_model, meter_waiting_fare_model, model_def=[100,50], freeze_input=True):\n",
    "    if freeze_input:\n",
    "        fare_model.trainable = False\n",
    "        duration_model.trainable = False\n",
    "        meter_waiting_model.trainable = False\n",
    "        meter_waiting_fare_model.trainable = False\n",
    "    \n",
    "    fare_input = Input(shape=(fare_model.input.shape[1],), name='fare_input')\n",
    "    fare = fare_model(fare_input)\n",
    "    \n",
    "    duration_input = Input(shape=(duration_model.input.shape[1],), name='duration_input')\n",
    "    duration = fare_model(duration_input)\n",
    "    \n",
    "    meter_waiting_input = Input(shape=(meter_waiting_model.input.shape[1],), name='meter_waiting_input')\n",
    "    meter_waiting = fare_model(meter_waiting_input)\n",
    "    \n",
    "    meter_waiting_fare_input = Input(shape=(meter_waiting_fare_model.input.shape[1],), name='meter_waiting_fare_input')\n",
    "    meter_waiting_fare = fare_model(meter_waiting_fare_input)\n",
    "    \n",
    "    X = concatenate([fare,duration,meter_waiting,meter_waiting_fare])\n",
    "    \n",
    "    for nodes in model_def:\n",
    "        X = Dense(nodes, activation='relu')(X)\n",
    "    output_layer = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model([fare_input,duration_input,meter_waiting_input,meter_waiting_fare_input],output_layer)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule), \n",
    "                  loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "                  metrics=[tfa.metrics.F1Score(num_classes=2,average='micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "fare_representation = tf.keras.models.load_model('models/fare_representation')\n",
    "duration_representation = tf.keras.models.load_model('models/duration_representation')\n",
    "meter_waiting_representation = tf.keras.models.load_model('models/meter_waiting_representation')\n",
    "meter_waiting_fare_representation = tf.keras.models.load_model('models/meter_waiting_fare_representation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference'\n",
    "]\n",
    "\n",
    "fare_features = ['additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "duration_features = ['additional_fare', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_features = ['additional_fare', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "\n",
    "meter_waiting_fare_features = ['additional_fare', \n",
    "    'meter_waiting',    \n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'duration',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features]\n",
    "y = train_df['label']\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "train[features] = X_scale\n",
    "\n",
    "test = test_df.copy()\n",
    "test[features] = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train[features], y, test_size=0.33, random_state=0,stratify=y)\n",
    "X_train_fare, X_train_duration, X_train_meter_waiting,X_train_meter_waiting_fare = X_train[fare_features],X_train[duration_features],X_train[meter_waiting_features],X_train[meter_waiting_fare_features]\n",
    "X_valid_fare, X_valid_duration, X_valid_meter_waiting,X_valid_meter_waiting_fare = X_valid[fare_features],X_valid[duration_features],X_valid[meter_waiting_features],X_valid[meter_waiting_fare_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model_def):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_log_dir(model_def))\n",
    "    model = get_combined_model(fare_representation,\n",
    "                               duration_representation,\n",
    "                               meter_waiting_representation,\n",
    "                               meter_waiting_fare_representation,\n",
    "                               model_def=model_def)\n",
    "\n",
    "    model.fit({'fare_input':X_train_fare,\n",
    "                  'duration_input':X_train_duration,\n",
    "                  'meter_waiting_input':X_train_meter_waiting,\n",
    "                  'meter_waiting_fare_input':X_train_meter_waiting_fare},\n",
    "                  y_train,\n",
    "                  batch_size=512,\n",
    "                  epochs=500,\n",
    "                  validation_data=({'fare_input':X_valid_fare,\n",
    "                  'duration_input':X_valid_duration,\n",
    "                  'meter_waiting_input':X_valid_meter_waiting,\n",
    "                  'meter_waiting_fare_input':X_valid_meter_waiting_fare},y_valid),\n",
    "              callbacks=callbacks + [tensorboard_callback],\n",
    "              verbose=False)\n",
    "    y_hat = model.predict({'fare_input':X_valid_fare,\n",
    "              'duration_input':X_valid_duration,\n",
    "              'meter_waiting_input':X_valid_meter_waiting,\n",
    "              'meter_waiting_fare_input':X_valid_meter_waiting_fare})\n",
    "\n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [    \n",
    "    (800,400,200,100,50),\n",
    "    (800,400,200,100,50,25),\n",
    "    (800,400,200,100,50,25,10),\n",
    "    (800,400,200,100,50,25,10,5),\n",
    "\n",
    "    (400,800,400),\n",
    "    (400,800,400,100),\n",
    "    (400,800,400,100,50),\n",
    "    (400,800,400,100,50,20),\n",
    "    (400,800,400,100,50,20,10),\n",
    "    \n",
    "    (1000,800,400,200,100,50),\n",
    "    (1000,800,400,200,100,50,25),\n",
    "    (1000,800,400,200,100,50,25,10),\n",
    "    (1000,800,400,200,100,50,25,10,5),\n",
    "    \n",
    "    (450,900,450),\n",
    "    (450,900,450,100),\n",
    "    (450,900,450,100,50),\n",
    "    (450,900,450,100,50,20),\n",
    "    (450,900,450,100,50,20,10),\n",
    "    \n",
    "    (400,800,400,800),\n",
    "    (400,800,400,800,100),\n",
    "    (400,800,400,800,100,50),\n",
    "    (400,800,400,800,100,50,20),\n",
    "    (400,800,400,800,100,50,20,10),\n",
    "    \n",
    "    (400,800,400,800,400),\n",
    "    (400,800,400,800,400,100),\n",
    "    (400,800,400,800,400,100,50),\n",
    "    (400,800,400,800,400,100,50,20),\n",
    "    (400,800,400,800,400,100,50,20,10),\n",
    "    \n",
    "    (450,900,450,900),\n",
    "    (450,900,450,900,100),\n",
    "    (450,900,450,900,100,50),\n",
    "    (450,900,450,900,100,50,20),\n",
    "    (450,900,450,900,100,50,20,10),\n",
    "]\n",
    "best_score = 0\n",
    "best_model = None\n",
    "model_score = {}\n",
    "for model in tqdm(models):\n",
    "    score = get_score(model)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "    model_score[model] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(models,key=lambda x:model_score[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "model_def=(400, 800, 400, 100, 50, 20, 10)\n",
    "# model_def=(400, 800, 400, 100, 50, 20)\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "fold=1\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    print('fold:',fold)\n",
    "    fold += 1\n",
    "    \n",
    "    X_fare_train, X_fare_test = train[fare_features].iloc[train_index,:],train[fare_features].iloc[test_index,:]\n",
    "    X_duration_train, X_duration_test = train[duration_features].iloc[train_index,:],train[duration_features].iloc[test_index,:]\n",
    "    X_meter_waiting_train, X_meter_waiting_test = train[meter_waiting_features].iloc[train_index,:],train[meter_waiting_features].iloc[test_index,:]\n",
    "    X_meter_waiting_fare_train, X_meter_waiting_fare_test = train[meter_waiting_fare_features].iloc[train_index,:],train[meter_waiting_fare_features].iloc[test_index,:]\n",
    "    \n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    model = get_combined_model(fare_representation,\n",
    "                           duration_representation,\n",
    "                           meter_waiting_representation,\n",
    "                           meter_waiting_fare_representation,\n",
    "                           model_def=model_def)\n",
    "    model.fit({'fare_input':X_fare_train,\n",
    "              'duration_input':X_duration_train,\n",
    "              'meter_waiting_input':X_meter_waiting_train,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_train},\n",
    "              y_train,\n",
    "              batch_size=512,\n",
    "              epochs=500,\n",
    "              validation_data=({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test},y_valid),callbacks=callbacks)\n",
    "    y_hat = model.predict({'fare_input':X_fare_test,\n",
    "              'duration_input':X_duration_test,\n",
    "              'meter_waiting_input':X_meter_waiting_test,\n",
    "              'meter_waiting_fare_input':X_meter_waiting_fare_test})\n",
    "    \n",
    "    y_hat = np.where(y_hat > 0.5,1,0)\n",
    "    score = f1_score(y_valid, y_hat, average='micro')\n",
    "    validation_scores.append(score)\n",
    "    print('validation score:', score)\n",
    "    \n",
    "    X_fare, X_duration, X_meter_waiting,X_X_meter_waiting_fare = test[fare_features],test[duration_features],test[meter_waiting_features],test[meter_waiting_fare_features]\n",
    "    \n",
    "    preds = model.predict({'fare_input':X_fare,\n",
    "              'duration_input':X_duration,\n",
    "              'meter_waiting_input':X_meter_waiting,\n",
    "              'meter_waiting_fare_input':X_X_meter_waiting_fare}).reshape(test_preds.shape)\n",
    "    test_preds += preds\n",
    "    models.append(model)\n",
    "    \n",
    "    X_fare, X_duration, X_meter_waiting,X_X_meter_waiting_fare = train[fare_features],train[duration_features],train[meter_waiting_features],train[meter_waiting_fare_features]\n",
    "    preds = model.predict({'fare_input':X_fare,\n",
    "              'duration_input':X_duration,\n",
    "              'meter_waiting_input':X_meter_waiting,\n",
    "              'meter_waiting_fare_input':X_X_meter_waiting_fare}).reshape(train_preds.shape)\n",
    "    train_preds += preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores), validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores) , np.std(validation_scores), validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]\n",
    "\n",
    "tf.keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(test_preds > 1.5, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'].sum() / submission_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
