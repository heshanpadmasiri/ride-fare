{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "test_df = test_df.fillna(0)\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['label'].values\n",
    "y.sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy = 0.125\n",
    "\n",
    "# sampling_strategy = 0.5\n",
    "\n",
    "ros = RandomOverSampler(random_state=0,sampling_strategy=sampling_strategy)\n",
    "train_df,y = ros.fit_resample(train_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'RMSE',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'RMSE'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.corr()['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols].values\n",
    "y = data['fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "\n",
    "    model = LinearRegression()\n",
    "#     model = SVR()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare'] = train_preds\n",
    "test_df['predicted_fare'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_diff'] = train_df['fare'] - train_df['predicted_fare']\n",
    "test_df['predicted_fare_diff'] = test_df['fare'] - test_df['predicted_fare']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_diff_per_fare'] = train_df['predicted_fare_diff'] / (train_df['fare']+1)\n",
    "test_df['predicted_fare_diff_per_fare'] = test_df['predicted_fare_diff'] / (test_df['fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_diff_per_predicted_fare'] = train_df['predicted_fare_diff'] / (train_df['predicted_fare']+1)\n",
    "test_df['predicted_fare_diff_per_predicted_fare'] = test_df['predicted_fare_diff'] / (test_df['predicted_fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare_per_distance'] = train_df['fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare_per_distance'] = test_df['fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_per_distance'] = train_df['predicted_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare_per_distance'] = test_df['predicted_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_diff_per_distance'] = train_df['predicted_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare_diff_per_distance'] = test_df['predicted_fare_diff'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_diff_per_fare'] = train_df['predicted_fare_diff'] / (train_df['fare']+1)\n",
    "test_df['predicted_fare_diff_per_fare'] = test_df['predicted_fare_diff'] / (test_df['fare']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['meter_waiting','meter_waiting_fare','fare','is_more_than_one_day','cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols].values\n",
    "y = data['duration'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duration'] = train_preds\n",
    "test_df['predicted_duration'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duration_diff'] = train_df['duration'] - train_df['predicted_duration']\n",
    "test_df['predicted_duration_diff'] = test_df['duration'] - test_df['predicted_duration']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duraton_diff_per_duraton'] = train_df['predicted_duration_diff'] / (train_df['duration']+1)\n",
    "test_df['predicted_duraton_diff_per_duraton'] = test_df['predicted_duration_diff'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duraton_diff_per_predicted_duration'] = train_df['predicted_duration_diff'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_duraton_diff_per_predicted_duration'] = test_df['predicted_duration_diff'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duraton_diff_per_distance'] = train_df['predicted_duration_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_duraton_diff_per_distance'] = test_df['predicted_duration_diff'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare_per_duration'] = train_df['fare'] / (train_df['duration']+1)\n",
    "test_df['fare_per_duration'] = test_df['fare'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_per_duration'] = train_df['predicted_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare_per_duration'] = test_df['predicted_fare'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare_per_duration_diff'] = train_df['fare_per_duration'] - train_df['predicted_fare_per_duration']\n",
    "test_df['predicted_fare_per_duration_diff'] = test_df['fare_per_duration'] - test_df['predicted_fare_per_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['avg_speed'] = train_df['distance_km'] / (train_df['duration'] + 1)\n",
    "test_df['avg_speed'] = test_df['distance_km'] / (test_df['duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_avg_speed'] = train_df['distance_km'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_avg_speed'] = test_df['distance_km'] / (test_df['predicted_duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_avg_speed_diff'] = train_df['avg_speed'] - train_df['predicted_avg_speed']\n",
    "test_df['predicted_avg_speed_diff'] = test_df['avg_speed'] - test_df['predicted_avg_speed']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meter waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting_fare','fare','cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols].values\n",
    "y = data['meter_waiting'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting'] = train_preds\n",
    "test_df['predicted_meter_waiting'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_diff'] = train_df['meter_waiting'] - train_df['predicted_meter_waiting']\n",
    "test_df['predicted_meter_waiting_diff'] = test_df['meter_waiting'] - test_df['predicted_meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_diff_per_meter_waiting'] = train_df['predicted_meter_waiting_diff'] / (train_df['meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_meter_waiting'] = test_df['predicted_meter_waiting_diff'] / (test_df['meter_waiting'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_diff_per_distance'] = train_df['predicted_meter_waiting_diff'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_distance'] = test_df['predicted_meter_waiting_diff'] / (test_df['distance_km'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_diff_per_predicted_meter_waiting'] = train_df['predicted_meter_waiting_diff'] / (train_df['predicted_meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_predicted_meter_waiting'] = test_df['predicted_meter_waiting_diff'] / (test_df['predicted_meter_waiting'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_per_duration'] = train_df['meter_waiting'] / (train_df['duration']+1)\n",
    "test_df['meter_waiting_per_duration'] = test_df['meter_waiting'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_per_duration'] = train_df['predicted_meter_waiting'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_meter_waiting_per_duration'] = test_df['predicted_meter_waiting'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_per_duration_diff'] = train_df['meter_waiting_per_duration'] - train_df['predicted_meter_waiting_per_duration']\n",
    "test_df['predicted_meter_waiting_per_duration_diff'] = test_df['meter_waiting_per_duration'] - test_df['predicted_meter_waiting_per_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meter waiting fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['meter_waiting_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting','fare','is_more_than_one_day','cal_time_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols].values\n",
    "y = data['meter_waiting_fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare'] = train_preds\n",
    "test_df['predicted_meter_waiting_fare'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_diff'] = train_df['meter_waiting_fare'] - train_df['predicted_meter_waiting_fare']\n",
    "test_df['predicted_meter_waiting_fare_diff'] = test_df['meter_waiting_fare'] - test_df['predicted_meter_waiting_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_diff_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['meter_waiting_fare']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['meter_waiting_fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_diff_per_distance'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_distance'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['predicted_meter_waiting_fare']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['predicted_meter_waiting_fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_fare_per_meter_waiting'] = train_df['meter_waiting_fare'] / train_df['meter_waiting']\n",
    "test_df['meter_waiting_fare_per_meter_waiting'] = test_df['meter_waiting_fare'] / test_df['meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_per_meter_waiting'] = train_df['predicted_meter_waiting_fare'] / train_df['predicted_meter_waiting']\n",
    "test_df['predicted_meter_waiting_fare_per_meter_waiting'] = test_df['predicted_meter_waiting_fare'] / test_df['predicted_meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_per_meter_waiting_diff'] = train_df['meter_waiting_fare_per_meter_waiting'] - train_df['predicted_meter_waiting_fare_per_meter_waiting']\n",
    "test_df['predicted_meter_waiting_fare_per_meter_waiting_diff'] = test_df['meter_waiting_fare_per_meter_waiting'] - test_df['predicted_meter_waiting_fare_per_meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_fare_per_duration'] = train_df['meter_waiting_fare'] / train_df['duration']\n",
    "test_df['meter_waiting_fare_per_duration'] = test_df['meter_waiting_fare'] / test_df['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_per_duration'] = train_df['predicted_meter_waiting_fare'] / train_df['predicted_duration']\n",
    "test_df['predicted_meter_waiting_fare_per_duration'] = test_df['predicted_meter_waiting_fare'] / test_df['predicted_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare_per_duration_diff'] = train_df['meter_waiting_fare_per_duration'] - train_df['predicted_meter_waiting_fare_per_duration']\n",
    "test_df['predicted_meter_waiting_fare_per_duration_diff'] = test_df['meter_waiting_fare_per_duration'] - test_df['predicted_meter_waiting_fare_per_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addtional fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['meter_waiting_fare_per_duration','meter_waiting_per_duration','fare_per_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols].values\n",
    "y = data['additional_fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = np.nan_to_num(scaler.transform(X_train_df))\n",
    "X_test_df = np.nan_to_num(scaler.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_additional_fare'] = train_preds\n",
    "test_df['predicted_additional_fare'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_additional_fare_diff'] = train_df['additional_fare'] - train_df['predicted_additional_fare']\n",
    "test_df['predicted_additional_fare_diff'] = test_df['additional_fare'] - test_df['predicted_additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_additional_fare_diff_per_additional_fare'] = train_df['predicted_additional_fare_diff'] / (train_df['additional_fare']+1)\n",
    "test_df['predicted_additional_fare_diff_per_additional_fare'] = test_df['predicted_additional_fare_diff'] / (test_df['additional_fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_addtional_fare_per_fare'] = train_df['predicted_additional_fare'] / (train_df['predicted_fare']+1)\n",
    "test_df['predicted_addtional_fare_per_fare'] = test_df['predicted_additional_fare'] / (test_df['predicted_fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['addtional_fare_per_fare'] = train_df['additional_fare'] / (train_df['fare']+1)\n",
    "test_df['addtional_fare_per_fare'] = test_df['additional_fare'] / (test_df['fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['addtional_fare_per_distance'] = train_df['additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['addtional_fare_per_distance'] = test_df['additional_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_addtional_fare_per_distance'] = train_df['predicted_additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_addtional_fare_per_distance'] = test_df['predicted_additional_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_addtional_fare_diff_per_distance'] = train_df['predicted_additional_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_addtional_fare_diff_per_distance'] = test_df['predicted_additional_fare_diff'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['addtional_fare_per_duration'] = train_df['additional_fare'] / (train_df['duration']+1)\n",
    "test_df['addtional_fare_per_duration'] = test_df['additional_fare'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_addtional_fare_per_duration'] = train_df['predicted_additional_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_addtional_fare_per_duration'] = test_df['predicted_additional_fare'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare'] = train_df['fare'] - train_df['additional_fare']\n",
    "test_df['fare-additional_fare'] = test_df['fare'] - test_df['additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare'] = train_df['predicted_fare'] - train_df['predicted_additional_fare']\n",
    "test_df['predicted_fare-additional_fare'] = test_df['predicted_fare'] - test_df['predicted_additional_fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare-meter_waiting_fare'] = train_df['fare'] - (train_df['additional_fare'] + train_df['meter_waiting_fare'])\n",
    "test_df['fare-additional_fare-meter_waiting_fare'] = test_df['fare'] - (test_df['additional_fare'] + test_df['meter_waiting_fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare-meter_waiting_fare'] = train_df['predicted_fare'] - (train_df['predicted_additional_fare'] + train_df['predicted_meter_waiting_fare'])\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare'] = test_df['predicted_fare'] - (test_df['predicted_additional_fare'] + test_df['predicted_meter_waiting_fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare_per_distance'] = train_df['fare-additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare-additional_fare_per_distance'] = test_df['fare-additional_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare_per_distance'] = train_df['predicted_fare-additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare-additional_fare_per_distance'] = test_df['predicted_fare-additional_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare_per_duration'] = train_df['fare-additional_fare'] / (train_df['duration']+1)\n",
    "test_df['fare-additional_fare_per_duration'] = test_df['fare-additional_fare'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare_per_duration'] = train_df['predicted_fare-additional_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare-additional_fare_per_duration'] = test_df['predicted_fare-additional_fare'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare-meter_waiting_fare_per_distance'] = train_df['fare-additional_fare-meter_waiting_fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare-additional_fare-meter_waiting_fare_per_distance'] = test_df['fare-additional_fare-meter_waiting_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare-meter_waiting_fare_per_distance'] = train_df['predicted_fare-additional_fare-meter_waiting_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare_per_distance'] = test_df['predicted_fare-additional_fare-meter_waiting_fare'] / (test_df['distance_km']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare-additional_fare-meter_waiting_fare_per_duration'] = train_df['fare-additional_fare-meter_waiting_fare'] / (train_df['duration']+1)\n",
    "test_df['fare-additional_fare-meter_waiting_fare_per_duration'] = test_df['fare-additional_fare-meter_waiting_fare'] / (test_df['duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare-additional_fare-meter_waiting_fare_per_duration'] = train_df['predicted_fare-additional_fare-meter_waiting_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare_per_duration'] = test_df['predicted_fare-additional_fare-meter_waiting_fare'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meter waiting till pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['meter_waiting_till_pickup'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df[train_df['label'] == 1].dropna()\n",
    "y = data['meter_waiting_till_pickup'].values\n",
    "X = data.drop(['label','meter_waiting_till_pickup'],axis=1)\n",
    "cols = X.columns\n",
    "X = X.values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = np.nan_to_num(scaler.transform(X_train_df))\n",
    "X_test_df = np.nan_to_num(scaler.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test),verbose=10)\n",
    "   \n",
    "#     model = SVR()\n",
    "#     model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup'] = train_preds\n",
    "test_df['predicted_meter_waiting_till_pickup'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_diff'] = train_df['meter_waiting_till_pickup'] - train_df['predicted_meter_waiting_till_pickup']\n",
    "test_df['predicted_meter_waiting_till_pickup_diff'] = test_df['meter_waiting_till_pickup'] - test_df['predicted_meter_waiting_till_pickup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup'] = train_df['predicted_meter_waiting_till_pickup_diff'] / (train_df['meter_waiting_till_pickup']+1)\n",
    "test_df['predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup'] = test_df['predicted_meter_waiting_till_pickup_diff'] / (test_df['meter_waiting_till_pickup']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_till_pickup_per_meter_waiting'] = train_df['meter_waiting_till_pickup'] / (train_df['meter_waiting'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_meter_waiting'] = test_df['meter_waiting_till_pickup'] / (test_df['meter_waiting'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_meter_waiting'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting_diff'] = train_df['meter_waiting_till_pickup_per_meter_waiting'] - train_df['predicted_meter_waiting_till_pickup_per_meter_waiting']\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting_diff'] = test_df['meter_waiting_till_pickup_per_meter_waiting'] - test_df['predicted_meter_waiting_till_pickup_per_meter_waiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_after_pickup'] = train_df['meter_waiting'] - train_df['meter_waiting_till_pickup']\n",
    "test_df['meter_waiting_after_pickup'] = test_df['meter_waiting'] - test_df['meter_waiting_till_pickup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_after_pickup'] = train_df['predicted_meter_waiting'] - train_df['predicted_meter_waiting_till_pickup']\n",
    "test_df['predicted_meter_waiting_after_pickup'] = test_df['predicted_meter_waiting'] - test_df['predicted_meter_waiting_till_pickup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_after_pickup_per_duration'] = train_df['meter_waiting_after_pickup'] / (train_df['duration'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_duration'] = test_df['meter_waiting_after_pickup'] / (test_df['duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_after_pickup_per_duration'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_duration'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_till_pickup_per_duration'] = train_df['meter_waiting_till_pickup'] / (train_df['duration'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_duration'] = test_df['meter_waiting_till_pickup'] / (test_df['duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_duration'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_duration'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_duration'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_till_pickup_per_distance'] = train_df['meter_waiting_till_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_distance'] = test_df['meter_waiting_till_pickup'] / (test_df['distance_km'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_distance'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_distance'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['distance_km'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_after_pickup_per_distance'] = train_df['meter_waiting_after_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_distance'] = test_df['meter_waiting_after_pickup'] / (test_df['distance_km'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_after_pickup_per_distance'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_distance'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['distance_km'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_till_pickup_per_fare'] = train_df['meter_waiting_till_pickup'] / (train_df['fare'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_fare'] = test_df['meter_waiting_till_pickup'] / (test_df['fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_fare'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_fare'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_after_pickup_per_fare'] = train_df['meter_waiting_after_pickup'] / (train_df['fare'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_fare'] = test_df['meter_waiting_after_pickup'] / (test_df['fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_after_pickup_per_fare'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_fare'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_till_pickup_per_meter_waiting_fare'] = train_df['meter_waiting_till_pickup'] / (train_df['meter_waiting_fare'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_meter_waiting_fare'] = test_df['meter_waiting_till_pickup'] / (test_df['meter_waiting_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_meter_waiting_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_meter_waiting_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_waiting_after_pickup_per_meter_waiting_fare'] = train_df['meter_waiting_after_pickup'] / (train_df['meter_waiting_fare'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_meter_waiting_fare'] = test_df['meter_waiting_after_pickup'] / (test_df['meter_waiting_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_after_pickup_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_meter_waiting_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_meter_waiting_fare'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anomaly = pd.read_csv('train_df_anomaly.csv')\n",
    "test_anomaly = pd.read_csv('test_df_anomaly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_columns = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in anomaly_columns:\n",
    "    train_df[col] = 1-train_anomaly[col]\n",
    "    test_df[col] = 1-test_anomaly[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_final_blanced.csv',index=False)\n",
    "test_df.to_csv('test_df_final_blanced.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final_blanced.csv')\n",
    "test_df = pd.read_csv('test_df_final_blanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_multiplicatives = {\n",
    "    'fare_anomaly':[\n",
    "        'predicted_fare_diff',\n",
    "        'predicted_fare_diff_per_fare',\n",
    "        'predicted_fare_diff_per_distance',\n",
    "    ],\n",
    "    'additional_fare_anomaly':[\n",
    "        'predicted_additional_fare_diff',\n",
    "        'predicted_additional_fare_diff_per_additional_fare',\n",
    "        'predicted_addtional_fare_per_distance',\n",
    "    ],\n",
    "    'duration_anomaly':[\n",
    "        'predicted_duration_diff', \n",
    "        'predicted_duraton_diff_per_duraton',\n",
    "        'predicted_duraton_diff_per_distance', \n",
    "    ],\n",
    "    'meter_waiting_anomaly':[\n",
    "        'predicted_meter_waiting_diff',\n",
    "        'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "        'predicted_meter_waiting_diff_per_distance'\n",
    "    ],\n",
    "    'meter_waiting_fare_anomaly':[\n",
    "        'predicted_meter_waiting_fare_diff',\n",
    "        'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "        'predicted_meter_waiting_fare_diff_per_distance'\n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col1 in anomaly_multiplicatives:\n",
    "    for col2 in anomaly_multiplicatives[col1]:\n",
    "        name = f'{col1}_{col2}_prod'\n",
    "        train_df[name] = train_df[col1] * train_df[col2]\n",
    "        test_df[name] = test_df[col1] * test_df[col2]\n",
    "        new_cols.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='predicted_duraton_diff_per_duraton',y='predicted_duraton_diff_per_distance',data=train_df,hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duraton_diff_per_duraton@predicted_duraton_diff_per_distance'] = train_df['predicted_duraton_diff_per_duraton'] * train_df['predicted_duraton_diff_per_distance']\n",
    "test_df['predicted_duraton_diff_per_duraton@predicted_duraton_diff_per_distance'] = test_df['predicted_duraton_diff_per_duraton'] * test_df['predicted_duraton_diff_per_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_diff(col_name):\n",
    "    normalizer = StandardScaler()\n",
    "    normalizer.fit(train_df[train_df['label'] == 1][col_name].values.reshape(-1,1))\n",
    "\n",
    "    train_df[f'{col_name}_normalized'] = normalizer.transform(train_df[col_name].values.reshape(-1,1))\n",
    "    test_df[f'{col_name}_normalized'] = normalizer.transform(test_df[col_name].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cols = [\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare'\n",
    "]\n",
    "for col in diff_cols:\n",
    "    normalize_diff(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['pick_cluster']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_value(col):\n",
    "    grouping_order = ['pick_cluster','pickup_timeslot']\n",
    "    group = train_df[train_df['label'] == 1].groupby(grouping_order)[col].mean()\n",
    "    def f(row):\n",
    "        return group[row['pick_cluster']][row['pickup_timeslot']]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoding(col):\n",
    "    train_df[f'{col}_mean'] = train_df.apply(mean_value(col),axis=1)\n",
    "    test_df[f'{col}_mean'] = test_df.apply(mean_value(col),axis=1)\n",
    "    \n",
    "    train_df[f'{col}_mean_diff'] = train_df[f'{col}_mean'] - train_df[col]\n",
    "    test_df[f'{col}_mean_diff'] = test_df[f'{col}_mean'] - test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cols = [\n",
    "    'fare_per_distance',\n",
    "    'avg_speed', \n",
    "    'meter_waiting_per_duration', \n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'addtional_fare_per_duration'\n",
    "]\n",
    "for col in mean_cols:\n",
    "    mean_encoding(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_duration_diff',\n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_additional_fare_diff',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_bucket(column):\n",
    "    std = train_df[train_df['label']==1][column].std()\n",
    "    name = f'{column}_bucket'\n",
    "    train_df[name] = np.round((train_df[column]/std)+1).astype(int)\n",
    "    test_df[name] = np.round((test_df[column]/std)+1).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in cols:\n",
    "    col_bucket(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_multiplicatives = {\n",
    "    'predicted_fare_diff_bucket':[\n",
    "        'fare',\n",
    "        'predicted_fare',\n",
    "        'fare_per_distance',\n",
    "        'predicted_fare_per_distance',         \n",
    "    ],\n",
    "    'predicted_duration_diff_bucket':[\n",
    "        'duration',\n",
    "        'predicted_duration',\n",
    "        'avg_speed', \n",
    "        'predicted_avg_speed',         \n",
    "    ],\n",
    "    'predicted_meter_waiting_diff_bucket':[\n",
    "        'meter_waiting', \n",
    "        'predicted_meter_waiting', \n",
    "        'meter_waiting_per_duration', \n",
    "        'predicted_meter_waiting_per_duration',\n",
    "    ],\n",
    "    'predicted_meter_waiting_fare_diff_bucket':[\n",
    "        'meter_waiting_fare',\n",
    "        'predicted_meter_waiting_fare',\n",
    "        'meter_waiting_fare_per_meter_waiting',\n",
    "        'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "        'meter_waiting_fare_per_duration',\n",
    "        'predicted_meter_waiting_fare_per_duration',\n",
    "    ],\n",
    "    'predicted_additional_fare_diff':[\n",
    "        'additional_fare',\n",
    "        'predicted_additional_fare', \n",
    "        'predicted_addtional_fare_per_fare', \n",
    "        'addtional_fare_per_fare',\n",
    "        'addtional_fare_per_distance', \n",
    "        'predicted_addtional_fare_per_distance',\n",
    "        'addtional_fare_per_duration', \n",
    "        'predicted_addtional_fare_per_duration',\n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket in tqdm(bin_multiplicatives):\n",
    "    for col in bin_multiplicatives[bucket]:\n",
    "        name = f'{bucket}@{col}'\n",
    "        train_df[name] = train_df[bucket] * train_df[col]\n",
    "        test_df[name] = test_df[bucket] * test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_final_blanced.csv',index=False)\n",
    "test_df.to_csv('test_df_final_blanced.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final_blanced.csv')\n",
    "test_df = pd.read_csv('test_df_final_blanced.csv')\n",
    "\n",
    "features = [\n",
    "#     'additional_fare', \n",
    "#     'pickup_date', \n",
    "#     'pickup_hour',\n",
    "#     'pickup_minute', \n",
    "#     'drop_date', \n",
    "#     'drop_hour', \n",
    "#     'drop_minute',    \n",
    "#     'pick_cluster', \n",
    "#     'is_more_than_one_day', \n",
    "#     'distance_km', \n",
    "#     'pickup_timeslot', \n",
    "#     'day_of_week', \n",
    "#     'is_weekday', \n",
    "#     'cal_time_difference',\n",
    "    # noise columns    \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'fare',\n",
    "    'predicted_fare',\n",
    "    'fare_per_distance',\n",
    "    'predicted_fare_per_distance', \n",
    "    'predicted_duration',\n",
    "    'fare_per_duration',\n",
    "    'predicted_fare_per_duration',\n",
    "    'avg_speed', \n",
    "    'predicted_avg_speed', \n",
    "    'predicted_meter_waiting', \n",
    "    'meter_waiting_per_duration', \n",
    "    'predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_fare',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_additional_fare', \n",
    "    'predicted_addtional_fare_per_fare', \n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'predicted_addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration', \n",
    "    'predicted_addtional_fare_per_duration',\n",
    "    'predicted_duraton_diff_per_duraton@predicted_duraton_diff_per_distance',\n",
    "    'predicted_fare_diff_normalized',\n",
    "    'predicted_fare_diff_per_fare_normalized',\n",
    "    'predicted_fare_diff_per_predicted_fare_normalized', \n",
    "    'predicted_fare_diff_per_distance_normalized',\n",
    "    'predicted_duraton_diff_per_duraton_normalized',\n",
    "    'predicted_duraton_diff_per_predicted_duration_normalized', \n",
    "    'predicted_fare_per_duration_diff_normalized',\n",
    "    'predicted_avg_speed_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_per_duration_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff_normalized',\n",
    "    'predicted_additional_fare_diff_normalized',\n",
    "    'predicted_additional_fare_diff_per_additional_fare_normalized',\n",
    "    \n",
    "#     'fare_per_distance_mean',\n",
    "#     'avg_speed_mean', \n",
    "#     'meter_waiting_per_duration_mean', \n",
    "#     'meter_waiting_fare_per_meter_waiting_mean',\n",
    "#     'meter_waiting_fare_per_duration_mean',\n",
    "#     'addtional_fare_per_fare_mean',\n",
    "#     'addtional_fare_per_distance_mean', \n",
    "#     'addtional_fare_per_duration_mean', \n",
    "\n",
    "#     'fare_per_distance_mean_diff',\n",
    "#     'avg_speed_mean_diff', \n",
    "#     'meter_waiting_per_duration_mean_diff', \n",
    "#     'meter_waiting_fare_per_meter_waiting_mean_diff',\n",
    "#     'meter_waiting_fare_per_duration_mean_diff',\n",
    "#     'addtional_fare_per_fare_mean_diff',\n",
    "#     'addtional_fare_per_distance_mean_diff', \n",
    "#     'addtional_fare_per_duration_mean_diff'\n",
    "    'predicted_fare_diff_bucket',\n",
    "    'predicted_duration_diff_bucket',   \n",
    "    'predicted_meter_waiting_diff_bucket',\n",
    "    'predicted_meter_waiting_fare_diff_bucket',\n",
    "    'predicted_additional_fare_diff_bucket',\n",
    "    'predicted_fare_diff_bucket@fare',\n",
    "    'predicted_fare_diff_bucket@predicted_fare',\n",
    "    'predicted_fare_diff_bucket@fare_per_distance',\n",
    "    'predicted_fare_diff_bucket@predicted_fare_per_distance',\n",
    "    'predicted_duration_diff_bucket@duration',\n",
    "    'predicted_duration_diff_bucket@predicted_duration',\n",
    "    'predicted_duration_diff_bucket@avg_speed',\n",
    "    'predicted_duration_diff_bucket@predicted_avg_speed',\n",
    "    'predicted_meter_waiting_diff_bucket@meter_waiting',\n",
    "    'predicted_meter_waiting_diff_bucket@predicted_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_bucket@meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_diff_bucket@predicted_meter_waiting_per_duration',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@predicted_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@predicted_meter_waiting_fare_per_meter_waiting',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@meter_waiting_fare_per_duration',\n",
    "    'predicted_meter_waiting_fare_diff_bucket@predicted_meter_waiting_fare_per_duration',\n",
    "    'predicted_additional_fare_diff@additional_fare',\n",
    "    'predicted_additional_fare_diff@predicted_additional_fare',\n",
    "    'predicted_additional_fare_diff@predicted_addtional_fare_per_fare',\n",
    "    'predicted_additional_fare_diff@addtional_fare_per_fare',\n",
    "    'predicted_additional_fare_diff@addtional_fare_per_distance',\n",
    "    'predicted_additional_fare_diff@predicted_addtional_fare_per_distance',\n",
    "    'predicted_additional_fare_diff@addtional_fare_per_duration',\n",
    "    'predicted_additional_fare_diff@predicted_addtional_fare_per_duration'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'predicted_fare_diff_bucket',\n",
    "    'predicted_duration_diff_bucket',\n",
    "    'predicted_meter_waiting_diff_bucket',\n",
    "    'predicted_meter_waiting_fare_diff_bucket',\n",
    "    'predicted_additional_fare_diff_bucket',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values\n",
    "train_df = train_df.drop(['label'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [(labels.shape[0] - np.sum(labels)) / np.sum(labels),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights,\n",
    "    'border_count':512,\n",
    "#     'depth':6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "train_df_pool = Pool(data=train_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    \n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores), np.min(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 2, 1, 0)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model = models[np.argmin(validation_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pool = Pool(data=train_df,label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cv(cv_pool,cv_params,plot=True, fold_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(features):\n",
    "    features_to_drop = []\n",
    "    features_to_keep = []\n",
    "    for feature in features:\n",
    "        if feature in features_to_drop:\n",
    "            continue\n",
    "        highly_corr_features = list((np.array(features))[np.abs(train_df[features].corr()[feature]) > 0.8])\n",
    "        for each in highly_corr_features:\n",
    "            if each == feature or each in features_to_keep:\n",
    "                continue\n",
    "            else:\n",
    "                features_to_drop.append(each)\n",
    "        features_to_keep.append(feature)\n",
    "    return features_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = list(best_model.get_feature_importance(prettified=True)['Feature Id'].values)\n",
    "new_features = filter_features(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df[new_features].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[new_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train)\n",
    "    test_pool = Pool(data=X_test, label=y_test)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)\n",
    "    train_preds += model.predict_proba(train_df_pool)[:,1]\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df['catboost_low_corr'] = train_preds\n",
    "\n",
    "stacking_test_df['catboost_low_corr'] = submission_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 2, 1, 0)\n",
    "submission_df.to_csv('submission_filtered.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(validation_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.plot_tree(0,train_pools[np.argmax(validation_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pool = Pool(data=train_df,label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cv(cv_pool,cv_params,plot=True, fold_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
