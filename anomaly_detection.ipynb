{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation forests for anomaly detection on noise columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred(col, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[col].values\n",
    "\n",
    "    X_train_df = train_df[col].values\n",
    "    X_test_df = test_df[col].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        X_train = X_train.reshape((-1,1))\n",
    "        X_test = X_test.reshape((-1,1))\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1).reshape(y_test.shape)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df.reshape(-1,1)).reshape(X_train_df.shape).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df.reshape(-1,1)).reshape(X_test_df.shape).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "        \n",
    "    train_df[f'{col}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{col}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:08,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:additional_fare, mean:0.9250, std:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:05<00:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:duration, mean:0.9226, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:08<00:05,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting, mean:0.9141, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:10<00:02,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_fare, mean:0.9107, std:0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_till_pickup, mean:0.9122, std:0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for col in tqdm(cols):\n",
    "    validation_scores = anomaly_pred(col)\n",
    "    print(f'col:{col}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi column anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred_multi(cols, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[cols].values\n",
    "\n",
    "    X_train_df = train_df[cols].values\n",
    "    X_test_df = test_df[cols].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "#     print(X.shape)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "    name = '_'.join(cols)\n",
    "    train_df[f'{name}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{name}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration'], mean:0.9169, std:0.0165\n",
      "cols:['additional_fare', 'meter_waiting'], mean:0.9141, std:0.0130\n",
      "cols:['additional_fare', 'meter_waiting_fare'], mean:0.9097, std:0.0120\n",
      "cols:['additional_fare', 'meter_waiting_till_pickup'], mean:0.9144, std:0.0153\n",
      "cols:['duration', 'meter_waiting'], mean:0.9176, std:0.0031\n",
      "cols:['duration', 'meter_waiting_fare'], mean:0.9131, std:0.0045\n",
      "cols:['duration', 'meter_waiting_till_pickup'], mean:0.9174, std:0.0016\n",
      "cols:['meter_waiting', 'meter_waiting_fare'], mean:0.9146, std:0.0041\n",
      "cols:['meter_waiting', 'meter_waiting_till_pickup'], mean:0.9164, std:0.0008\n",
      "cols:['meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9137, std:0.0027\n"
     ]
    }
   ],
   "source": [
    "cols = ['additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        validation_scores = anomaly_pred_multi([col_1,col_2])\n",
    "        print(f'cols:{[col_1,col_2]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration', 'meter_waiting'], mean:0.9130, std:0.012472483371970643:.4f\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare'], mean:0.9126, std:0.01252459846549521:.4f\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_till_pickup'], mean:0.9143, std:0.013659357134191733:.4f\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare'], mean:0.9104, std:0.012413300529136924:.4f\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9136, std:0.012346456535686709:.4f\n",
      "cols:['additional_fare', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9114, std:0.012325466473065498:.4f\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9162, std:0.0033317506567712455:.4f\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9177, std:0.001213277263629811:.4f\n",
      "cols:['duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9156, std:0.0020295719989319133:.4f\n",
      "cols:['meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9161, std:0.002502891385251626:.4f\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            validation_scores = anomaly_pred_multi([col_1,col_2,col_3])\n",
    "            print(f'cols:{[col_1,col_2,col_3]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9163, std:0.0030666657540945035:.4f\n",
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9192, std:0.0028070447860475585:.4f\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9176, std:0.0035533524795091044:.4f\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9169, std:0.00308527123233422:.4f\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9166, std:0.003168951838263162:.4f\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            k = cols.index(col_3)\n",
    "            for col_4 in cols[k+1:]:                \n",
    "                validation_scores = anomaly_pred_multi([col_1,col_2,col_3,col_4])\n",
    "                print(f'cols:{[col_1,col_2,col_3,col_4]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9189834563552332, 0.0020987658400050775)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores = anomaly_pred_multi(cols)\n",
    "np.mean(validation_scores) , np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
       "       'meter_waiting_till_pickup', 'fare', 'pickup_date', 'pickup_hour',\n",
       "       'pickup_minute', 'drop_date', 'drop_hour', 'drop_minute',\n",
       "       'pick_cluster', 'is_more_than_one_day', 'distance_km', 'fare_per_km',\n",
       "       'pickup_timeslot', 'day_of_week', 'is_weekday', 'cal_time_difference',\n",
       "       'label', 'additional_fare_anomaly', 'duration_anomaly',\n",
       "       'meter_waiting_anomaly', 'meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_till_pickup_anomaly', 'additional_fare_duration_anomaly',\n",
       "       'additional_fare_meter_waiting_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_anomaly', 'duration_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values\n",
    "train_df = train_df.drop(['label'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9530599\ttest: 0.9521957\tbest: 0.9521957 (0)\ttotal: 59.1ms\tremaining: 59s\n",
      "10:\tlearn: 0.9533645\ttest: 0.9531395\tbest: 0.9531395 (5)\ttotal: 154ms\tremaining: 13.8s\n",
      "20:\tlearn: 0.9536295\ttest: 0.9531395\tbest: 0.9531395 (5)\ttotal: 224ms\tremaining: 10.4s\n",
      "30:\tlearn: 0.9538504\ttest: 0.9529455\tbest: 0.9531395 (5)\ttotal: 275ms\tremaining: 8.6s\n",
      "40:\tlearn: 0.9541514\ttest: 0.9533871\tbest: 0.9534754 (39)\ttotal: 321ms\tremaining: 7.51s\n",
      "50:\tlearn: 0.9543199\ttest: 0.9534668\tbest: 0.9534754 (39)\ttotal: 366ms\tremaining: 6.82s\n",
      "60:\tlearn: 0.9544084\ttest: 0.9533698\tbest: 0.9534754 (39)\ttotal: 412ms\tremaining: 6.34s\n",
      "70:\tlearn: 0.9546214\ttest: 0.9535294\tbest: 0.9535294 (68)\ttotal: 470ms\tremaining: 6.15s\n",
      "80:\tlearn: 0.9547058\ttest: 0.9537063\tbest: 0.9537063 (72)\ttotal: 521ms\tremaining: 5.91s\n",
      "90:\tlearn: 0.9547986\ttest: 0.9536977\tbest: 0.9537948 (82)\ttotal: 576ms\tremaining: 5.76s\n",
      "100:\tlearn: 0.9550160\ttest: 0.9535920\tbest: 0.9537948 (82)\ttotal: 628ms\tremaining: 5.59s\n",
      "110:\tlearn: 0.9553252\ttest: 0.9536461\tbest: 0.9538661 (103)\ttotal: 674ms\tremaining: 5.4s\n",
      "120:\tlearn: 0.9556320\ttest: 0.9533544\tbest: 0.9538661 (103)\ttotal: 726ms\tremaining: 5.28s\n",
      "130:\tlearn: 0.9557654\ttest: 0.9533544\tbest: 0.9538661 (103)\ttotal: 773ms\tremaining: 5.13s\n",
      "140:\tlearn: 0.9558098\ttest: 0.9534430\tbest: 0.9538661 (103)\ttotal: 822ms\tremaining: 5.01s\n",
      "150:\tlearn: 0.9559912\ttest: 0.9538519\tbest: 0.9538661 (103)\ttotal: 882ms\tremaining: 4.96s\n",
      "160:\tlearn: 0.9561248\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 960ms\tremaining: 5s\n",
      "170:\tlearn: 0.9562584\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 1.02s\tremaining: 4.95s\n",
      "180:\tlearn: 0.9563475\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 1.08s\tremaining: 4.88s\n",
      "190:\tlearn: 0.9565258\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 1.21s\tremaining: 5.11s\n",
      "200:\tlearn: 0.9566595\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 1.28s\tremaining: 5.07s\n",
      "210:\tlearn: 0.9568379\ttest: 0.9541182\tbest: 0.9541182 (201)\ttotal: 1.36s\tremaining: 5.07s\n",
      "220:\tlearn: 0.9569231\ttest: 0.9541182\tbest: 0.9541182 (201)\ttotal: 1.48s\tremaining: 5.21s\n",
      "230:\tlearn: 0.9570123\ttest: 0.9540208\tbest: 0.9541182 (201)\ttotal: 1.54s\tremaining: 5.13s\n",
      "240:\tlearn: 0.9570529\ttest: 0.9540208\tbest: 0.9541182 (201)\ttotal: 1.6s\tremaining: 5.05s\n",
      "250:\tlearn: 0.9571016\ttest: 0.9539321\tbest: 0.9541182 (201)\ttotal: 1.66s\tremaining: 4.97s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9541181945\n",
      "bestIteration = 201\n",
      "\n",
      "Shrink model to first 202 iterations.\n",
      "Validation f1 0.9541181945090741\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9530301\ttest: 0.9528844\tbest: 0.9528844 (0)\ttotal: 8.59ms\tremaining: 8.58s\n",
      "10:\tlearn: 0.9532364\ttest: 0.9529630\tbest: 0.9529630 (3)\ttotal: 66.3ms\tremaining: 5.96s\n",
      "20:\tlearn: 0.9534130\ttest: 0.9531395\tbest: 0.9532277 (19)\ttotal: 166ms\tremaining: 7.75s\n",
      "30:\tlearn: 0.9539830\ttest: 0.9534841\tbest: 0.9534841 (30)\ttotal: 224ms\tremaining: 6.99s\n",
      "40:\tlearn: 0.9545961\ttest: 0.9533265\tbest: 0.9534841 (30)\ttotal: 292ms\tremaining: 6.82s\n",
      "50:\tlearn: 0.9547566\ttest: 0.9533005\tbest: 0.9535466 (42)\ttotal: 351ms\tremaining: 6.54s\n",
      "60:\tlearn: 0.9549215\ttest: 0.9533890\tbest: 0.9535466 (42)\ttotal: 416ms\tremaining: 6.4s\n",
      "70:\tlearn: 0.9554377\ttest: 0.9533631\tbest: 0.9535466 (42)\ttotal: 488ms\tremaining: 6.39s\n",
      "80:\tlearn: 0.9557489\ttest: 0.9531686\tbest: 0.9535466 (42)\ttotal: 563ms\tremaining: 6.39s\n",
      "90:\tlearn: 0.9559268\ttest: 0.9529740\tbest: 0.9535466 (42)\ttotal: 624ms\tremaining: 6.23s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9535465925\n",
      "bestIteration = 42\n",
      "\n",
      "Shrink model to first 43 iterations.\n",
      "Validation f1 0.9535465924895689\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9530208\ttest: 0.9516473\tbest: 0.9516473 (0)\ttotal: 9.42ms\tremaining: 9.41s\n",
      "10:\tlearn: 0.9533204\ttest: 0.9532191\tbest: 0.9533247 (7)\ttotal: 59.3ms\tremaining: 5.33s\n",
      "20:\tlearn: 0.9534970\ttest: 0.9532191\tbest: 0.9533247 (7)\ttotal: 110ms\tremaining: 5.12s\n",
      "30:\tlearn: 0.9539788\ttest: 0.9535466\tbest: 0.9536436 (26)\ttotal: 165ms\tremaining: 5.17s\n",
      "40:\tlearn: 0.9541956\ttest: 0.9535294\tbest: 0.9536436 (26)\ttotal: 241ms\tremaining: 5.64s\n",
      "50:\tlearn: 0.9544716\ttest: 0.9535575\tbest: 0.9536436 (26)\ttotal: 313ms\tremaining: 5.83s\n",
      "60:\tlearn: 0.9548219\ttest: 0.9536461\tbest: 0.9536461 (55)\ttotal: 370ms\tremaining: 5.7s\n",
      "70:\tlearn: 0.9549064\ttest: 0.9534516\tbest: 0.9536461 (55)\ttotal: 429ms\tremaining: 5.61s\n",
      "80:\tlearn: 0.9552128\ttest: 0.9535402\tbest: 0.9536461 (55)\ttotal: 510ms\tremaining: 5.78s\n",
      "90:\tlearn: 0.9552572\ttest: 0.9536288\tbest: 0.9536461 (55)\ttotal: 572ms\tremaining: 5.71s\n",
      "100:\tlearn: 0.9558817\ttest: 0.9532762\tbest: 0.9537717 (92)\ttotal: 640ms\tremaining: 5.69s\n",
      "110:\tlearn: 0.9560680\ttest: 0.9530814\tbest: 0.9537717 (92)\ttotal: 705ms\tremaining: 5.65s\n",
      "120:\tlearn: 0.9561044\ttest: 0.9529839\tbest: 0.9537717 (92)\ttotal: 797ms\tremaining: 5.79s\n",
      "130:\tlearn: 0.9561894\ttest: 0.9536226\tbest: 0.9537717 (92)\ttotal: 869ms\tremaining: 5.76s\n",
      "140:\tlearn: 0.9563191\ttest: 0.9532501\tbest: 0.9537717 (92)\ttotal: 934ms\tremaining: 5.69s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9537717422\n",
      "bestIteration = 92\n",
      "\n",
      "Shrink model to first 93 iterations.\n",
      "Validation f1 0.9537717421635197\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9538121763873875, 0.00023510056290938325)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 2, 1, 0)\n",
    "submission_df.to_csv('submission_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_anomaly.csv',index=False)\n",
    "test_df.to_csv('test_df_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
