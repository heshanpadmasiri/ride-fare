{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation forests for anomaly detection on noise columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred(col, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[col].values\n",
    "\n",
    "    X_train_df = train_df[col].values\n",
    "    X_test_df = test_df[col].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        X_train = X_train.reshape((-1,1))\n",
    "        X_test = X_test.reshape((-1,1))\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1).reshape(y_test.shape)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df.reshape(-1,1)).reshape(X_train_df.shape).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df.reshape(-1,1)).reshape(X_test_df.shape).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "        \n",
    "    train_df[f'{col}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{col}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:additional_fare, mean:0.9250, std:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:04<00:06,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:duration, mean:0.9226, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:08<00:05,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting, mean:0.9141, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:10<00:02,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_fare, mean:0.9107, std:0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_till_pickup, mean:0.9122, std:0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for col in tqdm(cols):\n",
    "    validation_scores = anomaly_pred(col)\n",
    "    print(f'col:{col}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi column anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred_multi(cols, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[cols].values\n",
    "\n",
    "    X_train_df = train_df[cols].values\n",
    "    X_test_df = test_df[cols].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "#     print(X.shape)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "    name = '_'.join(cols)\n",
    "    train_df[f'{name}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{name}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration'], mean:0.9169, std:0.0165\n",
      "cols:['additional_fare', 'meter_waiting'], mean:0.9141, std:0.0130\n",
      "cols:['additional_fare', 'meter_waiting_fare'], mean:0.9097, std:0.0120\n",
      "cols:['additional_fare', 'meter_waiting_till_pickup'], mean:0.9144, std:0.0153\n",
      "cols:['duration', 'meter_waiting'], mean:0.9176, std:0.0031\n",
      "cols:['duration', 'meter_waiting_fare'], mean:0.9131, std:0.0045\n",
      "cols:['duration', 'meter_waiting_till_pickup'], mean:0.9174, std:0.0016\n",
      "cols:['meter_waiting', 'meter_waiting_fare'], mean:0.9146, std:0.0041\n",
      "cols:['meter_waiting', 'meter_waiting_till_pickup'], mean:0.9164, std:0.0008\n",
      "cols:['meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9137, std:0.0027\n"
     ]
    }
   ],
   "source": [
    "cols = ['additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        validation_scores = anomaly_pred_multi([col_1,col_2])\n",
    "        print(f'cols:{[col_1,col_2]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration', 'meter_waiting'], mean:0.9130, std:0.0125\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare'], mean:0.9126, std:0.0125\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_till_pickup'], mean:0.9143, std:0.0137\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare'], mean:0.9104, std:0.0124\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9136, std:0.0123\n",
      "cols:['additional_fare', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9114, std:0.0123\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9162, std:0.0033\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9177, std:0.0012\n",
      "cols:['duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9156, std:0.0020\n",
      "cols:['meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9161, std:0.0025\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            validation_scores = anomaly_pred_multi([col_1,col_2,col_3])\n",
    "            print(f'cols:{[col_1,col_2,col_3]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9163, std:0.0031\n",
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9192, std:0.0028\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9176, std:0.0036\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9169, std:0.0031\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9166, std:0.0032\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            k = cols.index(col_3)\n",
    "            for col_4 in cols[k+1:]:                \n",
    "                validation_scores = anomaly_pred_multi([col_1,col_2,col_3,col_4])\n",
    "                print(f'cols:{[col_1,col_2,col_3,col_4]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9189834563552332, 0.0020987658400050775)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores = anomaly_pred_multi(cols)\n",
    "np.mean(validation_scores) , np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
       "       'meter_waiting_till_pickup', 'fare', 'pickup_date', 'pickup_hour',\n",
       "       'pickup_minute', 'drop_date', 'drop_hour', 'drop_minute',\n",
       "       'pick_cluster', 'is_more_than_one_day', 'distance_km', 'fare_per_km',\n",
       "       'pickup_timeslot', 'day_of_week', 'is_weekday', 'cal_time_difference',\n",
       "       'label', 'additional_fare_anomaly', 'duration_anomaly',\n",
       "       'meter_waiting_anomaly', 'meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_till_pickup_anomaly', 'additional_fare_duration_anomaly',\n",
       "       'additional_fare_meter_waiting_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_anomaly', 'duration_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values\n",
    "train_df = train_df.drop(['label'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "train_df_pool = Pool(data=train_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9530599\ttest: 0.9521957\tbest: 0.9521957 (0)\ttotal: 4.68ms\tremaining: 4.67s\n",
      "10:\tlearn: 0.9533645\ttest: 0.9531395\tbest: 0.9531395 (5)\ttotal: 46.2ms\tremaining: 4.16s\n",
      "20:\tlearn: 0.9536295\ttest: 0.9531395\tbest: 0.9531395 (5)\ttotal: 89.6ms\tremaining: 4.17s\n",
      "30:\tlearn: 0.9538504\ttest: 0.9529455\tbest: 0.9531395 (5)\ttotal: 136ms\tremaining: 4.24s\n",
      "40:\tlearn: 0.9541514\ttest: 0.9533871\tbest: 0.9534754 (39)\ttotal: 179ms\tremaining: 4.17s\n",
      "50:\tlearn: 0.9543199\ttest: 0.9534668\tbest: 0.9534754 (39)\ttotal: 238ms\tremaining: 4.44s\n",
      "60:\tlearn: 0.9544084\ttest: 0.9533698\tbest: 0.9534754 (39)\ttotal: 283ms\tremaining: 4.36s\n",
      "70:\tlearn: 0.9546214\ttest: 0.9535294\tbest: 0.9535294 (68)\ttotal: 328ms\tremaining: 4.3s\n",
      "80:\tlearn: 0.9547058\ttest: 0.9537063\tbest: 0.9537063 (72)\ttotal: 374ms\tremaining: 4.24s\n",
      "90:\tlearn: 0.9547986\ttest: 0.9536977\tbest: 0.9537948 (82)\ttotal: 419ms\tremaining: 4.19s\n",
      "100:\tlearn: 0.9550160\ttest: 0.9535920\tbest: 0.9537948 (82)\ttotal: 473ms\tremaining: 4.21s\n",
      "110:\tlearn: 0.9553252\ttest: 0.9536461\tbest: 0.9538661 (103)\ttotal: 519ms\tremaining: 4.16s\n",
      "120:\tlearn: 0.9556320\ttest: 0.9533544\tbest: 0.9538661 (103)\ttotal: 564ms\tremaining: 4.1s\n",
      "130:\tlearn: 0.9557654\ttest: 0.9533544\tbest: 0.9538661 (103)\ttotal: 608ms\tremaining: 4.03s\n",
      "140:\tlearn: 0.9558098\ttest: 0.9534430\tbest: 0.9538661 (103)\ttotal: 653ms\tremaining: 3.98s\n",
      "150:\tlearn: 0.9559912\ttest: 0.9538519\tbest: 0.9538661 (103)\ttotal: 711ms\tremaining: 4s\n",
      "160:\tlearn: 0.9561248\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 761ms\tremaining: 3.96s\n",
      "170:\tlearn: 0.9562584\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 806ms\tremaining: 3.91s\n",
      "180:\tlearn: 0.9563475\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 855ms\tremaining: 3.87s\n",
      "190:\tlearn: 0.9565258\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 902ms\tremaining: 3.82s\n",
      "200:\tlearn: 0.9566595\ttest: 0.9539406\tbest: 0.9539406 (151)\ttotal: 958ms\tremaining: 3.81s\n",
      "210:\tlearn: 0.9568379\ttest: 0.9541182\tbest: 0.9541182 (201)\ttotal: 1.01s\tremaining: 3.79s\n",
      "220:\tlearn: 0.9569231\ttest: 0.9541182\tbest: 0.9541182 (201)\ttotal: 1.06s\tremaining: 3.74s\n",
      "230:\tlearn: 0.9570123\ttest: 0.9540208\tbest: 0.9541182 (201)\ttotal: 1.11s\tremaining: 3.69s\n",
      "240:\tlearn: 0.9570529\ttest: 0.9540208\tbest: 0.9541182 (201)\ttotal: 1.15s\tremaining: 3.63s\n",
      "250:\tlearn: 0.9571016\ttest: 0.9539321\tbest: 0.9541182 (201)\ttotal: 1.22s\tremaining: 3.63s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9541181945\n",
      "bestIteration = 201\n",
      "\n",
      "Shrink model to first 202 iterations.\n",
      "Validation f1 0.9541181945090741\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9530301\ttest: 0.9528844\tbest: 0.9528844 (0)\ttotal: 5.21ms\tremaining: 5.21s\n",
      "10:\tlearn: 0.9532364\ttest: 0.9529630\tbest: 0.9529630 (3)\ttotal: 47.6ms\tremaining: 4.28s\n",
      "20:\tlearn: 0.9534130\ttest: 0.9531395\tbest: 0.9532277 (19)\ttotal: 93.2ms\tremaining: 4.35s\n",
      "30:\tlearn: 0.9539830\ttest: 0.9534841\tbest: 0.9534841 (30)\ttotal: 139ms\tremaining: 4.35s\n",
      "40:\tlearn: 0.9545961\ttest: 0.9533265\tbest: 0.9534841 (30)\ttotal: 186ms\tremaining: 4.36s\n",
      "50:\tlearn: 0.9547566\ttest: 0.9533005\tbest: 0.9535466 (42)\ttotal: 246ms\tremaining: 4.58s\n",
      "60:\tlearn: 0.9549215\ttest: 0.9533890\tbest: 0.9535466 (42)\ttotal: 293ms\tremaining: 4.51s\n",
      "70:\tlearn: 0.9554377\ttest: 0.9533631\tbest: 0.9535466 (42)\ttotal: 337ms\tremaining: 4.42s\n",
      "80:\tlearn: 0.9557489\ttest: 0.9531686\tbest: 0.9535466 (42)\ttotal: 382ms\tremaining: 4.34s\n",
      "90:\tlearn: 0.9559268\ttest: 0.9529740\tbest: 0.9535466 (42)\ttotal: 427ms\tremaining: 4.26s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9535465925\n",
      "bestIteration = 42\n",
      "\n",
      "Shrink model to first 43 iterations.\n",
      "Validation f1 0.9535465924895689\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9530208\ttest: 0.9516473\tbest: 0.9516473 (0)\ttotal: 10ms\tremaining: 10s\n",
      "10:\tlearn: 0.9533204\ttest: 0.9532191\tbest: 0.9533247 (7)\ttotal: 65ms\tremaining: 5.84s\n",
      "20:\tlearn: 0.9534970\ttest: 0.9532191\tbest: 0.9533247 (7)\ttotal: 114ms\tremaining: 5.32s\n",
      "30:\tlearn: 0.9539788\ttest: 0.9535466\tbest: 0.9536436 (26)\ttotal: 158ms\tremaining: 4.94s\n",
      "40:\tlearn: 0.9541956\ttest: 0.9535294\tbest: 0.9536436 (26)\ttotal: 217ms\tremaining: 5.08s\n",
      "50:\tlearn: 0.9544716\ttest: 0.9535575\tbest: 0.9536436 (26)\ttotal: 265ms\tremaining: 4.93s\n",
      "60:\tlearn: 0.9548219\ttest: 0.9536461\tbest: 0.9536461 (55)\ttotal: 329ms\tremaining: 5.07s\n",
      "70:\tlearn: 0.9549064\ttest: 0.9534516\tbest: 0.9536461 (55)\ttotal: 383ms\tremaining: 5.02s\n",
      "80:\tlearn: 0.9552128\ttest: 0.9535402\tbest: 0.9536461 (55)\ttotal: 437ms\tremaining: 4.96s\n",
      "90:\tlearn: 0.9552572\ttest: 0.9536288\tbest: 0.9536461 (55)\ttotal: 541ms\tremaining: 5.4s\n",
      "100:\tlearn: 0.9558817\ttest: 0.9532762\tbest: 0.9537717 (92)\ttotal: 598ms\tremaining: 5.32s\n",
      "110:\tlearn: 0.9560680\ttest: 0.9530814\tbest: 0.9537717 (92)\ttotal: 657ms\tremaining: 5.26s\n",
      "120:\tlearn: 0.9561044\ttest: 0.9529839\tbest: 0.9537717 (92)\ttotal: 717ms\tremaining: 5.21s\n",
      "130:\tlearn: 0.9561894\ttest: 0.9536226\tbest: 0.9537717 (92)\ttotal: 795ms\tremaining: 5.28s\n",
      "140:\tlearn: 0.9563191\ttest: 0.9532501\tbest: 0.9537717 (92)\ttotal: 856ms\tremaining: 5.21s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9537717422\n",
      "bestIteration = 92\n",
      "\n",
      "Shrink model to first 93 iterations.\n",
      "Validation f1 0.9537717421635197\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)\n",
    "    train_preds += model.predict_proba(train_df_pool)[:,1]\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9538121763873875, 0.00023510056290938325)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 2, 1, 0)\n",
    "submission_df.to_csv('submission_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_anomaly.csv',index=False)\n",
    "test_df.to_csv('test_df_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df = pd.read_csv('stacking_train_df.csv')\n",
    "stacking_test_df = pd.read_csv('stacking_test_df.csv')\n",
    "\n",
    "stacking_train_df['catboost_anomaly'] = train_preds\n",
    "stacking_test_df['catboost_anomaly'] = submission_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_test_df.to_csv('stacking_test_df.csv',index=False)\n",
    "stacking_train_df.to_csv('stacking_train_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
