{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation forests for anomaly detection on noise columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred(col, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[col].values\n",
    "\n",
    "    X_train_df = train_df[col].values\n",
    "    X_test_df = test_df[col].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        X_train = X_train.reshape((-1,1))\n",
    "        X_test = X_test.reshape((-1,1))\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1).reshape(y_test.shape)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df.reshape(-1,1)).reshape(X_train_df.shape).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df.reshape(-1,1)).reshape(X_test_df.shape).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "        \n",
    "    train_df[f'{col}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{col}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:03<00:15,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:fare, mean:0.9242, std:0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [00:05<00:11,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:additional_fare, mean:0.9250, std:0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [00:08<00:08,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:duration, mean:0.9226, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [00:11<00:05,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting, mean:0.9141, std:0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [00:13<00:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_fare, mean:0.9107, std:0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:17<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:meter_waiting_till_pickup, mean:0.9122, std:0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['fare','additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for col in tqdm(cols):\n",
    "    validation_scores = anomaly_pred(col)\n",
    "    print(f'col:{col}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi column anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred_multi(cols, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[cols].values\n",
    "\n",
    "    X_train_df = train_df[cols].values\n",
    "    X_test_df = test_df[cols].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "#     print(X.shape)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "    name = '_'.join(cols)\n",
    "    train_df[f'{name}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{name}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['fare', 'additional_fare'], mean:0.9179, std:0.0168\n",
      "cols:['fare', 'duration'], mean:0.9361, std:0.0016\n",
      "cols:['fare', 'meter_waiting'], mean:0.9223, std:0.0029\n",
      "cols:['fare', 'meter_waiting_fare'], mean:0.9187, std:0.0019\n",
      "cols:['fare', 'meter_waiting_till_pickup'], mean:0.9228, std:0.0023\n",
      "cols:['additional_fare', 'duration'], mean:0.9169, std:0.0165\n",
      "cols:['additional_fare', 'meter_waiting'], mean:0.9141, std:0.0130\n",
      "cols:['additional_fare', 'meter_waiting_fare'], mean:0.9097, std:0.0120\n",
      "cols:['additional_fare', 'meter_waiting_till_pickup'], mean:0.9144, std:0.0153\n",
      "cols:['duration', 'meter_waiting'], mean:0.9176, std:0.0031\n",
      "cols:['duration', 'meter_waiting_fare'], mean:0.9131, std:0.0045\n",
      "cols:['duration', 'meter_waiting_till_pickup'], mean:0.9174, std:0.0016\n",
      "cols:['meter_waiting', 'meter_waiting_fare'], mean:0.9146, std:0.0041\n",
      "cols:['meter_waiting', 'meter_waiting_till_pickup'], mean:0.9164, std:0.0008\n",
      "cols:['meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9137, std:0.0027\n"
     ]
    }
   ],
   "source": [
    "cols = ['fare','additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        validation_scores = anomaly_pred_multi([col_1,col_2])\n",
    "        print(f'cols:{[col_1,col_2]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['fare', 'additional_fare', 'duration'], mean:0.9183, std:0.0138\n",
      "cols:['fare', 'additional_fare', 'meter_waiting'], mean:0.9158, std:0.0123\n",
      "cols:['fare', 'additional_fare', 'meter_waiting_fare'], mean:0.9140, std:0.0120\n",
      "cols:['fare', 'additional_fare', 'meter_waiting_till_pickup'], mean:0.9152, std:0.0132\n",
      "cols:['fare', 'duration', 'meter_waiting'], mean:0.9259, std:0.0015\n",
      "cols:['fare', 'duration', 'meter_waiting_fare'], mean:0.9216, std:0.0020\n",
      "cols:['fare', 'duration', 'meter_waiting_till_pickup'], mean:0.9251, std:0.0017\n",
      "cols:['fare', 'meter_waiting', 'meter_waiting_fare'], mean:0.9199, std:0.0029\n",
      "cols:['fare', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9217, std:0.0023\n",
      "cols:['fare', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9193, std:0.0015\n",
      "cols:['additional_fare', 'duration', 'meter_waiting'], mean:0.9130, std:0.0125\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare'], mean:0.9126, std:0.0125\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_till_pickup'], mean:0.9143, std:0.0137\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare'], mean:0.9104, std:0.0124\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9136, std:0.0123\n",
      "cols:['additional_fare', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9114, std:0.0123\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9162, std:0.0033\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9177, std:0.0012\n",
      "cols:['duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9156, std:0.0020\n",
      "cols:['meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9161, std:0.0025\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            validation_scores = anomaly_pred_multi([col_1,col_2,col_3])\n",
    "            print(f'cols:{[col_1,col_2,col_3]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols:['fare', 'additional_fare', 'duration', 'meter_waiting'], mean:0.9194, std:0.0075\n",
      "cols:['fare', 'additional_fare', 'duration', 'meter_waiting_fare'], mean:0.9191, std:0.0059\n",
      "cols:['fare', 'additional_fare', 'duration', 'meter_waiting_till_pickup'], mean:0.9192, std:0.0090\n",
      "cols:['fare', 'additional_fare', 'meter_waiting', 'meter_waiting_fare'], mean:0.9165, std:0.0061\n",
      "cols:['fare', 'additional_fare', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9184, std:0.0073\n",
      "cols:['fare', 'additional_fare', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9202, std:0.0036\n",
      "cols:['fare', 'duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9197, std:0.0029\n",
      "cols:['fare', 'duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9221, std:0.0017\n",
      "cols:['fare', 'duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9201, std:0.0021\n",
      "cols:['fare', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9186, std:0.0025\n",
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare'], mean:0.9163, std:0.0031\n",
      "cols:['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_till_pickup'], mean:0.9192, std:0.0028\n",
      "cols:['additional_fare', 'duration', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9176, std:0.0036\n",
      "cols:['additional_fare', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9169, std:0.0031\n",
      "cols:['duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup'], mean:0.9166, std:0.0032\n"
     ]
    }
   ],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            k = cols.index(col_3)\n",
    "            for col_4 in cols[k+1:]:                \n",
    "                validation_scores = anomaly_pred_multi([col_1,col_2,col_3,col_4])\n",
    "                print(f'cols:{[col_1,col_2,col_3,col_4]}, mean:{np.mean(validation_scores):.4f}, std:{np.std(validation_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9221976028898832, 0.0014306015564709482)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores = anomaly_pred_multi(cols)\n",
    "np.mean(validation_scores) , np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare',\n",
       "       'meter_waiting_till_pickup', 'fare', 'pickup_date', 'pickup_hour',\n",
       "       'pickup_minute', 'drop_date', 'drop_hour', 'drop_minute',\n",
       "       'pick_cluster', 'is_more_than_one_day', 'distance_km', 'fare_per_km',\n",
       "       'pickup_timeslot', 'day_of_week', 'is_weekday', 'cal_time_difference',\n",
       "       'label', 'fare_anomaly', 'additional_fare_anomaly', 'duration_anomaly',\n",
       "       'meter_waiting_anomaly', 'meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_till_pickup_anomaly', 'fare_additional_fare_anomaly',\n",
       "       'fare_duration_anomaly', 'fare_meter_waiting_anomaly',\n",
       "       'fare_meter_waiting_fare_anomaly',\n",
       "       'fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_anomaly',\n",
       "       'additional_fare_meter_waiting_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_anomaly', 'duration_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_additional_fare_duration_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_fare_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_duration_meter_waiting_anomaly',\n",
       "       'fare_duration_meter_waiting_fare_anomaly',\n",
       "       'fare_duration_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_additional_fare_duration_meter_waiting_anomaly',\n",
       "       'fare_additional_fare_duration_meter_waiting_fare_anomaly',\n",
       "       'fare_additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
       "       'fare_additional_fare_duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    \n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values\n",
    "train_df = train_df.drop(['label'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "train_df_pool = Pool(data=train_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9532710\ttest: 0.9525581\tbest: 0.9525581 (0)\ttotal: 7.61ms\tremaining: 7.6s\n",
      "10:\tlearn: 0.9532762\ttest: 0.9531481\tbest: 0.9535810 (1)\ttotal: 58.7ms\tremaining: 5.28s\n",
      "20:\tlearn: 0.9537179\ttest: 0.9533160\tbest: 0.9535810 (1)\ttotal: 110ms\tremaining: 5.13s\n",
      "30:\tlearn: 0.9545096\ttest: 0.9534754\tbest: 0.9535810 (1)\ttotal: 165ms\tremaining: 5.16s\n",
      "40:\tlearn: 0.9552059\ttest: 0.9537862\tbest: 0.9538747 (35)\ttotal: 233ms\tremaining: 5.45s\n",
      "50:\tlearn: 0.9556051\ttest: 0.9540347\tbest: 0.9540433 (45)\ttotal: 293ms\tremaining: 5.45s\n",
      "60:\tlearn: 0.9557341\ttest: 0.9540176\tbest: 0.9541148 (55)\ttotal: 353ms\tremaining: 5.43s\n",
      "70:\tlearn: 0.9559561\ttest: 0.9542836\tbest: 0.9542836 (70)\ttotal: 414ms\tremaining: 5.41s\n",
      "80:\tlearn: 0.9559883\ttest: 0.9544525\tbest: 0.9544610 (78)\ttotal: 489ms\tremaining: 5.54s\n",
      "90:\tlearn: 0.9561983\ttest: 0.9547103\tbest: 0.9547103 (88)\ttotal: 552ms\tremaining: 5.51s\n",
      "100:\tlearn: 0.9563843\ttest: 0.9546131\tbest: 0.9548075 (92)\ttotal: 614ms\tremaining: 5.46s\n",
      "110:\tlearn: 0.9566068\ttest: 0.9551127\tbest: 0.9551127 (107)\ttotal: 682ms\tremaining: 5.46s\n",
      "120:\tlearn: 0.9568258\ttest: 0.9546895\tbest: 0.9551127 (107)\ttotal: 758ms\tremaining: 5.5s\n",
      "130:\tlearn: 0.9568258\ttest: 0.9551432\tbest: 0.9551432 (128)\ttotal: 823ms\tremaining: 5.46s\n",
      "140:\tlearn: 0.9568704\ttest: 0.9551432\tbest: 0.9551432 (128)\ttotal: 906ms\tremaining: 5.52s\n",
      "150:\tlearn: 0.9571709\ttest: 0.9553213\tbest: 0.9553213 (149)\ttotal: 999ms\tremaining: 5.62s\n",
      "160:\tlearn: 0.9571748\ttest: 0.9551348\tbest: 0.9553213 (149)\ttotal: 1.06s\tremaining: 5.55s\n",
      "170:\tlearn: 0.9573495\ttest: 0.9551264\tbest: 0.9553213 (149)\ttotal: 1.13s\tremaining: 5.47s\n",
      "180:\tlearn: 0.9573942\ttest: 0.9550289\tbest: 0.9553213 (149)\ttotal: 1.19s\tremaining: 5.41s\n",
      "190:\tlearn: 0.9576176\ttest: 0.9550289\tbest: 0.9553213 (149)\ttotal: 1.27s\tremaining: 5.39s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.955321332\n",
      "bestIteration = 149\n",
      "\n",
      "Shrink model to first 150 iterations.\n",
      "Validation f1 0.9553213319653017\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9532814\ttest: 0.9531134\tbest: 0.9531134 (0)\ttotal: 4.67ms\tremaining: 4.66s\n",
      "10:\tlearn: 0.9533645\ttest: 0.9529630\tbest: 0.9531308 (3)\ttotal: 55.7ms\tremaining: 5.01s\n",
      "20:\tlearn: 0.9536338\ttest: 0.9530512\tbest: 0.9531308 (3)\ttotal: 108ms\tremaining: 5.02s\n",
      "30:\tlearn: 0.9539431\ttest: 0.9530338\tbest: 0.9532277 (29)\ttotal: 156ms\tremaining: 4.88s\n",
      "40:\tlearn: 0.9550812\ttest: 0.9537149\tbest: 0.9537149 (40)\ttotal: 226ms\tremaining: 5.28s\n",
      "50:\tlearn: 0.9555525\ttest: 0.9545834\tbest: 0.9546890 (41)\ttotal: 286ms\tremaining: 5.33s\n",
      "60:\tlearn: 0.9558468\ttest: 0.9546637\tbest: 0.9546890 (41)\ttotal: 347ms\tremaining: 5.35s\n",
      "70:\tlearn: 0.9561983\ttest: 0.9545666\tbest: 0.9546890 (41)\ttotal: 409ms\tremaining: 5.35s\n",
      "80:\tlearn: 0.9566999\ttest: 0.9544271\tbest: 0.9546890 (41)\ttotal: 523ms\tremaining: 5.93s\n",
      "90:\tlearn: 0.9570243\ttest: 0.9545624\tbest: 0.9546890 (41)\ttotal: 588ms\tremaining: 5.88s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9546889508\n",
      "bestIteration = 41\n",
      "\n",
      "Shrink model to first 42 iterations.\n",
      "Validation f1 0.9546889507892293\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9532191\ttest: 0.9520097\tbest: 0.9520097 (0)\ttotal: 5.37ms\tremaining: 5.36s\n",
      "10:\tlearn: 0.9529276\ttest: 0.9529717\tbest: 0.9533160 (3)\ttotal: 53ms\tremaining: 4.77s\n",
      "20:\tlearn: 0.9538020\ttest: 0.9538462\tbest: 0.9538462 (20)\ttotal: 109ms\tremaining: 5.1s\n",
      "30:\tlearn: 0.9548154\ttest: 0.9541829\tbest: 0.9541914 (25)\ttotal: 165ms\tremaining: 5.16s\n",
      "40:\tlearn: 0.9554235\ttest: 0.9540518\tbest: 0.9541914 (25)\ttotal: 236ms\tremaining: 5.52s\n",
      "50:\tlearn: 0.9559117\ttest: 0.9541148\tbest: 0.9541914 (25)\ttotal: 298ms\tremaining: 5.54s\n",
      "60:\tlearn: 0.9562631\ttest: 0.9539119\tbest: 0.9541914 (25)\ttotal: 365ms\tremaining: 5.62s\n",
      "70:\tlearn: 0.9565258\ttest: 0.9541864\tbest: 0.9541914 (25)\ttotal: 427ms\tremaining: 5.59s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9541913947\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n",
      "Validation f1 0.9541913946587538\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)\n",
    "    train_preds += model.predict_proba(train_df_pool)[:,1]\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.954733892471095, 0.0004623882893981669)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation_scores), np.std(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.where(submission_preds > 2, 1, 0)\n",
    "submission_df.to_csv('submission_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_anomaly.csv',index=False)\n",
    "test_df.to_csv('test_df_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train_df = pd.read_csv('stacking_train_df.csv')\n",
    "stacking_test_df = pd.read_csv('stacking_test_df.csv')\n",
    "\n",
    "stacking_train_df['catboost_anomaly'] = train_preds\n",
    "stacking_test_df['catboost_anomaly'] = submission_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_test_df.to_csv('stacking_test_df.csv',index=False)\n",
    "stacking_train_df.to_csv('stacking_train_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
