{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import geopy.distance\n",
    "import itertools\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVR,SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest,ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler,KBinsDiscretizer,LabelEncoder,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,f1_score,confusion_matrix,log_loss\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "\n",
    "from catboost import Pool, cv,CatBoostClassifier,CatBoostRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate,Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor,DMatrix,plot_tree\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "## Shortened eda notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time(feature='date'):\n",
    "    def f(time_stamp): \n",
    "        date,time = time_stamp.strip().split()\n",
    "        date = list(map(int, date.split('/')))\n",
    "        time = list(map(int, time.split(':')))\n",
    "        if feature == 'date':\n",
    "            return date[1]\n",
    "        if feature == 'month':\n",
    "            return date[0]\n",
    "        if feature == 'year':\n",
    "            return date[2]\n",
    "        if feature == 'hour':\n",
    "            return time[0]\n",
    "        if feature == 'minute':\n",
    "            return time[1]\n",
    "    return f\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_dataset(cols, train=train_df, test=test_df):\n",
    "    tmp_1 = train.loc[:,cols]\n",
    "    tmp_1['dataset'] = 'train'\n",
    "\n",
    "    tmp_2 = test.loc[:,cols]\n",
    "    tmp_2['dataset'] = 'test'\n",
    "    return tmp_1.append(tmp_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.dropna().drop(['tripid'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pickup_month'] = data['pickup_time'].map(extract_time('month'))\n",
    "data['pickup_date'] = data['pickup_time'].map(extract_time('date'))\n",
    "data['pickup_year'] = data['pickup_time'].map(extract_time('year'))\n",
    "data['pickup_hour'] = data['pickup_time'].map(extract_time('hour'))\n",
    "data['pickup_minute'] = data['pickup_time'].map(extract_time('minute'))\n",
    "\n",
    "data['drop_month'] = data['drop_time'].map(extract_time('month'))\n",
    "data['drop_date'] = data['drop_time'].map(extract_time('date'))\n",
    "data['drop_year'] = data['drop_time'].map(extract_time('year'))\n",
    "data['drop_hour'] = data['drop_time'].map(extract_time('hour'))\n",
    "data['drop_minute'] = data['drop_time'].map(extract_time('minute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pickup_month'] = test_df['pickup_time'].map(extract_time('month'))\n",
    "test_df['pickup_date'] = test_df['pickup_time'].map(extract_time('date'))\n",
    "test_df['pickup_year'] = test_df['pickup_time'].map(extract_time('year'))\n",
    "test_df['pickup_hour'] = test_df['pickup_time'].map(extract_time('hour'))\n",
    "test_df['pickup_minute'] = test_df['pickup_time'].map(extract_time('minute'))\n",
    "\n",
    "test_df['drop_month'] = test_df['drop_time'].map(extract_time('month'))\n",
    "test_df['drop_date'] = test_df['drop_time'].map(extract_time('date'))\n",
    "test_df['drop_year'] = test_df['drop_time'].map(extract_time('year'))\n",
    "test_df['drop_hour'] = test_df['drop_time'].map(extract_time('hour'))\n",
    "test_df['drop_minute'] = test_df['drop_time'].map(extract_time('minute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['drop_lat'] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_more_than_one_day(row):\n",
    "    return 1 if row['pickup_date'] != row['drop_date'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_more_than_one_day'] = data.apply(is_more_than_one_day,axis=1)\n",
    "test_df['is_more_than_one_day'] = test_df.apply(is_more_than_one_day,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pick_lat','pick_lon']\n",
    "comb_data = get_combined_dataset(cols, train=data)\n",
    "\n",
    "gmm_pick = BayesianGaussianMixture(n_components=3)\n",
    "gmm_pick.fit(comb_data[cols].values)\n",
    "\n",
    "data['pick_cluster'] = gmm_pick.predict(data[cols].values)\n",
    "test_df['pick_cluster'] = gmm_pick.predict(test_df[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['drop_lat','drop_lon']\n",
    "comb_data = get_combined_dataset(cols, train=data)\n",
    "\n",
    "gmm_drop = BayesianGaussianMixture(n_components=3,max_iter=1000)\n",
    "gmm_drop.fit(comb_data[cols].values)\n",
    "\n",
    "data['drop_cluster'] = gmm_drop.predict(data[cols].values)\n",
    "test_df['drop_cluster'] = gmm_drop.predict(test_df[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trip_distance(row):\n",
    "    coords_1 = (row['pick_lat'],row['pick_lon'])\n",
    "    coords_2 = (row['drop_lat'],row['drop_lon'])\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distance_km'] = data.apply(calculate_trip_distance,axis=1).clip(0,100)\n",
    "test_df['distance_km'] = test_df.apply(calculate_trip_distance,axis=1).clip(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_per_distance(row):\n",
    "    return row['fare'] / (row['distance_km']+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fare_per_km'] = data.apply(fare_per_distance,axis=1)\n",
    "test_df['fare_per_km'] = test_df.apply(fare_per_distance,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_slot(row,by='pickup'):\n",
    "    hour = row[f'{by}_hour']\n",
    "    if 7 <= hour <= 9:\n",
    "        return 1\n",
    "    if 12 <= hour <= 2:\n",
    "        return 2\n",
    "    if 4 <= hour <= 6:\n",
    "        return 3\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pickup_timeslot'] = data.apply(time_slot,axis=1)\n",
    "test_df['pickup_timeslot'] = test_df.apply(time_slot,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(row,by='pickup'):\n",
    "    date = row[f'{by}_date']\n",
    "    month = row[f'{by}_month']\n",
    "    year = row[f'{by}_year']\n",
    "    d = datetime.datetime(year,month,date).weekday()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_of_week'] = data.apply(day_of_week,axis=1)\n",
    "test_df['day_of_week'] = test_df.apply(day_of_week,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekday(row,by='pickup'):\n",
    "    date = row['day_of_week']\n",
    "    return 1 if date < 5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_weekday'] = data.apply(is_weekday,axis=1)\n",
    "test_df['is_weekday'] = test_df.apply(is_weekday,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_time_difference(row):\n",
    "    pickup_date = row['pickup_date']\n",
    "    pickup_month = row['pickup_month']\n",
    "    pickup_year = row['pickup_year']\n",
    "    pickup_hour = row['pickup_hour']\n",
    "    pickup_minute = row['pickup_minute']\n",
    "    pickup_time = datetime.datetime(pickup_year, pickup_month, pickup_date, pickup_hour, pickup_minute)\n",
    "    \n",
    "    drop_date = row['drop_date']\n",
    "    drop_month = row['drop_month']\n",
    "    drop_year = row['drop_year']\n",
    "    drop_hour = row['drop_hour']\n",
    "    drop_minute = row['drop_minute']\n",
    "    drop_time = datetime.datetime(drop_year, drop_month, drop_date, drop_hour, drop_minute)\n",
    "    \n",
    "    delta = drop_time - pickup_time\n",
    "    return delta.seconds - row['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cal_time_difference'] = data.apply(cal_time_difference,axis=1)\n",
    "test_df['cal_time_difference'] = test_df.apply(cal_time_difference,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    if label == 'correct':\n",
    "        return 1\n",
    "    elif label == 'incorrect':\n",
    "        return 0\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].map(encode_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = [\n",
    "    'additional_fare', \n",
    "    'duration', \n",
    "    'meter_waiting', \n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup', \n",
    "    'fare',\n",
    "    'pickup_date', \n",
    "    'pickup_hour', \n",
    "    'pickup_minute',\n",
    "    'drop_date', \n",
    "    'drop_hour', \n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference']\n",
    "data.loc[:, columns_to_save+['label']].to_csv('train_df.csv',index=False)\n",
    "test_df.loc[:, columns_to_save].to_csv('test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortened anomaly_detection notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred(col, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[col].values\n",
    "\n",
    "    X_train_df = train_df[col].values\n",
    "    X_test_df = test_df[col].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        X_train = X_train.reshape((-1,1))\n",
    "        X_test = X_test.reshape((-1,1))\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1).reshape(y_test.shape)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df.reshape(-1,1)).reshape(X_train_df.shape).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df.reshape(-1,1)).reshape(X_test_df.shape).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "        \n",
    "    train_df[f'{col}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{col}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "cols = ['fare','additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for col in tqdm(cols):\n",
    "    validation_scores = anomaly_pred(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_pred_multi(cols, train_df=train_df, test_df=test_df, folds=3):\n",
    "    labels = train_df['label'].values\n",
    "    X = train_df[cols].values\n",
    "\n",
    "    X_train_df = train_df[cols].values\n",
    "    X_test_df = test_df[cols].values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    validation_scores = []\n",
    "    models = []\n",
    "\n",
    "    train_preds = np.zeros(train_df.shape[0])\n",
    "    test_preds = np.zeros(test_df.shape[0])\n",
    "#     print(X.shape)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        model = IsolationForest(random_state=0).fit(X_train)\n",
    "        preds = model.predict(X_test).clip(0,1)\n",
    "        validation_score = f1_score(y_test, preds)\n",
    "\n",
    "        train_preds += model.predict(X_train_df).clip(0,1)\n",
    "        test_preds += model.predict(X_test_df).clip(0,1)\n",
    "\n",
    "    #     print('Validation score:' , validation_score)\n",
    "\n",
    "        validation_scores.append(validation_score)\n",
    "        models.append(model)\n",
    "    name = '_'.join(cols)\n",
    "    train_df[f'{name}_anomaly'] = np.where(train_preds > 2, 1, 0)\n",
    "    test_df[f'{name}_anomaly'] = np.where(test_preds > 2, 1, 0)\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fare','additional_fare','duration','meter_waiting','meter_waiting_fare','meter_waiting_till_pickup']\n",
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        validation_scores = anomaly_pred_multi([col_1,col_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            validation_scores = anomaly_pred_multi([col_1,col_2,col_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col_1 in enumerate(cols):\n",
    "    for col_2 in cols[i+1:]:\n",
    "        j = cols.index(col_2)\n",
    "        for col_3 in cols[j+1:]:\n",
    "            k = cols.index(col_3)\n",
    "            for col_4 in cols[k+1:]:                \n",
    "                validation_scores = anomaly_pred_multi([col_1,col_2,col_3,col_4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "#     'class_weights':class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    \n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values\n",
    "train_df = train_df.drop(['label'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "train_df_pool = Pool(data=train_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9531844\ttest: 0.9530251\tbest: 0.9530251 (0)\ttotal: 57.3ms\tremaining: 57.3s\n",
      "10:\tlearn: 0.9534970\ttest: 0.9531481\tbest: 0.9533160 (1)\ttotal: 133ms\tremaining: 11.9s\n",
      "20:\tlearn: 0.9536295\ttest: 0.9533160\tbest: 0.9533247 (11)\ttotal: 192ms\tremaining: 8.93s\n",
      "30:\tlearn: 0.9540672\ttest: 0.9534754\tbest: 0.9534754 (28)\ttotal: 264ms\tremaining: 8.26s\n",
      "40:\tlearn: 0.9551255\ttest: 0.9549800\tbest: 0.9549800 (40)\ttotal: 338ms\tremaining: 7.9s\n",
      "50:\tlearn: 0.9556092\ttest: 0.9552294\tbest: 0.9552294 (50)\ttotal: 403ms\tremaining: 7.49s\n",
      "60:\tlearn: 0.9556051\ttest: 0.9552211\tbest: 0.9552294 (50)\ttotal: 475ms\tremaining: 7.3s\n",
      "70:\tlearn: 0.9558632\ttest: 0.9552932\tbest: 0.9552932 (70)\ttotal: 548ms\tremaining: 7.17s\n",
      "80:\tlearn: 0.9562671\ttest: 0.9554709\tbest: 0.9555597 (78)\ttotal: 614ms\tremaining: 6.97s\n",
      "90:\tlearn: 0.9564894\ttest: 0.9555597\tbest: 0.9555597 (78)\ttotal: 681ms\tremaining: 6.8s\n",
      "100:\tlearn: 0.9566067\ttest: 0.9555514\tbest: 0.9556485 (91)\ttotal: 760ms\tremaining: 6.77s\n",
      "110:\tlearn: 0.9567402\ttest: 0.9556403\tbest: 0.9556485 (91)\ttotal: 851ms\tremaining: 6.81s\n",
      "120:\tlearn: 0.9569627\ttest: 0.9556403\tbest: 0.9556485 (91)\ttotal: 939ms\tremaining: 6.82s\n",
      "130:\tlearn: 0.9570764\ttest: 0.9550405\tbest: 0.9556485 (91)\ttotal: 1.01s\tremaining: 6.71s\n",
      "140:\tlearn: 0.9571209\ttest: 0.9550405\tbest: 0.9556485 (91)\ttotal: 1.08s\tremaining: 6.56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9556485356\n",
      "bestIteration = 91\n",
      "\n",
      "Shrink model to first 92 iterations.\n",
      "Validation f1 0.9556485355648535\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9531793\ttest: 0.9523810\tbest: 0.9523810 (0)\ttotal: 4.95ms\tremaining: 4.95s\n",
      "10:\tlearn: 0.9534087\ttest: 0.9530512\tbest: 0.9531308 (3)\ttotal: 61.2ms\tremaining: 5.5s\n",
      "20:\tlearn: 0.9538547\ttest: 0.9533074\tbest: 0.9533074 (20)\ttotal: 122ms\tremaining: 5.69s\n",
      "30:\tlearn: 0.9546867\ttest: 0.9540145\tbest: 0.9540230 (29)\ttotal: 181ms\tremaining: 5.66s\n",
      "40:\tlearn: 0.9557465\ttest: 0.9545455\tbest: 0.9545455 (38)\ttotal: 256ms\tremaining: 5.98s\n",
      "50:\tlearn: 0.9558311\ttest: 0.9549884\tbest: 0.9549884 (50)\ttotal: 318ms\tremaining: 5.91s\n",
      "60:\tlearn: 0.9560450\ttest: 0.9547776\tbest: 0.9549884 (50)\ttotal: 385ms\tremaining: 5.92s\n",
      "70:\tlearn: 0.9564287\ttest: 0.9544779\tbest: 0.9549884 (50)\ttotal: 455ms\tremaining: 5.96s\n",
      "80:\tlearn: 0.9566471\ttest: 0.9544610\tbest: 0.9549884 (50)\ttotal: 539ms\tremaining: 6.11s\n",
      "90:\tlearn: 0.9572260\ttest: 0.9547103\tbest: 0.9549884 (50)\ttotal: 605ms\tremaining: 6.04s\n",
      "100:\tlearn: 0.9573596\ttest: 0.9547103\tbest: 0.9549884 (50)\ttotal: 679ms\tremaining: 6.04s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9549883991\n",
      "bestIteration = 50\n",
      "\n",
      "Shrink model to first 51 iterations.\n",
      "Validation f1 0.9549883990719258\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9532589\ttest: 0.9522042\tbest: 0.9522042 (0)\ttotal: 5.69ms\tremaining: 5.69s\n",
      "10:\tlearn: 0.9529673\ttest: 0.9530599\tbest: 0.9534130 (7)\ttotal: 54.8ms\tremaining: 4.93s\n",
      "20:\tlearn: 0.9539788\ttest: 0.9539260\tbest: 0.9540230 (17)\ttotal: 114ms\tremaining: 5.32s\n",
      "30:\tlearn: 0.9547268\ttest: 0.9538290\tbest: 0.9540230 (17)\ttotal: 174ms\tremaining: 5.44s\n",
      "40:\tlearn: 0.9554844\ttest: 0.9542459\tbest: 0.9542544 (36)\ttotal: 255ms\tremaining: 5.95s\n",
      "50:\tlearn: 0.9558755\ttest: 0.9545117\tbest: 0.9546003 (47)\ttotal: 351ms\tremaining: 6.54s\n",
      "60:\tlearn: 0.9559643\ttest: 0.9546890\tbest: 0.9546890 (52)\ttotal: 421ms\tremaining: 6.48s\n",
      "70:\tlearn: 0.9561420\ttest: 0.9549466\tbest: 0.9549466 (70)\ttotal: 499ms\tremaining: 6.53s\n",
      "80:\tlearn: 0.9565379\ttest: 0.9552932\tbest: 0.9552932 (80)\ttotal: 566ms\tremaining: 6.42s\n",
      "90:\tlearn: 0.9567118\ttest: 0.9551878\tbest: 0.9552932 (80)\ttotal: 636ms\tremaining: 6.35s\n",
      "100:\tlearn: 0.9568412\ttest: 0.9553654\tbest: 0.9553654 (96)\ttotal: 733ms\tremaining: 6.52s\n",
      "110:\tlearn: 0.9569707\ttest: 0.9553571\tbest: 0.9553654 (96)\ttotal: 803ms\tremaining: 6.43s\n",
      "120:\tlearn: 0.9570153\ttest: 0.9552600\tbest: 0.9553654 (96)\ttotal: 871ms\tremaining: 6.33s\n",
      "130:\tlearn: 0.9570558\ttest: 0.9552600\tbest: 0.9553654 (96)\ttotal: 985ms\tremaining: 6.53s\n",
      "140:\tlearn: 0.9571449\ttest: 0.9551461\tbest: 0.9555349 (132)\ttotal: 1.06s\tremaining: 6.47s\n",
      "150:\tlearn: 0.9573230\ttest: 0.9552350\tbest: 0.9555349 (132)\ttotal: 1.14s\tremaining: 6.42s\n",
      "160:\tlearn: 0.9573676\ttest: 0.9551378\tbest: 0.9555349 (132)\ttotal: 1.26s\tremaining: 6.56s\n",
      "170:\tlearn: 0.9576311\ttest: 0.9549432\tbest: 0.9555349 (132)\ttotal: 1.36s\tremaining: 6.62s\n",
      "180:\tlearn: 0.9578094\ttest: 0.9547402\tbest: 0.9555349 (132)\ttotal: 1.45s\tremaining: 6.54s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9555348837\n",
      "bestIteration = 132\n",
      "\n",
      "Shrink model to first 133 iterations.\n",
      "Validation f1 0.9555348837209301\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "submission_preds = np.zeros(submission_df.shape[0])\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_pools = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train_df, labels):\n",
    "    X_train, X_test = train_df.iloc[train_index,:], train_df.iloc[test_index,:]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    pred = model.predict(test_pool)\n",
    "    validation_score = model.best_score_['validation']['F1']\n",
    "    print('Validation f1',validation_score)\n",
    "    validation_scores.append(validation_score)\n",
    "    models.append(model)\n",
    "    train_pools.append(train_pool)\n",
    "    submission_preds += model.predict(submission_pool)\n",
    "    train_preds += model.predict_proba(train_df_pool)[:,1]\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_anomaly.csv',index=False)\n",
    "test_df.to_csv('test_df_anomaly.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortened noise_pre_eda notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df = pd.read_csv('test_df.csv')\n",
    "\n",
    "data = train_df[train_df['label'] == 1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting','meter_waiting_fare','is_more_than_one_day']\n",
    "X = data[cols].values\n",
    "y = data['fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 96.5273471319087\n",
      "RMSE: 82.29682215032592\n",
      "RMSE: 82.63358797352826\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "\n",
    "    model = LinearRegression()\n",
    "#     model = SVR()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_fare'] = train_preds\n",
    "test_df['predicted_fare'] = test_preds\n",
    "\n",
    "train_df['predicted_fare_diff'] = train_df['fare'] - train_df['predicted_fare']\n",
    "test_df['predicted_fare_diff'] = test_df['fare'] - test_df['predicted_fare']    \n",
    "\n",
    "train_df['predicted_fare_diff_per_fare'] = train_df['predicted_fare_diff'] / (train_df['fare']+1)\n",
    "test_df['predicted_fare_diff_per_fare'] = test_df['predicted_fare_diff'] / (test_df['fare']+1)\n",
    "\n",
    "train_df['predicted_fare_diff_per_predicted_fare'] = train_df['predicted_fare_diff'] / (train_df['predicted_fare']+1)\n",
    "test_df['predicted_fare_diff_per_predicted_fare'] = test_df['predicted_fare_diff'] / (test_df['predicted_fare']+1)\n",
    "\n",
    "train_df['fare_per_distance'] = train_df['fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare_per_distance'] = test_df['fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_fare_per_distance'] = train_df['predicted_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare_per_distance'] = test_df['predicted_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_fare_diff_per_distance'] = train_df['predicted_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare_diff_per_distance'] = test_df['predicted_fare_diff'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_fare_diff_per_fare'] = train_df['predicted_fare_diff'] / (train_df['fare']+1)\n",
    "test_df['predicted_fare_diff_per_fare'] = test_df['predicted_fare_diff'] / (test_df['fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['meter_waiting','meter_waiting_fare','fare','is_more_than_one_day','cal_time_difference']\n",
    "\n",
    "X = data[cols].values\n",
    "y = data['duration'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 412.05683862976997\n",
      "RMSE: 332.70147883644177\n",
      "RMSE: 343.7877005393285\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duration'] = train_preds\n",
    "test_df['predicted_duration'] = test_preds\n",
    "\n",
    "train_df['predicted_duration_diff'] = train_df['duration'] - train_df['predicted_duration']\n",
    "test_df['predicted_duration_diff'] = test_df['duration'] - test_df['predicted_duration']    \n",
    "\n",
    "train_df['predicted_duraton_diff_per_duraton'] = train_df['predicted_duration_diff'] / (train_df['duration']+1)\n",
    "test_df['predicted_duraton_diff_per_duraton'] = test_df['predicted_duration_diff'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_duraton_diff_per_predicted_duration'] = train_df['predicted_duration_diff'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_duraton_diff_per_predicted_duration'] = test_df['predicted_duration_diff'] / (test_df['predicted_duration']+1)\n",
    "\n",
    "train_df['predicted_duraton_diff_per_distance'] = train_df['predicted_duration_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_duraton_diff_per_distance'] = test_df['predicted_duration_diff'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['fare_per_duration'] = train_df['fare'] / (train_df['duration']+1)\n",
    "test_df['fare_per_duration'] = test_df['fare'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_fare_per_duration'] = train_df['predicted_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare_per_duration'] = test_df['predicted_fare'] / (test_df['predicted_duration']+1)\n",
    "\n",
    "train_df['predicted_fare_per_duration_diff'] = train_df['fare_per_duration'] - train_df['predicted_fare_per_duration']\n",
    "test_df['predicted_fare_per_duration_diff'] = test_df['fare_per_duration'] - test_df['predicted_fare_per_duration']\n",
    "\n",
    "train_df['avg_speed'] = train_df['distance_km'] / (train_df['duration'] + 1)\n",
    "test_df['avg_speed'] = test_df['distance_km'] / (test_df['duration'] + 1)\n",
    "\n",
    "train_df['predicted_avg_speed'] = train_df['distance_km'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_avg_speed'] = test_df['distance_km'] / (test_df['predicted_duration'] + 1)\n",
    "\n",
    "train_df['predicted_avg_speed_diff'] = train_df['avg_speed'] - train_df['predicted_avg_speed']\n",
    "test_df['predicted_avg_speed_diff'] = test_df['avg_speed'] - test_df['predicted_avg_speed']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting_fare','fare','cal_time_difference']\n",
    "\n",
    "X = data[cols].values\n",
    "y = data['meter_waiting'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 121.23549829752587\n",
      "RMSE: 126.15607547905648\n",
      "RMSE: 119.87616226350285\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting'] = train_preds\n",
    "test_df['predicted_meter_waiting'] = test_preds\n",
    "\n",
    "train_df['predicted_meter_waiting_diff'] = train_df['meter_waiting'] - train_df['predicted_meter_waiting']\n",
    "test_df['predicted_meter_waiting_diff'] = test_df['meter_waiting'] - test_df['predicted_meter_waiting']\n",
    "\n",
    "train_df['predicted_meter_waiting_diff_per_meter_waiting'] = train_df['predicted_meter_waiting_diff'] / (train_df['meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_meter_waiting'] = test_df['predicted_meter_waiting_diff'] / (test_df['meter_waiting'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_diff_per_distance'] = train_df['predicted_meter_waiting_diff'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_distance'] = test_df['predicted_meter_waiting_diff'] / (test_df['distance_km'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_diff_per_predicted_meter_waiting'] = train_df['predicted_meter_waiting_diff'] / (train_df['predicted_meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_diff_per_predicted_meter_waiting'] = test_df['predicted_meter_waiting_diff'] / (test_df['predicted_meter_waiting'] + 1)\n",
    "\n",
    "train_df['meter_waiting_per_duration'] = train_df['meter_waiting'] / (train_df['duration']+1)\n",
    "test_df['meter_waiting_per_duration'] = test_df['meter_waiting'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_meter_waiting_per_duration'] = train_df['predicted_meter_waiting'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_meter_waiting_per_duration'] = test_df['predicted_meter_waiting'] / (test_df['predicted_duration']+1)\n",
    "\n",
    "train_df['predicted_meter_waiting_per_duration_diff'] = train_df['meter_waiting_per_duration'] - train_df['predicted_meter_waiting_per_duration']\n",
    "test_df['predicted_meter_waiting_per_duration_diff'] = test_df['meter_waiting_per_duration'] - test_df['predicted_meter_waiting_per_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration','meter_waiting','fare','is_more_than_one_day','cal_time_difference']\n",
    "\n",
    "X = data[cols].values\n",
    "y = data['meter_waiting_fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = scaler.transform(X_train_df)\n",
    "X_test_df = scaler.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 7.21561205286957\n",
      "RMSE: 7.758602065112114\n",
      "RMSE: 8.8391720955996\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_fare'] = train_preds\n",
    "test_df['predicted_meter_waiting_fare'] = test_preds\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_diff'] = train_df['meter_waiting_fare'] - train_df['predicted_meter_waiting_fare']\n",
    "test_df['predicted_meter_waiting_fare_diff'] = test_df['meter_waiting_fare'] - test_df['predicted_meter_waiting_fare']\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_diff_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['meter_waiting_fare']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['meter_waiting_fare']+1)\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_diff_per_distance'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_distance'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare'] = train_df['predicted_meter_waiting_fare_diff'] / (train_df['predicted_meter_waiting_fare']+1)\n",
    "test_df['predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare'] = test_df['predicted_meter_waiting_fare_diff'] / (test_df['predicted_meter_waiting_fare']+1)\n",
    "\n",
    "train_df['meter_waiting_fare_per_meter_waiting'] = train_df['meter_waiting_fare'] / train_df['meter_waiting']\n",
    "test_df['meter_waiting_fare_per_meter_waiting'] = test_df['meter_waiting_fare'] / test_df['meter_waiting']\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_per_meter_waiting'] = train_df['predicted_meter_waiting_fare'] / train_df['predicted_meter_waiting']\n",
    "test_df['predicted_meter_waiting_fare_per_meter_waiting'] = test_df['predicted_meter_waiting_fare'] / test_df['predicted_meter_waiting']\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_per_meter_waiting_diff'] = train_df['meter_waiting_fare_per_meter_waiting'] - train_df['predicted_meter_waiting_fare_per_meter_waiting']\n",
    "test_df['predicted_meter_waiting_fare_per_meter_waiting_diff'] = test_df['meter_waiting_fare_per_meter_waiting'] - test_df['predicted_meter_waiting_fare_per_meter_waiting']\n",
    "\n",
    "train_df['meter_waiting_fare_per_duration'] = train_df['meter_waiting_fare'] / train_df['duration']\n",
    "test_df['meter_waiting_fare_per_duration'] = test_df['meter_waiting_fare'] / test_df['duration']\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_per_duration'] = train_df['predicted_meter_waiting_fare'] / train_df['predicted_duration']\n",
    "test_df['predicted_meter_waiting_fare_per_duration'] = test_df['predicted_meter_waiting_fare'] / test_df['predicted_duration']\n",
    "\n",
    "train_df['predicted_meter_waiting_fare_per_duration_diff'] = train_df['meter_waiting_fare_per_duration'] - train_df['predicted_meter_waiting_fare_per_duration']\n",
    "test_df['predicted_meter_waiting_fare_per_duration_diff'] = test_df['meter_waiting_fare_per_duration'] - test_df['predicted_meter_waiting_fare_per_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['meter_waiting_fare_per_duration','meter_waiting_per_duration','fare_per_duration']\n",
    "data = train_df[train_df['label'] == 1].dropna()\n",
    "\n",
    "X = data[cols].values\n",
    "y = data['additional_fare'].values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = np.nan_to_num(scaler.transform(X_train_df))\n",
    "X_test_df = np.nan_to_num(scaler.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.720292350311684\n",
      "RMSE: 11.875141951981368\n",
      "RMSE: 12.088516557325503\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#     model = CatBoostRegressor(**params)\n",
    "#     model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test))\n",
    "   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_additional_fare'] = train_preds\n",
    "test_df['predicted_additional_fare'] = test_preds\n",
    "\n",
    "train_df['predicted_additional_fare_diff'] = train_df['additional_fare'] - train_df['predicted_additional_fare']\n",
    "test_df['predicted_additional_fare_diff'] = test_df['additional_fare'] - test_df['predicted_additional_fare']\n",
    "\n",
    "train_df['predicted_additional_fare_diff_per_additional_fare'] = train_df['predicted_additional_fare_diff'] / (train_df['additional_fare']+1)\n",
    "test_df['predicted_additional_fare_diff_per_additional_fare'] = test_df['predicted_additional_fare_diff'] / (test_df['additional_fare']+1)\n",
    "\n",
    "train_df['predicted_addtional_fare_per_fare'] = train_df['predicted_additional_fare'] / (train_df['predicted_fare']+1)\n",
    "test_df['predicted_addtional_fare_per_fare'] = test_df['predicted_additional_fare'] / (test_df['predicted_fare']+1)\n",
    "\n",
    "train_df['addtional_fare_per_fare'] = train_df['additional_fare'] / (train_df['fare']+1)\n",
    "test_df['addtional_fare_per_fare'] = test_df['additional_fare'] / (test_df['fare']+1)\n",
    "\n",
    "train_df['addtional_fare_per_distance'] = train_df['additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['addtional_fare_per_distance'] = test_df['additional_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_addtional_fare_per_distance'] = train_df['predicted_additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_addtional_fare_per_distance'] = test_df['predicted_additional_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_addtional_fare_diff_per_distance'] = train_df['predicted_additional_fare_diff'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_addtional_fare_diff_per_distance'] = test_df['predicted_additional_fare_diff'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['addtional_fare_per_duration'] = train_df['additional_fare'] / (train_df['duration']+1)\n",
    "test_df['addtional_fare_per_duration'] = test_df['additional_fare'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_addtional_fare_per_duration'] = train_df['predicted_additional_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_addtional_fare_per_duration'] = test_df['predicted_additional_fare'] / (test_df['predicted_duration']+1)\n",
    "\n",
    "train_df['fare-additional_fare'] = train_df['fare'] - train_df['additional_fare']\n",
    "test_df['fare-additional_fare'] = test_df['fare'] - test_df['additional_fare']\n",
    "\n",
    "train_df['predicted_fare-additional_fare'] = train_df['predicted_fare'] - train_df['predicted_additional_fare']\n",
    "test_df['predicted_fare-additional_fare'] = test_df['predicted_fare'] - test_df['predicted_additional_fare']\n",
    "\n",
    "train_df['fare-additional_fare-meter_waiting_fare'] = train_df['fare'] - (train_df['additional_fare'] + train_df['meter_waiting_fare'])\n",
    "test_df['fare-additional_fare-meter_waiting_fare'] = test_df['fare'] - (test_df['additional_fare'] + test_df['meter_waiting_fare'])\n",
    "\n",
    "train_df['predicted_fare-additional_fare-meter_waiting_fare'] = train_df['predicted_fare'] - (train_df['predicted_additional_fare'] + train_df['predicted_meter_waiting_fare'])\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare'] = test_df['predicted_fare'] - (test_df['predicted_additional_fare'] + test_df['predicted_meter_waiting_fare'])\n",
    "\n",
    "train_df['fare-additional_fare_per_distance'] = train_df['fare-additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare-additional_fare_per_distance'] = test_df['fare-additional_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_fare-additional_fare_per_distance'] = train_df['predicted_fare-additional_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare-additional_fare_per_distance'] = test_df['predicted_fare-additional_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['fare-additional_fare_per_duration'] = train_df['fare-additional_fare'] / (train_df['duration']+1)\n",
    "test_df['fare-additional_fare_per_duration'] = test_df['fare-additional_fare'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_fare-additional_fare_per_duration'] = train_df['predicted_fare-additional_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare-additional_fare_per_duration'] = test_df['predicted_fare-additional_fare'] / (test_df['predicted_duration']+1)\n",
    "\n",
    "train_df['fare-additional_fare-meter_waiting_fare_per_distance'] = train_df['fare-additional_fare-meter_waiting_fare'] / (train_df['distance_km']+1)\n",
    "test_df['fare-additional_fare-meter_waiting_fare_per_distance'] = test_df['fare-additional_fare-meter_waiting_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['predicted_fare-additional_fare-meter_waiting_fare_per_distance'] = train_df['predicted_fare-additional_fare-meter_waiting_fare'] / (train_df['distance_km']+1)\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare_per_distance'] = test_df['predicted_fare-additional_fare-meter_waiting_fare'] / (test_df['distance_km']+1)\n",
    "\n",
    "train_df['fare-additional_fare-meter_waiting_fare_per_duration'] = train_df['fare-additional_fare-meter_waiting_fare'] / (train_df['duration']+1)\n",
    "test_df['fare-additional_fare-meter_waiting_fare_per_duration'] = test_df['fare-additional_fare-meter_waiting_fare'] / (test_df['duration']+1)\n",
    "\n",
    "train_df['predicted_fare-additional_fare-meter_waiting_fare_per_duration'] = train_df['predicted_fare-additional_fare-meter_waiting_fare'] / (train_df['predicted_duration']+1)\n",
    "test_df['predicted_fare-additional_fare-meter_waiting_fare_per_duration'] = test_df['predicted_fare-additional_fare-meter_waiting_fare'] / (test_df['predicted_duration']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df[train_df['label'] == 1].dropna()\n",
    "y = data['meter_waiting_till_pickup'].values\n",
    "X = data.drop(['label','meter_waiting_till_pickup'],axis=1)\n",
    "cols = X.columns\n",
    "X = X.values\n",
    "\n",
    "X_train_df = train_df[cols].values\n",
    "X_test_df = test_df[cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_df = np.nan_to_num(scaler.transform(X_train_df))\n",
    "X_test_df = np.nan_to_num(scaler.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss_function':'RMSE',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'RMSE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.071025\n",
      "0:\tlearn: 118.6085647\ttest: 752.4014533\tbest: 752.4014533 (0)\ttotal: 16.1ms\tremaining: 16s\n",
      "10:\tlearn: 115.6279704\ttest: 751.4615819\tbest: 751.4615819 (10)\ttotal: 108ms\tremaining: 9.68s\n",
      "20:\tlearn: 114.1567627\ttest: 751.0719888\tbest: 751.0719888 (20)\ttotal: 196ms\tremaining: 9.13s\n",
      "30:\tlearn: 113.1604569\ttest: 750.7494121\tbest: 750.7494121 (30)\ttotal: 301ms\tremaining: 9.4s\n",
      "40:\tlearn: 112.3488130\ttest: 750.3135685\tbest: 750.3135685 (40)\ttotal: 394ms\tremaining: 9.22s\n",
      "50:\tlearn: 111.6237013\ttest: 750.1796473\tbest: 750.1796473 (50)\ttotal: 497ms\tremaining: 9.25s\n",
      "60:\tlearn: 110.9276689\ttest: 750.1443872\tbest: 750.1353974 (57)\ttotal: 594ms\tremaining: 9.15s\n",
      "70:\tlearn: 110.3372737\ttest: 749.9718913\tbest: 749.9536518 (63)\ttotal: 690ms\tremaining: 9.03s\n",
      "80:\tlearn: 109.6922453\ttest: 749.9560205\tbest: 749.9450179 (72)\ttotal: 796ms\tremaining: 9.04s\n",
      "90:\tlearn: 109.0438206\ttest: 749.8348078\tbest: 749.8250639 (83)\ttotal: 914ms\tremaining: 9.13s\n",
      "100:\tlearn: 108.4398849\ttest: 749.8340139\tbest: 749.8182700 (95)\ttotal: 1.01s\tremaining: 9s\n",
      "110:\tlearn: 107.9258169\ttest: 749.7733492\tbest: 749.7733492 (110)\ttotal: 1.12s\tremaining: 8.97s\n",
      "120:\tlearn: 107.4059852\ttest: 749.7322239\tbest: 749.7301791 (119)\ttotal: 1.21s\tremaining: 8.82s\n",
      "130:\tlearn: 106.8772928\ttest: 749.5542323\tbest: 749.5412577 (126)\ttotal: 1.31s\tremaining: 8.72s\n",
      "140:\tlearn: 106.3892339\ttest: 749.5409012\tbest: 749.5409012 (140)\ttotal: 1.41s\tremaining: 8.59s\n",
      "150:\tlearn: 105.9360389\ttest: 749.5081454\tbest: 749.4965001 (147)\ttotal: 1.51s\tremaining: 8.5s\n",
      "160:\tlearn: 105.3696996\ttest: 749.3299575\tbest: 749.3299575 (160)\ttotal: 1.61s\tremaining: 8.37s\n",
      "170:\tlearn: 104.8490110\ttest: 749.2954212\tbest: 749.2934116 (169)\ttotal: 1.7s\tremaining: 8.24s\n",
      "180:\tlearn: 104.3472346\ttest: 749.2381408\tbest: 749.2360254 (177)\ttotal: 1.8s\tremaining: 8.15s\n",
      "190:\tlearn: 103.7845220\ttest: 749.2309354\tbest: 749.2248850 (186)\ttotal: 1.9s\tremaining: 8.04s\n",
      "200:\tlearn: 103.3072271\ttest: 749.1180526\tbest: 749.0722874 (192)\ttotal: 1.99s\tremaining: 7.91s\n",
      "210:\tlearn: 102.8139993\ttest: 749.1293459\tbest: 749.0722874 (192)\ttotal: 2.1s\tremaining: 7.84s\n",
      "220:\tlearn: 102.2867741\ttest: 749.0945691\tbest: 749.0722874 (192)\ttotal: 2.19s\tremaining: 7.72s\n",
      "230:\tlearn: 101.8286527\ttest: 749.0792284\tbest: 749.0722874 (192)\ttotal: 2.29s\tremaining: 7.61s\n",
      "240:\tlearn: 101.3548378\ttest: 749.0815441\tbest: 749.0722874 (192)\ttotal: 2.4s\tremaining: 7.55s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 749.0722874\n",
      "bestIteration = 192\n",
      "\n",
      "Shrink model to first 193 iterations.\n",
      "RMSE: 749.0722873851424\n",
      "Learning rate set to 0.071025\n",
      "0:\tlearn: 529.7150969\ttest: 121.6558668\tbest: 121.6558668 (0)\ttotal: 9.27ms\tremaining: 9.26s\n",
      "10:\tlearn: 449.2934740\ttest: 148.9171854\tbest: 121.6558668 (0)\ttotal: 97.2ms\tremaining: 8.74s\n",
      "20:\tlearn: 384.3612812\ttest: 234.5253136\tbest: 121.6558668 (0)\ttotal: 179ms\tremaining: 8.36s\n",
      "30:\tlearn: 332.1693752\ttest: 317.0376439\tbest: 121.6558668 (0)\ttotal: 278ms\tremaining: 8.7s\n",
      "40:\tlearn: 287.0552451\ttest: 377.9529019\tbest: 121.6558668 (0)\ttotal: 393ms\tremaining: 9.19s\n",
      "50:\tlearn: 250.4644820\ttest: 453.7104706\tbest: 121.6558668 (0)\ttotal: 492ms\tremaining: 9.16s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 121.6558668\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "RMSE: 121.65586676482299\n",
      "Learning rate set to 0.071025\n",
      "0:\tlearn: 530.0395760\ttest: 118.1700022\tbest: 118.1700022 (0)\ttotal: 9.98ms\tremaining: 9.97s\n",
      "10:\tlearn: 450.6555259\ttest: 117.9286773\tbest: 117.9211593 (5)\ttotal: 92ms\tremaining: 8.28s\n",
      "20:\tlearn: 384.9934871\ttest: 119.1148469\tbest: 117.7715019 (13)\ttotal: 177ms\tremaining: 8.23s\n",
      "30:\tlearn: 331.3216124\ttest: 121.7253560\tbest: 117.7715019 (13)\ttotal: 279ms\tremaining: 8.72s\n",
      "40:\tlearn: 288.2810037\ttest: 122.8873394\tbest: 117.7715019 (13)\ttotal: 366ms\tremaining: 8.56s\n",
      "50:\tlearn: 251.1275024\ttest: 127.7956714\tbest: 117.7715019 (13)\ttotal: 456ms\tremaining: 8.49s\n",
      "60:\tlearn: 221.6309454\ttest: 129.4950962\tbest: 117.7715019 (13)\ttotal: 558ms\tremaining: 8.59s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 117.7715019\n",
      "bestIteration = 13\n",
      "\n",
      "Shrink model to first 14 iterations.\n",
      "RMSE: 117.77150193094023\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "validation_scores = []\n",
    "models = []\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "kf = KFold(n_splits=folds)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X=X_train,y=y_train,eval_set=(X_test,y_test),verbose=10)\n",
    "   \n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test,pred) ** 0.5\n",
    "    validation_scores.append(score)\n",
    "    models.append(model)\n",
    "    print('RMSE:', score)\n",
    "    \n",
    "    train_preds += model.predict(X_train_df)\n",
    "    test_preds += model.predict(X_test_df)\n",
    "    \n",
    "train_preds /= folds\n",
    "test_preds /= folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_meter_waiting_till_pickup'] = train_preds\n",
    "test_df['predicted_meter_waiting_till_pickup'] = test_preds\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_diff'] = train_df['meter_waiting_till_pickup'] - train_df['predicted_meter_waiting_till_pickup']\n",
    "test_df['predicted_meter_waiting_till_pickup_diff'] = test_df['meter_waiting_till_pickup'] - test_df['predicted_meter_waiting_till_pickup']\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup'] = train_df['predicted_meter_waiting_till_pickup_diff'] / (train_df['meter_waiting_till_pickup']+1)\n",
    "test_df['predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup'] = test_df['predicted_meter_waiting_till_pickup_diff'] / (test_df['meter_waiting_till_pickup']+1)\n",
    "\n",
    "train_df['meter_waiting_till_pickup_per_meter_waiting'] = train_df['meter_waiting_till_pickup'] / (train_df['meter_waiting'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_meter_waiting'] = test_df['meter_waiting_till_pickup'] / (test_df['meter_waiting'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_meter_waiting'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_meter_waiting'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting_diff'] = train_df['meter_waiting_till_pickup_per_meter_waiting'] - train_df['predicted_meter_waiting_till_pickup_per_meter_waiting']\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting_diff'] = test_df['meter_waiting_till_pickup_per_meter_waiting'] - test_df['predicted_meter_waiting_till_pickup_per_meter_waiting']\n",
    "\n",
    "train_df['meter_waiting_after_pickup'] = train_df['meter_waiting'] - train_df['meter_waiting_till_pickup']\n",
    "test_df['meter_waiting_after_pickup'] = test_df['meter_waiting'] - test_df['meter_waiting_till_pickup']\n",
    "\n",
    "train_df['predicted_meter_waiting_after_pickup'] = train_df['predicted_meter_waiting'] - train_df['predicted_meter_waiting_till_pickup']\n",
    "test_df['predicted_meter_waiting_after_pickup'] = test_df['predicted_meter_waiting'] - test_df['predicted_meter_waiting_till_pickup']\n",
    "\n",
    "train_df['meter_waiting_after_pickup_per_duration'] = train_df['meter_waiting_after_pickup'] / (train_df['duration'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_duration'] = test_df['meter_waiting_after_pickup'] / (test_df['duration'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_after_pickup_per_duration'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_duration'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_duration'] + 1)\n",
    "\n",
    "train_df['meter_waiting_till_pickup_per_duration'] = train_df['meter_waiting_till_pickup'] / (train_df['duration'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_duration'] = test_df['meter_waiting_till_pickup'] / (test_df['duration'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_duration'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_duration'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_duration'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_duration'] + 1)\n",
    "\n",
    "train_df['meter_waiting_till_pickup_per_distance'] = train_df['meter_waiting_till_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_distance'] = test_df['meter_waiting_till_pickup'] / (test_df['distance_km'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_distance'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_distance'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['distance_km'] + 1)\n",
    "\n",
    "train_df['meter_waiting_after_pickup_per_distance'] = train_df['meter_waiting_after_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_distance'] = test_df['meter_waiting_after_pickup'] / (test_df['distance_km'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_after_pickup_per_distance'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['distance_km'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_distance'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['distance_km'] + 1)\n",
    "\n",
    "train_df['meter_waiting_till_pickup_per_fare'] = train_df['meter_waiting_till_pickup'] / (train_df['fare'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_fare'] = test_df['meter_waiting_till_pickup'] / (test_df['fare'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_fare'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_fare'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_fare'] + 1)\n",
    "\n",
    "train_df['meter_waiting_after_pickup_per_fare'] = train_df['meter_waiting_after_pickup'] / (train_df['fare'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_fare'] = test_df['meter_waiting_after_pickup'] / (test_df['fare'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_after_pickup_per_fare'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_fare'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_fare'] + 1)\n",
    "\n",
    "train_df['meter_waiting_till_pickup_per_meter_waiting_fare'] = train_df['meter_waiting_till_pickup'] / (train_df['meter_waiting_fare'] + 1)\n",
    "test_df['meter_waiting_till_pickup_per_meter_waiting_fare'] = test_df['meter_waiting_till_pickup'] / (test_df['meter_waiting_fare'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_till_pickup_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_till_pickup'] / (train_df['predicted_meter_waiting_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_till_pickup_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_till_pickup'] / (test_df['predicted_meter_waiting_fare'] + 1)\n",
    "\n",
    "train_df['meter_waiting_after_pickup_per_meter_waiting_fare'] = train_df['meter_waiting_after_pickup'] / (train_df['meter_waiting_fare'] + 1)\n",
    "test_df['meter_waiting_after_pickup_per_meter_waiting_fare'] = test_df['meter_waiting_after_pickup'] / (test_df['meter_waiting_fare'] + 1)\n",
    "\n",
    "train_df['predicted_meter_waiting_after_pickup_per_meter_waiting_fare'] = train_df['predicted_meter_waiting_after_pickup'] / (train_df['predicted_meter_waiting_fare'] + 1)\n",
    "test_df['predicted_meter_waiting_after_pickup_per_meter_waiting_fare'] = test_df['predicted_meter_waiting_after_pickup'] / (test_df['predicted_meter_waiting_fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anomaly = pd.read_csv('train_df_anomaly.csv')\n",
    "test_anomaly = pd.read_csv('test_df_anomaly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_columns = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in anomaly_columns:\n",
    "    train_df[col] = 1-train_anomaly[col]\n",
    "    test_df[col] = 1-test_anomaly[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_multiplicatives = {\n",
    "    'fare_anomaly':[\n",
    "        'predicted_fare_diff',\n",
    "        'predicted_fare_diff_per_fare',\n",
    "        'predicted_fare_diff_per_distance',\n",
    "    ],\n",
    "    'additional_fare_anomaly':[\n",
    "        'predicted_additional_fare_diff',\n",
    "        'predicted_additional_fare_diff_per_additional_fare',\n",
    "        'predicted_addtional_fare_per_distance',\n",
    "    ],\n",
    "    'duration_anomaly':[\n",
    "        'predicted_duration_diff', \n",
    "        'predicted_duraton_diff_per_duraton',\n",
    "        'predicted_duraton_diff_per_distance', \n",
    "    ],\n",
    "    'meter_waiting_anomaly':[\n",
    "        'predicted_meter_waiting_diff',\n",
    "        'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "        'predicted_meter_waiting_diff_per_distance'\n",
    "    ],\n",
    "    'meter_waiting_fare_anomaly':[\n",
    "        'predicted_meter_waiting_fare_diff',\n",
    "        'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "        'predicted_meter_waiting_fare_diff_per_distance'\n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col1 in anomaly_multiplicatives:\n",
    "    for col2 in anomaly_multiplicatives[col1]:\n",
    "        name = f'{col1}_{col2}_prod'\n",
    "        train_df[name] = train_df[col1] * train_df[col2]\n",
    "        test_df[name] = test_df[col1] * test_df[col2]\n",
    "        new_cols.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_duraton_diff_per_duraton@predicted_duraton_diff_per_distance'] = train_df['predicted_duraton_diff_per_duraton'] * train_df['predicted_duraton_diff_per_distance']\n",
    "test_df['predicted_duraton_diff_per_duraton@predicted_duraton_diff_per_distance'] = test_df['predicted_duraton_diff_per_duraton'] * test_df['predicted_duraton_diff_per_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_diff(col_name):\n",
    "    normalizer = StandardScaler()\n",
    "    normalizer.fit(train_df[train_df['label'] == 1][col_name].values.reshape(-1,1))\n",
    "\n",
    "    train_df[f'{col_name}_normalized'] = normalizer.transform(train_df[col_name].values.reshape(-1,1))\n",
    "    test_df[f'{col_name}_normalized'] = normalizer.transform(test_df[col_name].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cols = [\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare', \n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration', \n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare'\n",
    "]\n",
    "for col in diff_cols:\n",
    "    normalize_diff(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_value(col):\n",
    "    grouping_order = ['pick_cluster','pickup_timeslot']\n",
    "    group = train_df[train_df['label'] == 1].groupby(grouping_order)[col].mean()\n",
    "    def f(row):\n",
    "        return group[row['pick_cluster']][row['pickup_timeslot']]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoding(col):\n",
    "    train_df[f'{col}_mean'] = train_df.apply(mean_value(col),axis=1)\n",
    "    test_df[f'{col}_mean'] = test_df.apply(mean_value(col),axis=1)\n",
    "    \n",
    "    train_df[f'{col}_mean_diff'] = train_df[f'{col}_mean'] - train_df[col]\n",
    "    test_df[f'{col}_mean_diff'] = test_df[f'{col}_mean'] - test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cols = [\n",
    "    'fare_per_distance',\n",
    "    'avg_speed', \n",
    "    'meter_waiting_per_duration', \n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance', \n",
    "    'addtional_fare_per_duration'\n",
    "]\n",
    "for col in mean_cols:\n",
    "    mean_encoding(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_duration_diff',\n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_additional_fare_diff',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_bucket(column):\n",
    "    std = train_df[train_df['label']==1][column].std()\n",
    "    name = f'{column}_bucket'\n",
    "    train_df[name] = np.round((train_df[column]/std)+1).astype(int)\n",
    "    test_df[name] = np.round((test_df[column]/std)+1).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in cols:\n",
    "    col_bucket(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_multiplicatives = {\n",
    "    'predicted_fare_diff_bucket':[\n",
    "        'fare',\n",
    "        'predicted_fare',\n",
    "        'fare_per_distance',\n",
    "        'predicted_fare_per_distance',         \n",
    "    ],\n",
    "    'predicted_duration_diff_bucket':[\n",
    "        'duration',\n",
    "        'predicted_duration',\n",
    "        'avg_speed', \n",
    "        'predicted_avg_speed',         \n",
    "    ],\n",
    "    'predicted_meter_waiting_diff_bucket':[\n",
    "        'meter_waiting', \n",
    "        'predicted_meter_waiting', \n",
    "        'meter_waiting_per_duration', \n",
    "        'predicted_meter_waiting_per_duration',\n",
    "    ],\n",
    "    'predicted_meter_waiting_fare_diff_bucket':[\n",
    "        'meter_waiting_fare',\n",
    "        'predicted_meter_waiting_fare',\n",
    "        'meter_waiting_fare_per_meter_waiting',\n",
    "        'predicted_meter_waiting_fare_per_meter_waiting',\n",
    "        'meter_waiting_fare_per_duration',\n",
    "        'predicted_meter_waiting_fare_per_duration',\n",
    "    ],\n",
    "    'predicted_additional_fare_diff':[\n",
    "        'additional_fare',\n",
    "        'predicted_additional_fare', \n",
    "        'predicted_addtional_fare_per_fare', \n",
    "        'addtional_fare_per_fare',\n",
    "        'addtional_fare_per_distance', \n",
    "        'predicted_addtional_fare_per_distance',\n",
    "        'addtional_fare_per_duration', \n",
    "        'predicted_addtional_fare_per_duration',\n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 102.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for bucket in tqdm(bin_multiplicatives):\n",
    "    for col in bin_multiplicatives[bucket]:\n",
    "        name = f'{bucket}@{col}'\n",
    "        train_df[name] = train_df[bucket] * train_df[col]\n",
    "        test_df[name] = test_df[bucket] * test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_final.csv',index=False)\n",
    "test_df.to_csv('test_df_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "test_df = test_df.fillna(0)\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cat_cols = [\n",
    "    'pickup_hour',\n",
    "    'drop_hour',\n",
    "#     'pick_cluster'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'fare_per_distance',\n",
    "    'fare_per_duration',\n",
    "    'avg_speed',\n",
    "    'meter_waiting_per_duration',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration',\n",
    "    'fare-additional_fare_per_distance',\n",
    "    'fare-additional_fare_per_duration',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_distance',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_duration',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting',\n",
    "    'meter_waiting_after_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_distance',\n",
    "    'meter_waiting_after_pickup_per_distance',\n",
    "    'meter_waiting_till_pickup_per_fare',\n",
    "    'meter_waiting_after_pickup_per_fare',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting_fare',\n",
    "    'meter_waiting_after_pickup_per_meter_waiting_fare',    \n",
    "    'meter_waiting_till_pickup'\n",
    "]\n",
    "\n",
    "cat_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += original_cat_cols\n",
    "cat_features += original_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumeric_cols_to_multiply = [\n",
    "    'fare_per_distance',    \n",
    "    'avg_speed',    \n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_till_pickup'\n",
    "]\n",
    "\n",
    "encoding_cols = []\n",
    "for col1 in original_cat_cols:\n",
    "    for col2 in neumeric_cols_to_multiply:\n",
    "        name = f'{col1}@{col2}'\n",
    "        train_df[name] = train_df[col1] * train_df[col2]\n",
    "        test_df[name] = test_df[col1] * test_df[col2]\n",
    "        encoding_cols.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += encoding_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9666778\ttest: 0.9632290\tbest: 0.9632290 (0)\ttotal: 22.3ms\tremaining: 22.3s\n",
      "10:\tlearn: 0.9699035\ttest: 0.9739840\tbest: 0.9739840 (10)\ttotal: 182ms\tremaining: 16.4s\n",
      "20:\tlearn: 0.9728780\ttest: 0.9763629\tbest: 0.9764695 (16)\ttotal: 349ms\tremaining: 16.3s\n",
      "30:\tlearn: 0.9745396\ttest: 0.9771838\tbest: 0.9771838 (30)\ttotal: 483ms\tremaining: 15.1s\n",
      "40:\tlearn: 0.9756005\ttest: 0.9772510\tbest: 0.9774422 (36)\ttotal: 634ms\tremaining: 14.8s\n",
      "50:\tlearn: 0.9765245\ttest: 0.9776969\tbest: 0.9777097 (46)\ttotal: 767ms\tremaining: 14.3s\n",
      "60:\tlearn: 0.9772239\ttest: 0.9777905\tbest: 0.9779904 (52)\ttotal: 915ms\tremaining: 14.1s\n",
      "70:\tlearn: 0.9777799\ttest: 0.9776927\tbest: 0.9779904 (52)\ttotal: 1.1s\tremaining: 14.4s\n",
      "80:\tlearn: 0.9787173\ttest: 0.9772967\tbest: 0.9779904 (52)\ttotal: 1.28s\tremaining: 14.5s\n",
      "90:\tlearn: 0.9790859\ttest: 0.9774840\tbest: 0.9779904 (52)\ttotal: 1.41s\tremaining: 14.1s\n",
      "100:\tlearn: 0.9793222\ttest: 0.9779567\tbest: 0.9779904 (52)\ttotal: 1.56s\tremaining: 13.9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9779904306\n",
      "bestIteration = 52\n",
      "\n",
      "Shrink model to first 53 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9657029\ttest: 0.9651985\tbest: 0.9651985 (0)\ttotal: 69.2ms\tremaining: 1m 9s\n",
      "10:\tlearn: 0.9718704\ttest: 0.9726340\tbest: 0.9726392 (7)\ttotal: 359ms\tremaining: 32.3s\n",
      "20:\tlearn: 0.9733428\ttest: 0.9749595\tbest: 0.9749595 (20)\ttotal: 551ms\tremaining: 25.7s\n",
      "30:\tlearn: 0.9744371\ttest: 0.9755075\tbest: 0.9756098 (27)\ttotal: 740ms\tremaining: 23.1s\n",
      "40:\tlearn: 0.9757376\ttest: 0.9760519\tbest: 0.9760519 (40)\ttotal: 885ms\tremaining: 20.7s\n",
      "50:\tlearn: 0.9764779\ttest: 0.9768019\tbest: 0.9768019 (50)\ttotal: 1.05s\tremaining: 19.6s\n",
      "60:\tlearn: 0.9772749\ttest: 0.9774508\tbest: 0.9774508 (57)\ttotal: 1.19s\tremaining: 18.3s\n",
      "70:\tlearn: 0.9778330\ttest: 0.9774335\tbest: 0.9778245 (64)\ttotal: 1.38s\tremaining: 18s\n",
      "80:\tlearn: 0.9785301\ttest: 0.9774076\tbest: 0.9778245 (64)\ttotal: 1.56s\tremaining: 17.7s\n",
      "90:\tlearn: 0.9790511\ttest: 0.9775012\tbest: 0.9778245 (64)\ttotal: 1.73s\tremaining: 17.3s\n",
      "100:\tlearn: 0.9794278\ttest: 0.9776927\tbest: 0.9778245 (64)\ttotal: 1.87s\tremaining: 16.7s\n",
      "110:\tlearn: 0.9799904\ttest: 0.9780672\tbest: 0.9780672 (110)\ttotal: 2.03s\tremaining: 16.2s\n",
      "120:\tlearn: 0.9803189\ttest: 0.9782505\tbest: 0.9782505 (119)\ttotal: 2.19s\tremaining: 15.9s\n",
      "130:\tlearn: 0.9810236\ttest: 0.9783442\tbest: 0.9784379 (128)\ttotal: 2.39s\tremaining: 15.9s\n",
      "140:\tlearn: 0.9812171\ttest: 0.9782463\tbest: 0.9784379 (128)\ttotal: 2.56s\tremaining: 15.6s\n",
      "150:\tlearn: 0.9819263\ttest: 0.9780546\tbest: 0.9784379 (128)\ttotal: 2.72s\tremaining: 15.3s\n",
      "160:\tlearn: 0.9825874\ttest: 0.9779609\tbest: 0.9784379 (128)\ttotal: 2.85s\tremaining: 14.9s\n",
      "170:\tlearn: 0.9829175\ttest: 0.9781442\tbest: 0.9784379 (128)\ttotal: 3.01s\tremaining: 14.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9784379492\n",
      "bestIteration = 128\n",
      "\n",
      "Shrink model to first 129 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9703251\ttest: 0.9646351\tbest: 0.9646351 (0)\ttotal: 21.2ms\tremaining: 21.2s\n",
      "10:\tlearn: 0.9750202\ttest: 0.9672240\tbest: 0.9672240 (10)\ttotal: 213ms\tremaining: 19.2s\n",
      "20:\tlearn: 0.9767907\ttest: 0.9685785\tbest: 0.9685785 (20)\ttotal: 424ms\tremaining: 19.8s\n",
      "30:\tlearn: 0.9772966\ttest: 0.9690312\tbest: 0.9691171 (29)\ttotal: 613ms\tremaining: 19.2s\n",
      "40:\tlearn: 0.9784104\ttest: 0.9694439\tbest: 0.9694439 (40)\ttotal: 817ms\tremaining: 19.1s\n",
      "50:\tlearn: 0.9790571\ttest: 0.9698984\tbest: 0.9698984 (50)\ttotal: 975ms\tremaining: 18.1s\n",
      "60:\tlearn: 0.9795743\ttest: 0.9699848\tbest: 0.9700883 (55)\ttotal: 1.13s\tremaining: 17.4s\n",
      "70:\tlearn: 0.9802288\ttest: 0.9702500\tbest: 0.9702613 (63)\ttotal: 1.27s\tremaining: 16.6s\n",
      "80:\tlearn: 0.9809332\ttest: 0.9708959\tbest: 0.9708959 (80)\ttotal: 1.43s\tremaining: 16.3s\n",
      "90:\tlearn: 0.9812171\ttest: 0.9712709\tbest: 0.9714558 (85)\ttotal: 1.62s\tremaining: 16.2s\n",
      "100:\tlearn: 0.9814034\ttest: 0.9719181\tbest: 0.9719181 (100)\ttotal: 1.86s\tremaining: 16.5s\n",
      "110:\tlearn: 0.9818775\ttest: 0.9720053\tbest: 0.9720160 (104)\ttotal: 1.99s\tremaining: 16s\n",
      "120:\tlearn: 0.9822559\ttest: 0.9721905\tbest: 0.9723810 (117)\ttotal: 2.17s\tremaining: 15.7s\n",
      "130:\tlearn: 0.9824460\ttest: 0.9721852\tbest: 0.9723810 (117)\ttotal: 2.32s\tremaining: 15.4s\n",
      "140:\tlearn: 0.9829663\ttest: 0.9719947\tbest: 0.9723810 (117)\ttotal: 2.49s\tremaining: 15.2s\n",
      "150:\tlearn: 0.9832509\ttest: 0.9721693\tbest: 0.9723810 (117)\ttotal: 2.64s\tremaining: 14.9s\n",
      "160:\tlearn: 0.9835373\ttest: 0.9722566\tbest: 0.9723810 (117)\ttotal: 2.84s\tremaining: 14.8s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9723809524\n",
      "bestIteration = 117\n",
      "\n",
      "Shrink model to first 118 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "models = []\n",
    "train_pools = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    train_pools.append(train_pool)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = test_class\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "test_df = test_df.fillna(0)\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cat_cols = [\n",
    "    'pickup_hour',\n",
    "    'drop_hour',\n",
    "#     'pick_cluster'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'fare_per_distance',\n",
    "    'fare_per_duration',\n",
    "    'avg_speed',\n",
    "    'meter_waiting_per_duration',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration',\n",
    "    'fare-additional_fare_per_distance',\n",
    "    'fare-additional_fare_per_duration',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_distance',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_duration',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting',\n",
    "    'meter_waiting_after_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_distance',\n",
    "    'meter_waiting_after_pickup_per_distance',\n",
    "    'meter_waiting_till_pickup_per_fare',\n",
    "    'meter_waiting_after_pickup_per_fare',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting_fare',\n",
    "    'meter_waiting_after_pickup_per_meter_waiting_fare',    \n",
    "    'meter_waiting_till_pickup',\n",
    "    \n",
    "    'additional_fare',\n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    \n",
    "    'predicted_duration_diff',\n",
    "    'predicted_fare_diff_per_predicted_fare',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_distance',\n",
    "]\n",
    "\n",
    "cat_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += original_cat_cols\n",
    "cat_features += original_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumeric_cols_to_multiply = [\n",
    "    'fare_per_distance',  \n",
    "#     'fare_per_duration',\n",
    "#     'fare-additional_fare_per_duration',\n",
    "    'avg_speed',    \n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_till_pickup'\n",
    "]\n",
    "\n",
    "encoding_cols = []\n",
    "for col1 in original_cat_cols:\n",
    "    for col2 in neumeric_cols_to_multiply:\n",
    "        name = f'{col1}@{col2}'\n",
    "        train_df[name] = train_df[col1] * train_df[col2]\n",
    "        test_df[name] = test_df[col1] * test_df[col2]\n",
    "        encoding_cols.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_features = []\n",
    "\n",
    "train_df['pickup_timeslot@distance'] = (train_df['pickup_timeslot']+1) * train_df['distance_km']\n",
    "test_df['pickup_timeslot@distance'] = (test_df['pickup_timeslot']+1) * test_df['distance_km']\n",
    "special_features.append('pickup_timeslot@distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += encoding_cols\n",
    "features += special_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9682270\ttest: 0.9657256\tbest: 0.9657256 (0)\ttotal: 26.3ms\tremaining: 26.3s\n",
      "10:\tlearn: 0.9740705\ttest: 0.9766597\tbest: 0.9766597 (10)\ttotal: 217ms\tremaining: 19.5s\n",
      "20:\tlearn: 0.9756424\ttest: 0.9774883\tbest: 0.9775905 (15)\ttotal: 376ms\tremaining: 17.5s\n",
      "30:\tlearn: 0.9769268\ttest: 0.9777479\tbest: 0.9781358 (27)\ttotal: 545ms\tremaining: 17.1s\n",
      "40:\tlearn: 0.9780931\ttest: 0.9780083\tbest: 0.9781358 (27)\ttotal: 702ms\tremaining: 16.4s\n",
      "50:\tlearn: 0.9786601\ttest: 0.9782003\tbest: 0.9784946 (45)\ttotal: 903ms\tremaining: 16.8s\n",
      "60:\tlearn: 0.9792766\ttest: 0.9781878\tbest: 0.9784946 (45)\ttotal: 1.07s\tremaining: 16.6s\n",
      "70:\tlearn: 0.9797466\ttest: 0.9778974\tbest: 0.9784946 (45)\ttotal: 1.29s\tremaining: 16.9s\n",
      "80:\tlearn: 0.9802698\ttest: 0.9781710\tbest: 0.9784946 (45)\ttotal: 1.44s\tremaining: 16.4s\n",
      "90:\tlearn: 0.9808367\ttest: 0.9782609\tbest: 0.9784946 (45)\ttotal: 1.68s\tremaining: 16.8s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9784946237\n",
      "bestIteration = 45\n",
      "\n",
      "Shrink model to first 46 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9706232\ttest: 0.9722566\tbest: 0.9722566 (0)\ttotal: 28.1ms\tremaining: 28s\n",
      "10:\tlearn: 0.9749713\ttest: 0.9772554\tbest: 0.9772554 (10)\ttotal: 202ms\tremaining: 18.2s\n",
      "20:\tlearn: 0.9760880\ttest: 0.9774335\tbest: 0.9776333 (15)\ttotal: 434ms\tremaining: 20.2s\n",
      "30:\tlearn: 0.9771694\ttest: 0.9781735\tbest: 0.9781735 (30)\ttotal: 610ms\tremaining: 19.1s\n",
      "40:\tlearn: 0.9776287\ttest: 0.9784379\tbest: 0.9790250 (35)\ttotal: 796ms\tremaining: 18.6s\n",
      "50:\tlearn: 0.9782442\ttest: 0.9787071\tbest: 0.9790250 (35)\ttotal: 968ms\tremaining: 18s\n",
      "60:\tlearn: 0.9791397\ttest: 0.9784090\tbest: 0.9790250 (35)\ttotal: 1.14s\tremaining: 17.6s\n",
      "70:\tlearn: 0.9797563\ttest: 0.9786866\tbest: 0.9790250 (35)\ttotal: 1.31s\tremaining: 17.2s\n",
      "80:\tlearn: 0.9801325\ttest: 0.9787806\tbest: 0.9790707 (77)\ttotal: 1.49s\tremaining: 16.9s\n",
      "90:\tlearn: 0.9809474\ttest: 0.9788746\tbest: 0.9790707 (77)\ttotal: 1.7s\tremaining: 17s\n",
      "100:\tlearn: 0.9815197\ttest: 0.9785927\tbest: 0.9790707 (77)\ttotal: 1.95s\tremaining: 17.3s\n",
      "110:\tlearn: 0.9816086\ttest: 0.9787806\tbest: 0.9790707 (77)\ttotal: 2.18s\tremaining: 17.4s\n",
      "120:\tlearn: 0.9820871\ttest: 0.9784864\tbest: 0.9790707 (77)\ttotal: 2.37s\tremaining: 17.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9790706605\n",
      "bestIteration = 77\n",
      "\n",
      "Shrink model to first 78 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9729652\ttest: 0.9665072\tbest: 0.9665072 (0)\ttotal: 20.1ms\tremaining: 20.1s\n",
      "10:\tlearn: 0.9776248\ttest: 0.9697143\tbest: 0.9697201 (9)\ttotal: 199ms\tremaining: 17.9s\n",
      "20:\tlearn: 0.9790799\ttest: 0.9701535\tbest: 0.9703555 (16)\ttotal: 392ms\tremaining: 18.3s\n",
      "30:\tlearn: 0.9796290\ttest: 0.9710795\tbest: 0.9711777 (29)\ttotal: 568ms\tremaining: 17.7s\n",
      "40:\tlearn: 0.9801515\ttest: 0.9711612\tbest: 0.9711777 (29)\ttotal: 863ms\tremaining: 20.2s\n",
      "50:\tlearn: 0.9808569\ttest: 0.9710685\tbest: 0.9711777 (29)\ttotal: 1.04s\tremaining: 19.3s\n",
      "60:\tlearn: 0.9811864\ttest: 0.9715377\tbest: 0.9716359 (55)\ttotal: 1.22s\tremaining: 18.8s\n",
      "70:\tlearn: 0.9815144\ttest: 0.9716305\tbest: 0.9716359 (55)\ttotal: 1.38s\tremaining: 18s\n",
      "80:\tlearn: 0.9819404\ttest: 0.9719037\tbest: 0.9719037 (78)\ttotal: 1.56s\tremaining: 17.7s\n",
      "90:\tlearn: 0.9824207\ttest: 0.9719912\tbest: 0.9720948 (83)\ttotal: 1.74s\tremaining: 17.4s\n",
      "100:\tlearn: 0.9827056\ttest: 0.9720735\tbest: 0.9720948 (83)\ttotal: 1.94s\tremaining: 17.3s\n",
      "110:\tlearn: 0.9832316\ttest: 0.9722753\tbest: 0.9722753 (108)\ttotal: 2.21s\tremaining: 17.7s\n",
      "120:\tlearn: 0.9838035\ttest: 0.9725543\tbest: 0.9725543 (116)\ttotal: 2.4s\tremaining: 17.4s\n",
      "130:\tlearn: 0.9840904\ttest: 0.9724613\tbest: 0.9726473 (128)\ttotal: 2.6s\tremaining: 17.2s\n",
      "140:\tlearn: 0.9846642\ttest: 0.9723630\tbest: 0.9726473 (128)\ttotal: 2.79s\tremaining: 17s\n",
      "150:\tlearn: 0.9849067\ttest: 0.9724560\tbest: 0.9726473 (128)\ttotal: 2.99s\tremaining: 16.8s\n",
      "160:\tlearn: 0.9853358\ttest: 0.9721611\tbest: 0.9726473 (128)\ttotal: 3.18s\tremaining: 16.6s\n",
      "170:\tlearn: 0.9855282\ttest: 0.9721611\tbest: 0.9726473 (128)\ttotal: 3.38s\tremaining: 16.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9726472839\n",
      "bestIteration = 128\n",
      "\n",
      "Shrink model to first 129 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "models = []\n",
    "train_pools = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    train_pools.append(train_pool)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = test_class\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat,average='micro'), True\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = 1-f1_score(y_true, np.round(y_pred),average='micro')\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_final.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = pd.read_csv('test_df_final.csv')\n",
    "test_df = test_df.fillna(0)\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_train = pd.DataFrame()\n",
    "model_predictions_train['label'] = train_df['label']\n",
    "model_predictions_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heshan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/heshan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'fare_anomaly',\n",
    "    'additional_fare_anomaly', \n",
    "    'duration_anomaly',\n",
    "    'meter_waiting_anomaly', \n",
    "    'meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_till_pickup_anomaly', \n",
    "    'additional_fare_duration_anomaly',\n",
    "    'additional_fare_meter_waiting_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_anomaly', \n",
    "    'duration_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_fare_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_duration_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'additional_fare_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "    'duration_meter_waiting_meter_waiting_fare_meter_waiting_till_pickup_anomaly',\n",
    "]\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9531844\ttest: 0.9530251\tbest: 0.9530251 (0)\ttotal: 5.26ms\tremaining: 5.26s\n",
      "10:\tlearn: 0.9534970\ttest: 0.9531481\tbest: 0.9533160 (1)\ttotal: 52.6ms\tremaining: 4.73s\n",
      "20:\tlearn: 0.9536295\ttest: 0.9533160\tbest: 0.9533247 (11)\ttotal: 97.4ms\tremaining: 4.54s\n",
      "30:\tlearn: 0.9540672\ttest: 0.9534754\tbest: 0.9534754 (28)\ttotal: 142ms\tremaining: 4.43s\n",
      "40:\tlearn: 0.9551255\ttest: 0.9549800\tbest: 0.9549800 (40)\ttotal: 189ms\tremaining: 4.43s\n",
      "50:\tlearn: 0.9556092\ttest: 0.9552294\tbest: 0.9552294 (50)\ttotal: 284ms\tremaining: 5.28s\n",
      "60:\tlearn: 0.9556051\ttest: 0.9552211\tbest: 0.9552294 (50)\ttotal: 329ms\tremaining: 5.07s\n",
      "70:\tlearn: 0.9558632\ttest: 0.9552932\tbest: 0.9552932 (70)\ttotal: 376ms\tremaining: 4.92s\n",
      "80:\tlearn: 0.9562671\ttest: 0.9554709\tbest: 0.9555597 (78)\ttotal: 428ms\tremaining: 4.86s\n",
      "90:\tlearn: 0.9564894\ttest: 0.9555597\tbest: 0.9555597 (78)\ttotal: 473ms\tremaining: 4.73s\n",
      "100:\tlearn: 0.9566067\ttest: 0.9555514\tbest: 0.9556485 (91)\ttotal: 526ms\tremaining: 4.68s\n",
      "110:\tlearn: 0.9567402\ttest: 0.9556403\tbest: 0.9556485 (91)\ttotal: 574ms\tremaining: 4.6s\n",
      "120:\tlearn: 0.9569627\ttest: 0.9556403\tbest: 0.9556485 (91)\ttotal: 623ms\tremaining: 4.53s\n",
      "130:\tlearn: 0.9570764\ttest: 0.9550405\tbest: 0.9556485 (91)\ttotal: 694ms\tremaining: 4.6s\n",
      "140:\tlearn: 0.9571209\ttest: 0.9550405\tbest: 0.9556485 (91)\ttotal: 770ms\tremaining: 4.69s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9556485356\n",
      "bestIteration = 91\n",
      "\n",
      "Shrink model to first 92 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9531793\ttest: 0.9523810\tbest: 0.9523810 (0)\ttotal: 14ms\tremaining: 14s\n",
      "10:\tlearn: 0.9534087\ttest: 0.9530512\tbest: 0.9531308 (3)\ttotal: 72.6ms\tremaining: 6.53s\n",
      "20:\tlearn: 0.9538547\ttest: 0.9533074\tbest: 0.9533074 (20)\ttotal: 121ms\tremaining: 5.66s\n",
      "30:\tlearn: 0.9546867\ttest: 0.9540145\tbest: 0.9540230 (29)\ttotal: 172ms\tremaining: 5.37s\n",
      "40:\tlearn: 0.9557465\ttest: 0.9545455\tbest: 0.9545455 (38)\ttotal: 232ms\tremaining: 5.43s\n",
      "50:\tlearn: 0.9558311\ttest: 0.9549884\tbest: 0.9549884 (50)\ttotal: 281ms\tremaining: 5.24s\n",
      "60:\tlearn: 0.9560450\ttest: 0.9547776\tbest: 0.9549884 (50)\ttotal: 329ms\tremaining: 5.07s\n",
      "70:\tlearn: 0.9564287\ttest: 0.9544779\tbest: 0.9549884 (50)\ttotal: 377ms\tremaining: 4.94s\n",
      "80:\tlearn: 0.9566471\ttest: 0.9544610\tbest: 0.9549884 (50)\ttotal: 425ms\tremaining: 4.83s\n",
      "90:\tlearn: 0.9572260\ttest: 0.9547103\tbest: 0.9549884 (50)\ttotal: 515ms\tremaining: 5.14s\n",
      "100:\tlearn: 0.9573596\ttest: 0.9547103\tbest: 0.9549884 (50)\ttotal: 615ms\tremaining: 5.47s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9549883991\n",
      "bestIteration = 50\n",
      "\n",
      "Shrink model to first 51 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9532589\ttest: 0.9522042\tbest: 0.9522042 (0)\ttotal: 5.59ms\tremaining: 5.58s\n",
      "10:\tlearn: 0.9529673\ttest: 0.9530599\tbest: 0.9534130 (7)\ttotal: 57.9ms\tremaining: 5.21s\n",
      "20:\tlearn: 0.9539788\ttest: 0.9539260\tbest: 0.9540230 (17)\ttotal: 117ms\tremaining: 5.44s\n",
      "30:\tlearn: 0.9547268\ttest: 0.9538290\tbest: 0.9540230 (17)\ttotal: 172ms\tremaining: 5.37s\n",
      "40:\tlearn: 0.9554844\ttest: 0.9542459\tbest: 0.9542544 (36)\ttotal: 268ms\tremaining: 6.28s\n",
      "50:\tlearn: 0.9558755\ttest: 0.9545117\tbest: 0.9546003 (47)\ttotal: 337ms\tremaining: 6.28s\n",
      "60:\tlearn: 0.9559643\ttest: 0.9546890\tbest: 0.9546890 (52)\ttotal: 406ms\tremaining: 6.26s\n",
      "70:\tlearn: 0.9561420\ttest: 0.9549466\tbest: 0.9549466 (70)\ttotal: 480ms\tremaining: 6.28s\n",
      "80:\tlearn: 0.9565379\ttest: 0.9552932\tbest: 0.9552932 (80)\ttotal: 552ms\tremaining: 6.27s\n",
      "90:\tlearn: 0.9567118\ttest: 0.9551878\tbest: 0.9552932 (80)\ttotal: 617ms\tremaining: 6.17s\n",
      "100:\tlearn: 0.9568412\ttest: 0.9553654\tbest: 0.9553654 (96)\ttotal: 676ms\tremaining: 6.01s\n",
      "110:\tlearn: 0.9569707\ttest: 0.9553571\tbest: 0.9553654 (96)\ttotal: 747ms\tremaining: 5.99s\n",
      "120:\tlearn: 0.9570153\ttest: 0.9552600\tbest: 0.9553654 (96)\ttotal: 805ms\tremaining: 5.85s\n",
      "130:\tlearn: 0.9570558\ttest: 0.9552600\tbest: 0.9553654 (96)\ttotal: 859ms\tremaining: 5.7s\n",
      "140:\tlearn: 0.9571449\ttest: 0.9551461\tbest: 0.9555349 (132)\ttotal: 910ms\tremaining: 5.54s\n",
      "150:\tlearn: 0.9573230\ttest: 0.9552350\tbest: 0.9555349 (132)\ttotal: 984ms\tremaining: 5.53s\n",
      "160:\tlearn: 0.9573676\ttest: 0.9551378\tbest: 0.9555349 (132)\ttotal: 1.06s\tremaining: 5.5s\n",
      "170:\tlearn: 0.9576311\ttest: 0.9549432\tbest: 0.9555349 (132)\ttotal: 1.13s\tremaining: 5.46s\n",
      "180:\tlearn: 0.9578094\ttest: 0.9547402\tbest: 0.9555349 (132)\ttotal: 1.2s\tremaining: 5.45s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9555348837\n",
      "bestIteration = 132\n",
      "\n",
      "Shrink model to first 133 iterations.\n"
     ]
    }
   ],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "}\n",
    "\n",
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)\n",
    "\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.05,\n",
    "    'seed':0, \n",
    "    'metric':'f1',\n",
    "    'max_depth':6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train,y_train)\n",
    "    valid_data = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(lgb_params, train_data,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid_data,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,np.round(model.predict(X_test)),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':15,\n",
    "    'weights':'uniform'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = KNeighborsClassifier(**knn_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'knn_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':50,\n",
    "    'max_depth':10,\n",
    "    'random_state':0,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'rf_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':2,\n",
    "    'kernel':'linear',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'scale'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svc_linear_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':2,\n",
    "    'kernel':'rbf',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'scale'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svc_rbf_anomaly'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heshan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/heshan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'additional_fare',\n",
    "    'duration',\n",
    "    'meter_waiting',\n",
    "    'meter_waiting_fare',\n",
    "    'meter_waiting_till_pickup',\n",
    "    'fare',\n",
    "    'pickup_date',\n",
    "    'pickup_hour',\n",
    "    'pickup_minute',\n",
    "    'drop_date',\n",
    "    'drop_hour',\n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'distance_km',\n",
    "    'fare_per_km',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "    'cal_time_difference',\n",
    "    'fare_per_distance',\n",
    "    'fare_per_duration',\n",
    "    'avg_speed',\n",
    "    'meter_waiting_per_duration',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration',\n",
    "    'fare-additional_fare',\n",
    "    'fare-additional_fare-meter_waiting_fare',\n",
    "    'fare-additional_fare_per_distance',\n",
    "    'fare-additional_fare_per_duration',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_distance',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_duration',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting',\n",
    "    'meter_waiting_after_pickup',\n",
    "    'meter_waiting_after_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_distance',\n",
    "    'meter_waiting_after_pickup_per_distance',\n",
    "    'meter_waiting_till_pickup_per_fare',\n",
    "    'meter_waiting_after_pickup_per_fare',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting_fare',\n",
    "    'meter_waiting_after_pickup_per_meter_waiting_fare',\n",
    "    'fare_per_distance_mean',\n",
    "    'fare_per_distance_mean_diff',\n",
    "    'avg_speed_mean',\n",
    "    'avg_speed_mean_diff',\n",
    "    'meter_waiting_per_duration_mean',\n",
    "    'meter_waiting_per_duration_mean_diff',\n",
    "    'meter_waiting_fare_per_meter_waiting_mean',\n",
    "    'meter_waiting_fare_per_meter_waiting_mean_diff',\n",
    "    'meter_waiting_fare_per_duration_mean',\n",
    "    'meter_waiting_fare_per_duration_mean_diff',\n",
    "    'addtional_fare_per_fare_mean',\n",
    "    'addtional_fare_per_fare_mean_diff',\n",
    "    'addtional_fare_per_distance_mean',\n",
    "    'addtional_fare_per_distance_mean_diff',\n",
    "    'addtional_fare_per_duration_mean',\n",
    "    'addtional_fare_per_duration_mean_diff',\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'pickup_date',\n",
    "    'pickup_hour',\n",
    "    'pickup_minute',\n",
    "    'drop_date',\n",
    "    'drop_hour',\n",
    "    'drop_minute',\n",
    "    'pick_cluster',\n",
    "    'is_more_than_one_day',\n",
    "    'pickup_timeslot',\n",
    "    'day_of_week',\n",
    "    'is_weekday',\n",
    "]\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9647735\ttest: 0.9632415\tbest: 0.9632415 (0)\ttotal: 41.4ms\tremaining: 41.3s\n",
      "10:\tlearn: 0.9700899\ttest: 0.9719538\tbest: 0.9719538 (10)\ttotal: 346ms\tremaining: 31.1s\n",
      "20:\tlearn: 0.9726190\ttest: 0.9756376\tbest: 0.9756376 (20)\ttotal: 576ms\tremaining: 26.9s\n",
      "30:\tlearn: 0.9750083\ttest: 0.9766199\tbest: 0.9769304 (23)\ttotal: 831ms\tremaining: 26s\n",
      "40:\tlearn: 0.9773833\ttest: 0.9760903\tbest: 0.9769304 (23)\ttotal: 1.13s\tremaining: 26.4s\n",
      "50:\tlearn: 0.9785424\ttest: 0.9761517\tbest: 0.9769304 (23)\ttotal: 1.51s\tremaining: 28s\n",
      "60:\tlearn: 0.9793829\ttest: 0.9707952\tbest: 0.9769304 (23)\ttotal: 1.86s\tremaining: 28.7s\n",
      "70:\tlearn: 0.9799435\ttest: 0.9690125\tbest: 0.9769304 (23)\ttotal: 2.19s\tremaining: 28.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9769304099\n",
      "bestIteration = 23\n",
      "\n",
      "Shrink model to first 24 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9645070\ttest: 0.9653875\tbest: 0.9653875 (0)\ttotal: 36.4ms\tremaining: 36.4s\n",
      "10:\tlearn: 0.9711497\ttest: 0.9728550\tbest: 0.9728550 (10)\ttotal: 301ms\tremaining: 27.1s\n",
      "20:\tlearn: 0.9736792\ttest: 0.9739395\tbest: 0.9739395 (20)\ttotal: 730ms\tremaining: 34s\n",
      "30:\tlearn: 0.9749203\ttest: 0.9749452\tbest: 0.9749452 (30)\ttotal: 1.05s\tremaining: 33s\n",
      "40:\tlearn: 0.9763494\ttest: 0.9762337\tbest: 0.9762337 (39)\ttotal: 1.4s\tremaining: 32.7s\n",
      "50:\tlearn: 0.9774257\ttest: 0.9767797\tbest: 0.9768775 (49)\ttotal: 1.69s\tremaining: 31.4s\n",
      "60:\tlearn: 0.9779349\ttest: 0.9764773\tbest: 0.9768775 (49)\ttotal: 1.97s\tremaining: 30.3s\n",
      "70:\tlearn: 0.9785892\ttest: 0.9765483\tbest: 0.9768775 (49)\ttotal: 2.22s\tremaining: 29s\n",
      "80:\tlearn: 0.9795801\ttest: 0.9763478\tbest: 0.9768775 (49)\ttotal: 2.5s\tremaining: 28.4s\n",
      "90:\tlearn: 0.9801407\ttest: 0.9751320\tbest: 0.9768775 (49)\ttotal: 2.74s\tremaining: 27.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9768775081\n",
      "bestIteration = 49\n",
      "\n",
      "Shrink model to first 50 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9692703\ttest: 0.9625850\tbest: 0.9625850 (0)\ttotal: 33.9ms\tremaining: 33.9s\n",
      "10:\tlearn: 0.9763254\ttest: 0.9672906\tbest: 0.9676687 (9)\ttotal: 283ms\tremaining: 25.4s\n",
      "20:\tlearn: 0.9767442\ttest: 0.9682855\tbest: 0.9683832 (19)\ttotal: 526ms\tremaining: 24.5s\n",
      "30:\tlearn: 0.9778138\ttest: 0.9694902\tbest: 0.9694902 (30)\ttotal: 780ms\tremaining: 24.4s\n",
      "40:\tlearn: 0.9787336\ttest: 0.9698120\tbest: 0.9698235 (39)\ttotal: 1.02s\tremaining: 23.8s\n",
      "50:\tlearn: 0.9792972\ttest: 0.9703535\tbest: 0.9704569 (48)\ttotal: 1.22s\tremaining: 22.8s\n",
      "60:\tlearn: 0.9798555\ttest: 0.9709015\tbest: 0.9709015 (60)\ttotal: 1.47s\tremaining: 22.6s\n",
      "70:\tlearn: 0.9806550\ttest: 0.9705267\tbest: 0.9709883 (64)\ttotal: 1.73s\tremaining: 22.6s\n",
      "80:\tlearn: 0.9813599\ttest: 0.9711676\tbest: 0.9711731 (79)\ttotal: 1.96s\tremaining: 22.2s\n",
      "90:\tlearn: 0.9815498\ttest: 0.9710862\tbest: 0.9711840 (89)\ttotal: 2.21s\tremaining: 22.1s\n",
      "100:\tlearn: 0.9820239\ttest: 0.9712709\tbest: 0.9713688 (97)\ttotal: 2.42s\tremaining: 21.6s\n",
      "110:\tlearn: 0.9822593\ttest: 0.9710972\tbest: 0.9713688 (97)\ttotal: 2.69s\tremaining: 21.6s\n",
      "120:\tlearn: 0.9827809\ttest: 0.9712764\tbest: 0.9715590 (119)\ttotal: 2.95s\tremaining: 21.4s\n",
      "130:\tlearn: 0.9830183\ttest: 0.9712764\tbest: 0.9715590 (119)\ttotal: 3.17s\tremaining: 21s\n",
      "140:\tlearn: 0.9832622\ttest: 0.9716407\tbest: 0.9716407 (138)\ttotal: 3.42s\tremaining: 20.9s\n",
      "150:\tlearn: 0.9836396\ttest: 0.9721085\tbest: 0.9721085 (146)\ttotal: 3.66s\tremaining: 20.6s\n",
      "160:\tlearn: 0.9840203\ttest: 0.9718203\tbest: 0.9721085 (146)\ttotal: 3.9s\tremaining: 20.3s\n",
      "170:\tlearn: 0.9843540\ttest: 0.9718149\tbest: 0.9721085 (146)\ttotal: 4.18s\tremaining: 20.3s\n",
      "180:\tlearn: 0.9845903\ttest: 0.9720053\tbest: 0.9721085 (146)\ttotal: 4.44s\tremaining: 20.1s\n",
      "190:\tlearn: 0.9849700\ttest: 0.9721852\tbest: 0.9721852 (190)\ttotal: 4.68s\tremaining: 19.8s\n",
      "200:\tlearn: 0.9852539\ttest: 0.9719893\tbest: 0.9721852 (190)\ttotal: 4.96s\tremaining: 19.7s\n",
      "210:\tlearn: 0.9857774\ttest: 0.9719074\tbest: 0.9722778 (203)\ttotal: 5.18s\tremaining: 19.4s\n",
      "220:\tlearn: 0.9860170\ttest: 0.9719074\tbest: 0.9722778 (203)\ttotal: 5.46s\tremaining: 19.3s\n",
      "230:\tlearn: 0.9863488\ttest: 0.9719128\tbest: 0.9722778 (203)\ttotal: 5.7s\tremaining: 19s\n",
      "240:\tlearn: 0.9867308\ttest: 0.9717170\tbest: 0.9722778 (203)\ttotal: 5.98s\tremaining: 18.8s\n",
      "250:\tlearn: 0.9868244\ttest: 0.9713361\tbest: 0.9722778 (203)\ttotal: 6.27s\tremaining: 18.7s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9722777937\n",
      "bestIteration = 203\n",
      "\n",
      "Shrink model to first 204 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost_base'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.05,\n",
    "    'seed':0, \n",
    "    'metric':'f1',\n",
    "    'max_depth':6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train,y_train)\n",
    "    valid_data = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(lgb_params, train_data,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid_data,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,np.round(model.predict(X_test)),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_base'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'predicted_fare_diff',\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare',\n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duration_diff',\n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration',\n",
    "    'predicted_duraton_diff_per_distance',\n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'predicted_avg_speed_diff',\n",
    "    'predicted_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_distance',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_distance',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_diff_per_distance',\n",
    "    'predicted_meter_waiting_till_pickup_diff',\n",
    "    'predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup',\n",
    "    'predicted_meter_waiting_till_pickup_per_meter_waiting_diff',\n",
    "    'predicted_fare_diff_per_distance_normalized',\n",
    "    'predicted_fare_diff_normalized',\n",
    "    'predicted_fare_diff_per_fare_normalized',\n",
    "    'predicted_fare_diff_per_predicted_fare_normalized',\n",
    "    'predicted_duraton_diff_per_duraton_normalized',\n",
    "    'predicted_duraton_diff_per_predicted_duration_normalized',\n",
    "    'predicted_fare_per_duration_diff_normalized',\n",
    "    'predicted_avg_speed_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_per_duration_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff_normalized',\n",
    "    'predicted_additional_fare_diff_normalized',\n",
    "    'predicted_additional_fare_diff_per_additional_fare_normalized',\n",
    "]\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9691234\ttest: 0.9694540\tbest: 0.9694540 (0)\ttotal: 22ms\tremaining: 22s\n",
      "10:\tlearn: 0.9729214\ttest: 0.9740508\tbest: 0.9740508 (10)\ttotal: 227ms\tremaining: 20.4s\n",
      "20:\tlearn: 0.9743174\ttest: 0.9757170\tbest: 0.9757170 (20)\ttotal: 364ms\tremaining: 17s\n",
      "30:\tlearn: 0.9751363\ttest: 0.9761563\tbest: 0.9761563 (30)\ttotal: 515ms\tremaining: 16.1s\n",
      "40:\tlearn: 0.9760651\ttest: 0.9764097\tbest: 0.9765078 (36)\ttotal: 650ms\tremaining: 15.2s\n",
      "50:\tlearn: 0.9767152\ttest: 0.9770479\tbest: 0.9771418 (49)\ttotal: 837ms\tremaining: 15.6s\n",
      "60:\tlearn: 0.9772836\ttest: 0.9774147\tbest: 0.9778034 (58)\ttotal: 996ms\tremaining: 15.3s\n",
      "70:\tlearn: 0.9779419\ttest: 0.9776026\tbest: 0.9778034 (58)\ttotal: 1.18s\tremaining: 15.5s\n",
      "80:\tlearn: 0.9782275\ttest: 0.9780643\tbest: 0.9780643 (79)\ttotal: 1.39s\tremaining: 15.8s\n",
      "90:\tlearn: 0.9786458\ttest: 0.9784491\tbest: 0.9784491 (88)\ttotal: 1.59s\tremaining: 15.9s\n",
      "100:\tlearn: 0.9793037\ttest: 0.9785433\tbest: 0.9785433 (94)\ttotal: 1.8s\tremaining: 16s\n",
      "110:\tlearn: 0.9797859\ttest: 0.9785350\tbest: 0.9785433 (94)\ttotal: 2.03s\tremaining: 16.3s\n",
      "120:\tlearn: 0.9806445\ttest: 0.9783425\tbest: 0.9787234 (114)\ttotal: 2.21s\tremaining: 16.1s\n",
      "130:\tlearn: 0.9809345\ttest: 0.9783466\tbest: 0.9787234 (114)\ttotal: 2.42s\tremaining: 16.1s\n",
      "140:\tlearn: 0.9809798\ttest: 0.9780474\tbest: 0.9787234 (114)\ttotal: 2.6s\tremaining: 15.8s\n",
      "150:\tlearn: 0.9813133\ttest: 0.9781416\tbest: 0.9787234 (114)\ttotal: 2.81s\tremaining: 15.8s\n",
      "160:\tlearn: 0.9815509\ttest: 0.9782357\tbest: 0.9787234 (114)\ttotal: 2.99s\tremaining: 15.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9787234043\n",
      "bestIteration = 114\n",
      "\n",
      "Shrink model to first 115 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9713079\ttest: 0.9747030\tbest: 0.9747030 (0)\ttotal: 15ms\tremaining: 15s\n",
      "10:\tlearn: 0.9729111\ttest: 0.9749213\tbest: 0.9751861 (5)\ttotal: 219ms\tremaining: 19.7s\n",
      "20:\tlearn: 0.9751386\ttest: 0.9768510\tbest: 0.9768510 (20)\ttotal: 374ms\tremaining: 17.4s\n",
      "30:\tlearn: 0.9760674\ttest: 0.9771270\tbest: 0.9771270 (28)\ttotal: 546ms\tremaining: 17.1s\n",
      "40:\tlearn: 0.9766707\ttest: 0.9771095\tbest: 0.9772074 (39)\ttotal: 680ms\tremaining: 15.9s\n",
      "50:\tlearn: 0.9773795\ttest: 0.9776713\tbest: 0.9776713 (50)\ttotal: 830ms\tremaining: 15.5s\n",
      "60:\tlearn: 0.9775669\ttest: 0.9770963\tbest: 0.9776713 (50)\ttotal: 1.01s\tremaining: 15.5s\n",
      "70:\tlearn: 0.9781358\ttest: 0.9765213\tbest: 0.9776713 (50)\ttotal: 1.19s\tremaining: 15.6s\n",
      "80:\tlearn: 0.9791317\ttest: 0.9770071\tbest: 0.9776713 (50)\ttotal: 1.43s\tremaining: 16.3s\n",
      "90:\tlearn: 0.9796055\ttest: 0.9769046\tbest: 0.9776713 (50)\ttotal: 1.63s\tremaining: 16.3s\n",
      "100:\tlearn: 0.9799347\ttest: 0.9766951\tbest: 0.9776713 (50)\ttotal: 1.79s\tremaining: 15.9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9776712985\n",
      "bestIteration = 50\n",
      "\n",
      "Shrink model to first 51 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9750526\ttest: 0.9664762\tbest: 0.9664762 (0)\ttotal: 14.1ms\tremaining: 14s\n",
      "10:\tlearn: 0.9775948\ttest: 0.9697721\tbest: 0.9698818 (9)\ttotal: 165ms\tremaining: 14.8s\n",
      "20:\tlearn: 0.9779162\ttest: 0.9693673\tbest: 0.9702517 (12)\ttotal: 334ms\tremaining: 15.6s\n",
      "30:\tlearn: 0.9785235\ttest: 0.9707625\tbest: 0.9707681 (28)\ttotal: 517ms\tremaining: 16.2s\n",
      "40:\tlearn: 0.9791687\ttest: 0.9713248\tbest: 0.9714231 (38)\ttotal: 682ms\tremaining: 16s\n",
      "50:\tlearn: 0.9797349\ttest: 0.9711281\tbest: 0.9714231 (38)\ttotal: 879ms\tremaining: 16.4s\n",
      "60:\tlearn: 0.9801604\ttest: 0.9716963\tbest: 0.9716963 (59)\ttotal: 1.05s\tremaining: 16.2s\n",
      "70:\tlearn: 0.9806315\ttest: 0.9715980\tbest: 0.9716963 (59)\ttotal: 1.23s\tremaining: 16.2s\n",
      "80:\tlearn: 0.9813515\ttest: 0.9715980\tbest: 0.9716963 (59)\ttotal: 1.41s\tremaining: 16s\n",
      "90:\tlearn: 0.9814913\ttest: 0.9720735\tbest: 0.9720735 (87)\ttotal: 1.64s\tremaining: 16.4s\n",
      "100:\tlearn: 0.9822098\ttest: 0.9718822\tbest: 0.9720735 (87)\ttotal: 1.8s\tremaining: 16s\n",
      "110:\tlearn: 0.9824005\ttest: 0.9715980\tbest: 0.9720735 (87)\ttotal: 1.98s\tremaining: 15.9s\n",
      "120:\tlearn: 0.9826873\ttest: 0.9714067\tbest: 0.9720735 (87)\ttotal: 2.18s\tremaining: 15.8s\n",
      "130:\tlearn: 0.9829759\ttest: 0.9714012\tbest: 0.9720735 (87)\ttotal: 2.34s\tremaining: 15.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9720734507\n",
      "bestIteration = 87\n",
      "\n",
      "Shrink model to first 88 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost_pred_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.05,\n",
    "    'seed':0, \n",
    "    'metric':'f1',\n",
    "    'max_depth':6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train,y_train)\n",
    "    valid_data = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(lgb_params, train_data,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid_data,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,np.round(model.predict(X_test)),average='micro'))\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_pred_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':10,\n",
    "    'weights':'uniform'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = KNeighborsClassifier(**knn_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'knn_pred_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':1,\n",
    "    'kernel':'rbf',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'auto'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svm_pred_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'predicted_fare_diff_per_fare',\n",
    "    'predicted_fare_diff_per_predicted_fare',\n",
    "    'predicted_fare_diff_per_distance',\n",
    "    'predicted_duraton_diff_per_duraton',\n",
    "    'predicted_duraton_diff_per_predicted_duration',\n",
    "    'predicted_duraton_diff_per_distance',\n",
    "    'predicted_fare_per_duration_diff',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting',\n",
    "    'predicted_meter_waiting_diff_per_distance',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting',\n",
    "    'predicted_meter_waiting_per_duration_diff',\n",
    "    'predicted_meter_waiting_fare_diff_per_distance',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff',\n",
    "    'predicted_additional_fare_diff_per_additional_fare',\n",
    "    'predicted_addtional_fare_diff_per_distance',\n",
    "    'predicted_meter_waiting_till_pickup_diff_per_meter_waiting_till_pickup',\n",
    "    'predicted_meter_waiting_till_pickup_per_meter_waiting_diff'\n",
    "]\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9645377\ttest: 0.9632381\tbest: 0.9632381 (0)\ttotal: 18.9ms\tremaining: 18.9s\n",
      "10:\tlearn: 0.9730582\ttest: 0.9747867\tbest: 0.9747867 (10)\ttotal: 174ms\tremaining: 15.7s\n",
      "20:\tlearn: 0.9741948\ttest: 0.9761905\tbest: 0.9761905 (20)\ttotal: 296ms\tremaining: 13.8s\n",
      "30:\tlearn: 0.9750706\ttest: 0.9772269\tbest: 0.9772269 (30)\ttotal: 374ms\tremaining: 11.7s\n",
      "40:\tlearn: 0.9756728\ttest: 0.9773121\tbest: 0.9774190 (31)\ttotal: 453ms\tremaining: 10.6s\n",
      "50:\tlearn: 0.9764790\ttest: 0.9777906\tbest: 0.9777949 (46)\ttotal: 553ms\tremaining: 10.3s\n",
      "60:\tlearn: 0.9769448\ttest: 0.9777821\tbest: 0.9777949 (46)\ttotal: 637ms\tremaining: 9.8s\n",
      "70:\tlearn: 0.9777075\ttest: 0.9777778\tbest: 0.9778761 (68)\ttotal: 718ms\tremaining: 9.39s\n",
      "80:\tlearn: 0.9784766\ttest: 0.9778718\tbest: 0.9781584 (74)\ttotal: 817ms\tremaining: 9.27s\n",
      "90:\tlearn: 0.9788560\ttest: 0.9783508\tbest: 0.9783508 (89)\ttotal: 907ms\tremaining: 9.05s\n",
      "100:\tlearn: 0.9793686\ttest: 0.9781500\tbest: 0.9783508 (89)\ttotal: 993ms\tremaining: 8.84s\n",
      "110:\tlearn: 0.9796506\ttest: 0.9780600\tbest: 0.9783508 (89)\ttotal: 1.1s\tremaining: 8.78s\n",
      "120:\tlearn: 0.9799837\ttest: 0.9778676\tbest: 0.9783508 (89)\ttotal: 1.19s\tremaining: 8.64s\n",
      "130:\tlearn: 0.9802679\ttest: 0.9783466\tbest: 0.9783508 (89)\ttotal: 1.28s\tremaining: 8.51s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.978350813\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9681798\ttest: 0.9660232\tbest: 0.9660232 (0)\ttotal: 9.39ms\tremaining: 9.38s\n",
      "10:\tlearn: 0.9727203\ttest: 0.9734007\tbest: 0.9738350 (4)\ttotal: 143ms\tremaining: 12.8s\n",
      "20:\tlearn: 0.9745159\ttest: 0.9748686\tbest: 0.9751577 (17)\ttotal: 274ms\tremaining: 12.8s\n",
      "30:\tlearn: 0.9749258\ttest: 0.9749522\tbest: 0.9755305 (23)\ttotal: 405ms\tremaining: 12.7s\n",
      "40:\tlearn: 0.9757149\ttest: 0.9753996\tbest: 0.9755305 (23)\ttotal: 516ms\tremaining: 12.1s\n",
      "50:\tlearn: 0.9764700\ttest: 0.9755864\tbest: 0.9756798 (44)\ttotal: 686ms\tremaining: 12.8s\n",
      "60:\tlearn: 0.9768891\ttest: 0.9758621\tbest: 0.9759602 (57)\ttotal: 828ms\tremaining: 12.7s\n",
      "70:\tlearn: 0.9776904\ttest: 0.9759417\tbest: 0.9763297 (69)\ttotal: 937ms\tremaining: 12.3s\n",
      "80:\tlearn: 0.9779740\ttest: 0.9765168\tbest: 0.9765168 (80)\ttotal: 1.04s\tremaining: 11.8s\n",
      "90:\tlearn: 0.9784539\ttest: 0.9765123\tbest: 0.9766149 (82)\ttotal: 1.11s\tremaining: 11.1s\n",
      "100:\tlearn: 0.9789337\ttest: 0.9764142\tbest: 0.9766149 (82)\ttotal: 1.26s\tremaining: 11.2s\n",
      "110:\tlearn: 0.9795076\ttest: 0.9763160\tbest: 0.9766149 (82)\ttotal: 1.35s\tremaining: 10.8s\n",
      "120:\tlearn: 0.9799309\ttest: 0.9765033\tbest: 0.9766149 (82)\ttotal: 1.43s\tremaining: 10.4s\n",
      "130:\tlearn: 0.9806012\ttest: 0.9763024\tbest: 0.9766906 (126)\ttotal: 1.53s\tremaining: 10.2s\n",
      "140:\tlearn: 0.9814655\ttest: 0.9764006\tbest: 0.9766906 (126)\ttotal: 1.62s\tremaining: 9.85s\n",
      "150:\tlearn: 0.9816994\ttest: 0.9766862\tbest: 0.9767843 (145)\ttotal: 1.7s\tremaining: 9.55s\n",
      "160:\tlearn: 0.9820854\ttest: 0.9767754\tbest: 0.9770655 (157)\ttotal: 1.88s\tremaining: 9.78s\n",
      "170:\tlearn: 0.9822758\ttest: 0.9765880\tbest: 0.9770655 (157)\ttotal: 2.04s\tremaining: 9.88s\n",
      "180:\tlearn: 0.9826145\ttest: 0.9768736\tbest: 0.9770655 (157)\ttotal: 2.14s\tremaining: 9.68s\n",
      "190:\tlearn: 0.9829043\ttest: 0.9768692\tbest: 0.9770655 (157)\ttotal: 2.27s\tremaining: 9.6s\n",
      "200:\tlearn: 0.9832381\ttest: 0.9772487\tbest: 0.9772487 (200)\ttotal: 2.36s\tremaining: 9.4s\n",
      "210:\tlearn: 0.9836695\ttest: 0.9769585\tbest: 0.9772487 (200)\ttotal: 2.46s\tremaining: 9.19s\n",
      "220:\tlearn: 0.9839089\ttest: 0.9771505\tbest: 0.9772487 (200)\ttotal: 2.56s\tremaining: 9.02s\n",
      "230:\tlearn: 0.9842917\ttest: 0.9771505\tbest: 0.9772487 (200)\ttotal: 2.67s\tremaining: 8.88s\n",
      "240:\tlearn: 0.9845799\ttest: 0.9774451\tbest: 0.9775389 (236)\ttotal: 2.76s\tremaining: 8.68s\n",
      "250:\tlearn: 0.9846745\ttest: 0.9770567\tbest: 0.9775389 (236)\ttotal: 2.83s\tremaining: 8.46s\n",
      "260:\tlearn: 0.9849584\ttest: 0.9775346\tbest: 0.9775389 (236)\ttotal: 2.93s\tremaining: 8.29s\n",
      "270:\tlearn: 0.9850072\ttest: 0.9773425\tbest: 0.9775389 (236)\ttotal: 3.01s\tremaining: 8.09s\n",
      "280:\tlearn: 0.9852969\ttest: 0.9773382\tbest: 0.9775389 (236)\ttotal: 3.12s\tremaining: 7.99s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.977538875\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9708335\ttest: 0.9646382\tbest: 0.9646382 (0)\ttotal: 8.28ms\tremaining: 8.27s\n",
      "10:\tlearn: 0.9760367\ttest: 0.9685714\tbest: 0.9685714 (10)\ttotal: 114ms\tremaining: 10.2s\n",
      "20:\tlearn: 0.9767976\ttest: 0.9687679\tbest: 0.9690741 (15)\ttotal: 215ms\tremaining: 10s\n",
      "30:\tlearn: 0.9775841\ttest: 0.9702347\tbest: 0.9702347 (30)\ttotal: 295ms\tremaining: 9.21s\n",
      "40:\tlearn: 0.9782015\ttest: 0.9707904\tbest: 0.9707904 (40)\ttotal: 413ms\tremaining: 9.66s\n",
      "50:\tlearn: 0.9791886\ttest: 0.9706921\tbest: 0.9708831 (42)\ttotal: 529ms\tremaining: 9.84s\n",
      "60:\tlearn: 0.9797074\ttest: 0.9712539\tbest: 0.9714449 (55)\ttotal: 609ms\tremaining: 9.37s\n",
      "70:\tlearn: 0.9802736\ttest: 0.9712430\tbest: 0.9714449 (55)\ttotal: 707ms\tremaining: 9.25s\n",
      "80:\tlearn: 0.9804637\ttest: 0.9711391\tbest: 0.9714449 (55)\ttotal: 808ms\tremaining: 9.17s\n",
      "90:\tlearn: 0.9808006\ttest: 0.9710519\tbest: 0.9714449 (55)\ttotal: 889ms\tremaining: 8.88s\n",
      "100:\tlearn: 0.9811792\ttest: 0.9707625\tbest: 0.9714449 (55)\ttotal: 995ms\tremaining: 8.85s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9714449432\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost_unit_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.05,\n",
    "    'seed':0, \n",
    "    'metric':'f1',\n",
    "    'max_depth':8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train,y_train)\n",
    "    valid_data = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(lgb_params, train_data,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid_data,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,np.round(model.predict(X_test)),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_unit_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':10,\n",
    "    'weights':'distance'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = KNeighborsClassifier(**knn_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'knn_unit_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':5,\n",
    "    'kernel':'rbf',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'auto'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'rbf_svm_unit_diff'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'predicted_fare_diff_per_distance_normalized',\n",
    "    'predicted_fare_diff_normalized',\n",
    "    'predicted_fare_diff_per_fare_normalized',\n",
    "    'predicted_fare_diff_per_predicted_fare_normalized',\n",
    "    'predicted_duraton_diff_per_duraton_normalized',\n",
    "    'predicted_duraton_diff_per_predicted_duration_normalized',\n",
    "    'predicted_fare_per_duration_diff_normalized',\n",
    "    'predicted_avg_speed_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_diff_per_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_diff_per_predicted_meter_waiting_normalized',\n",
    "    'predicted_meter_waiting_per_duration_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_diff_per_predicted_meter_waiting_fare_normalized',\n",
    "    'predicted_meter_waiting_fare_per_meter_waiting_diff_normalized',\n",
    "    'predicted_meter_waiting_fare_per_duration_diff_normalized',\n",
    "    'predicted_additional_fare_diff_normalized',\n",
    "    'predicted_additional_fare_diff_per_additional_fare_normalized',\n",
    "]\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':15,\n",
    "    'weights':'distance'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_org' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-79cf580d48c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvalidation_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0morg_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_org\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_org' is not defined"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = KNeighborsClassifier(**knn_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    org_scores.append(f1_score(y_org,model.predict(train_org.values),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'knn_unit_diff_norm'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':5,\n",
    "    'kernel':'rbf',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'scale'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svm_rbf_unit_diff_norm'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'fare_per_distance',\n",
    "    'fare_per_duration',\n",
    "    'avg_speed',\n",
    "    'meter_waiting_per_duration',\n",
    "    'meter_waiting_fare_per_meter_waiting',\n",
    "    'meter_waiting_fare_per_duration',\n",
    "    'addtional_fare_per_fare',\n",
    "    'addtional_fare_per_distance',\n",
    "    'addtional_fare_per_duration',\n",
    "    'fare-additional_fare_per_distance',\n",
    "    'fare-additional_fare_per_duration',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_distance',\n",
    "    'fare-additional_fare-meter_waiting_fare_per_duration',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting',\n",
    "    'meter_waiting_after_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_duration',\n",
    "    'meter_waiting_till_pickup_per_distance',\n",
    "    'meter_waiting_after_pickup_per_distance',\n",
    "    'meter_waiting_till_pickup_per_fare',\n",
    "    'meter_waiting_after_pickup_per_fare',\n",
    "    'meter_waiting_till_pickup_per_meter_waiting_fare',\n",
    "    'meter_waiting_after_pickup_per_meter_waiting_fare',    \n",
    "]\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "y = train_df['label']\n",
    "for each in cat_features:\n",
    "    train[each] = train[each].values.astype(int)\n",
    "    test[each] = test[each].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'loss_function':'Logloss',\n",
    "    'random_state':0,\n",
    "    'early_stopping_rounds':50,\n",
    "    'eval_metric':'F1',\n",
    "    'border_count':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pool = Pool(data=test_df[features], cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9637438\ttest: 0.9634802\tbest: 0.9634802 (0)\ttotal: 20.4ms\tremaining: 20.4s\n",
      "10:\tlearn: 0.9706593\ttest: 0.9747052\tbest: 0.9749786 (9)\ttotal: 175ms\tremaining: 15.7s\n",
      "20:\tlearn: 0.9737268\ttest: 0.9762337\tbest: 0.9763359 (19)\ttotal: 279ms\tremaining: 13s\n",
      "30:\tlearn: 0.9750238\ttest: 0.9774249\tbest: 0.9774249 (30)\ttotal: 362ms\tremaining: 11.3s\n",
      "40:\tlearn: 0.9757680\ttest: 0.9782713\tbest: 0.9783691 (39)\ttotal: 444ms\tremaining: 10.4s\n",
      "50:\tlearn: 0.9766909\ttest: 0.9786337\tbest: 0.9787397 (46)\ttotal: 548ms\tremaining: 10.2s\n",
      "60:\tlearn: 0.9773466\ttest: 0.9784297\tbest: 0.9787397 (46)\ttotal: 646ms\tremaining: 9.95s\n",
      "70:\tlearn: 0.9778670\ttest: 0.9786214\tbest: 0.9787397 (46)\ttotal: 740ms\tremaining: 9.68s\n",
      "80:\tlearn: 0.9782390\ttest: 0.9787152\tbest: 0.9789110 (77)\ttotal: 860ms\tremaining: 9.76s\n",
      "90:\tlearn: 0.9785625\ttest: 0.9787071\tbest: 0.9790049 (82)\ttotal: 966ms\tremaining: 9.65s\n",
      "100:\tlearn: 0.9789821\ttest: 0.9782171\tbest: 0.9790049 (82)\ttotal: 1.09s\tremaining: 9.72s\n",
      "110:\tlearn: 0.9795977\ttest: 0.9780209\tbest: 0.9790049 (82)\ttotal: 1.26s\tremaining: 10.1s\n",
      "120:\tlearn: 0.9801121\ttest: 0.9780083\tbest: 0.9790049 (82)\ttotal: 1.42s\tremaining: 10.3s\n",
      "130:\tlearn: 0.9806365\ttest: 0.9780083\tbest: 0.9790049 (82)\ttotal: 1.52s\tremaining: 10.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9790048893\n",
      "bestIteration = 82\n",
      "\n",
      "Shrink model to first 83 iterations.\n",
      "Learning rate set to 0.057693\n",
      "0:\tlearn: 0.9666745\ttest: 0.9683574\tbest: 0.9683574 (0)\ttotal: 21.1ms\tremaining: 21.1s\n",
      "10:\tlearn: 0.9723395\ttest: 0.9732712\tbest: 0.9732712 (10)\ttotal: 184ms\tremaining: 16.5s\n",
      "20:\tlearn: 0.9738130\ttest: 0.9740903\tbest: 0.9743736 (19)\ttotal: 302ms\tremaining: 14.1s\n",
      "30:\tlearn: 0.9745811\ttest: 0.9745448\tbest: 0.9745545 (24)\ttotal: 424ms\tremaining: 13.3s\n",
      "40:\tlearn: 0.9757446\ttest: 0.9753864\tbest: 0.9753864 (40)\ttotal: 567ms\tremaining: 13.3s\n",
      "50:\tlearn: 0.9762495\ttest: 0.9763178\tbest: 0.9764155 (48)\ttotal: 664ms\tremaining: 12.4s\n",
      "60:\tlearn: 0.9772282\ttest: 0.9767709\tbest: 0.9769797 (53)\ttotal: 757ms\tremaining: 11.7s\n",
      "70:\tlearn: 0.9781134\ttest: 0.9772379\tbest: 0.9772379 (70)\ttotal: 875ms\tremaining: 11.5s\n",
      "80:\tlearn: 0.9785769\ttest: 0.9771226\tbest: 0.9772379 (70)\ttotal: 963ms\tremaining: 10.9s\n",
      "90:\tlearn: 0.9791856\ttest: 0.9772074\tbest: 0.9774076 (85)\ttotal: 1.06s\tremaining: 10.5s\n",
      "100:\tlearn: 0.9795567\ttest: 0.9774883\tbest: 0.9775905 (93)\ttotal: 1.17s\tremaining: 10.4s\n",
      "110:\tlearn: 0.9800747\ttest: 0.9770963\tbest: 0.9775905 (93)\ttotal: 1.26s\tremaining: 10.1s\n",
      "120:\tlearn: 0.9805500\ttest: 0.9773860\tbest: 0.9775905 (93)\ttotal: 1.34s\tremaining: 9.77s\n",
      "130:\tlearn: 0.9809766\ttest: 0.9775690\tbest: 0.9776627 (129)\ttotal: 1.45s\tremaining: 9.64s\n",
      "140:\tlearn: 0.9810199\ttest: 0.9774753\tbest: 0.9778545 (131)\ttotal: 1.68s\tremaining: 10.2s\n",
      "150:\tlearn: 0.9813021\ttest: 0.9777565\tbest: 0.9778545 (131)\ttotal: 1.85s\tremaining: 10.4s\n",
      "160:\tlearn: 0.9816333\ttest: 0.9775604\tbest: 0.9778545 (131)\ttotal: 2s\tremaining: 10.4s\n",
      "170:\tlearn: 0.9820641\ttest: 0.9776456\tbest: 0.9778545 (131)\ttotal: 2.14s\tremaining: 10.4s\n",
      "180:\tlearn: 0.9822491\ttest: 0.9776456\tbest: 0.9779355 (178)\ttotal: 2.26s\tremaining: 10.2s\n",
      "190:\tlearn: 0.9826329\ttest: 0.9780209\tbest: 0.9780209 (190)\ttotal: 2.35s\tremaining: 9.98s\n",
      "200:\tlearn: 0.9830118\ttest: 0.9778375\tbest: 0.9780209 (190)\ttotal: 2.52s\tremaining: 10s\n",
      "210:\tlearn: 0.9832022\ttest: 0.9777437\tbest: 0.9780209 (190)\ttotal: 2.72s\tremaining: 10.2s\n",
      "220:\tlearn: 0.9834381\ttest: 0.9779313\tbest: 0.9780209 (190)\ttotal: 2.87s\tremaining: 10.1s\n",
      "230:\tlearn: 0.9837231\ttest: 0.9777351\tbest: 0.9780251 (222)\ttotal: 2.99s\tremaining: 9.97s\n",
      "240:\tlearn: 0.9840081\ttest: 0.9776370\tbest: 0.9780251 (222)\ttotal: 3.08s\tremaining: 9.69s\n",
      "250:\tlearn: 0.9843435\ttest: 0.9778205\tbest: 0.9780251 (222)\ttotal: 3.16s\tremaining: 9.44s\n",
      "260:\tlearn: 0.9846760\ttest: 0.9777223\tbest: 0.9780251 (222)\ttotal: 3.27s\tremaining: 9.25s\n",
      "270:\tlearn: 0.9848165\ttest: 0.9775259\tbest: 0.9780251 (222)\ttotal: 3.35s\tremaining: 9.02s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9780251415\n",
      "bestIteration = 222\n",
      "\n",
      "Shrink model to first 223 iterations.\n",
      "Learning rate set to 0.057694\n",
      "0:\tlearn: 0.9683532\ttest: 0.9620349\tbest: 0.9620349 (0)\ttotal: 8.33ms\tremaining: 8.32s\n",
      "10:\tlearn: 0.9755215\ttest: 0.9679433\tbest: 0.9679433 (10)\ttotal: 109ms\tremaining: 9.84s\n",
      "20:\tlearn: 0.9770482\ttest: 0.9688417\tbest: 0.9688417 (20)\ttotal: 202ms\tremaining: 9.42s\n",
      "30:\tlearn: 0.9778478\ttest: 0.9695821\tbest: 0.9695821 (30)\ttotal: 339ms\tremaining: 10.6s\n",
      "40:\tlearn: 0.9787763\ttest: 0.9698349\tbest: 0.9698407 (38)\ttotal: 492ms\tremaining: 11.5s\n",
      "50:\tlearn: 0.9791467\ttest: 0.9701053\tbest: 0.9702895 (49)\ttotal: 633ms\tremaining: 11.8s\n",
      "60:\tlearn: 0.9799435\ttest: 0.9702613\tbest: 0.9702895 (49)\ttotal: 756ms\tremaining: 11.6s\n",
      "70:\tlearn: 0.9800316\ttest: 0.9704457\tbest: 0.9704513 (68)\ttotal: 860ms\tremaining: 11.3s\n",
      "80:\tlearn: 0.9806439\ttest: 0.9708036\tbest: 0.9709938 (79)\ttotal: 1.01s\tremaining: 11.5s\n",
      "90:\tlearn: 0.9808319\ttest: 0.9709883\tbest: 0.9712709 (86)\ttotal: 1.12s\tremaining: 11.2s\n",
      "100:\tlearn: 0.9812099\ttest: 0.9716353\tbest: 0.9716353 (100)\ttotal: 1.21s\tremaining: 10.8s\n",
      "110:\tlearn: 0.9819193\ttest: 0.9716190\tbest: 0.9719074 (104)\ttotal: 1.36s\tremaining: 10.9s\n",
      "120:\tlearn: 0.9822491\ttest: 0.9719893\tbest: 0.9719947 (116)\ttotal: 1.46s\tremaining: 10.6s\n",
      "130:\tlearn: 0.9825302\ttest: 0.9722619\tbest: 0.9722619 (130)\ttotal: 1.58s\tremaining: 10.5s\n",
      "140:\tlearn: 0.9826750\ttest: 0.9724473\tbest: 0.9724473 (136)\ttotal: 1.79s\tremaining: 10.9s\n",
      "150:\tlearn: 0.9827222\ttest: 0.9723599\tbest: 0.9725453 (141)\ttotal: 1.92s\tremaining: 10.8s\n",
      "160:\tlearn: 0.9831501\ttest: 0.9724526\tbest: 0.9725453 (141)\ttotal: 2s\tremaining: 10.4s\n",
      "170:\tlearn: 0.9834838\ttest: 0.9724421\tbest: 0.9725453 (141)\ttotal: 2.1s\tremaining: 10.2s\n",
      "180:\tlearn: 0.9836727\ttest: 0.9723441\tbest: 0.9726328 (175)\ttotal: 2.19s\tremaining: 9.91s\n",
      "190:\tlearn: 0.9838144\ttest: 0.9721480\tbest: 0.9726328 (175)\ttotal: 2.29s\tremaining: 9.68s\n",
      "200:\tlearn: 0.9839074\ttest: 0.9720553\tbest: 0.9726328 (175)\ttotal: 2.37s\tremaining: 9.42s\n",
      "210:\tlearn: 0.9843878\ttest: 0.9716684\tbest: 0.9726328 (175)\ttotal: 2.45s\tremaining: 9.17s\n",
      "220:\tlearn: 0.9851005\ttest: 0.9719519\tbest: 0.9726328 (175)\ttotal: 2.55s\tremaining: 9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9726327834\n",
      "bestIteration = 175\n",
      "\n",
      "Shrink model to first 176 iterations.\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "train_class = np.zeros(train_df.shape[0])\n",
    "test_class = np.zeros(test_df.shape[0])\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_pool = Pool(data=X_train, label=y_train,cat_features=cat_features)\n",
    "    test_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)    \n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(X=train_pool, eval_set=test_pool,verbose=10)\n",
    "    train_preds[test_index] = model.predict_proba(test_pool)[:,1]\n",
    "    train_class[test_index] = model.predict(test_pool)\n",
    "    test_preds += model.predict_proba(submission_pool)[:,1]/3\n",
    "    test_class += model.predict(submission_pool)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(test_pool),average='micro'))\n",
    "    models.append(model)\n",
    "test_class = np.where(test_class > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'catboost_unit'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'learning_rate':0.05,\n",
    "    'seed':0, \n",
    "    'metric':'f1',\n",
    "    'max_depth':8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:], train.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train,y_train)\n",
    "    valid_data = lgb.Dataset(X_test,y_test)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(lgb_params, train_data,num_boost_round=1000,early_stopping_rounds=50, valid_sets=valid_data,feval=lgb_f1_score, evals_result=evals_result,verbose_eval=False)\n",
    "    \n",
    "    test_preds += model.predict(test) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,np.round(model.predict(X_test)),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lgb_unit'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors':10,\n",
    "    'weights':'distance'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = KNeighborsClassifier(**knn_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'knn_unit'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C':10,\n",
    "    'kernel':'rbf',\n",
    "    'random_state':0,    \n",
    "    'probability': False,\n",
    "    'gamma':'auto'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "org_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = SVC(**svc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'svm_unit'\n",
    "model_predictions_train[name] = train_preds\n",
    "model_predictions_test[name] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in model_predictions_test.columns:\n",
    "    model_predictions_train[col] = np.round(model_predictions_train[col]).astype(int)\n",
    "    model_predictions_test[col] = np.round(model_predictions_test[col]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'catboost_unit',\n",
    "    'knn_pred_diff',\n",
    "    'catboost_pred_diff',\n",
    "    'lgb_pred_diff',\n",
    "    'catboost_unit_diff',\n",
    "    'lgb_unit_diff',\n",
    "    'svm_pred_diff',\n",
    "    'svc_linear_anomaly',\n",
    "    'catboost_anomaly',\n",
    "    'rbf_svm_unit_diff',\n",
    "    'rf_anomaly'\n",
    "]\n",
    "cat_cols = [\n",
    "    'knn_pred_diff',\n",
    "    'svm_pred_diff',\n",
    "    'svc_linear_anomaly',\n",
    "    'svc_linear_anomaly',\n",
    "    'rbf_svm_unit_diff',\n",
    "    'rf_anomaly',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in cat_cols:\n",
    "    model_predictions_train[each] = model_predictions_train[each].astype(int)\n",
    "    model_predictions_test[each] = model_predictions_test[each].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model_predictions_train[features]\n",
    "test = model_predictions_test[features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_params = {\n",
    "    'penalty':'l2',\n",
    "    'C':1.0,\n",
    "    'solver':'lbfgs',\n",
    "    'max_iter':100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "train_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "validation_scores = []\n",
    "models = []\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    X_train, X_test = train.iloc[train_index,:].values, train.iloc[test_index,:].values\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = LogisticRegression(**logistic_reg_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_preds += model.predict(test.values) / 3\n",
    "    train_preds[test_index] = model.predict(X_test)\n",
    "    validation_scores.append(f1_score(y_test,model.predict(X_test),average='micro'))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = np.round(test_preds).astype(int)\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
